{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b04802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 15:32:57.369507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 15:32:58.940224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.941677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.943223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.944766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.959036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.962675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.965090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.967539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.969944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.972107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.974513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.976041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.978964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 15:32:58.987984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.990510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:58.992938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:59.473244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:59.476644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:59.479695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 15:32:59.482962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38397 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import os\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import skmob\n",
    "from skmob.tessellation import tilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c754cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_pickle('../data/freemove/freemove_point_geographical_context.pickle')\n",
    "points['lat'] = points.geometry.apply(lambda x: x.y)\n",
    "points['lng'] = points.geometry.apply(lambda x: x.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e464e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geographical_context</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 14:59:24</td>\n",
       "      <td>POINT (13.31753 52.53094)</td>\n",
       "      <td>[0.36, 0.22, 0.04, 0.17, 0.46, 0.55, 0.01, 0.3...</td>\n",
       "      <td>52.530942</td>\n",
       "      <td>13.317532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:02:10</td>\n",
       "      <td>POINT (13.32791 52.53281)</td>\n",
       "      <td>[0.83, 0.35, 0.05, 0.4, 0.99, 0.84, 0.02, 0.27...</td>\n",
       "      <td>52.532806</td>\n",
       "      <td>13.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:10:39</td>\n",
       "      <td>POINT (13.36288 52.53582)</td>\n",
       "      <td>[0.18, 0.27, 0.03, 0.09, 0.49, 0.27, 0.16, 0.2...</td>\n",
       "      <td>52.535821</td>\n",
       "      <td>13.362884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:13:28</td>\n",
       "      <td>POINT (13.36931 52.52905)</td>\n",
       "      <td>[0.27, 0.4, 0.07, 0.16, 0.45, 0.53, 0.14, 0.19...</td>\n",
       "      <td>52.529052</td>\n",
       "      <td>13.369314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:16:03</td>\n",
       "      <td>POINT (13.36997 52.52837)</td>\n",
       "      <td>[0.26, 0.39, 0.08, 0.15, 0.43, 0.55, 0.25, 0.2...</td>\n",
       "      <td>52.528374</td>\n",
       "      <td>13.369971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12346</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:09:33</td>\n",
       "      <td>POINT (13.36541 52.47671)</td>\n",
       "      <td>[0.09, 0.26, 0.01, 0.03, 0.28, 0.34, 0.02, 0.0...</td>\n",
       "      <td>52.476712</td>\n",
       "      <td>13.365414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:15:28</td>\n",
       "      <td>POINT (13.35614 52.46070)</td>\n",
       "      <td>[0.02, 0.48, 0.0, 0.02, 1.0, 0.34, 0.15, 0.02,...</td>\n",
       "      <td>52.460702</td>\n",
       "      <td>13.356144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:17:07</td>\n",
       "      <td>POINT (13.35593 52.45973)</td>\n",
       "      <td>[0.02, 0.59, 0.0, 0.03, 1.0, 0.34, 0.22, 0.02,...</td>\n",
       "      <td>52.459734</td>\n",
       "      <td>13.355926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:19:27</td>\n",
       "      <td>POINT (13.35338 52.44808)</td>\n",
       "      <td>[0.29, 0.39, 0.0, 0.07, 0.3, 0.22, 0.16, 0.05,...</td>\n",
       "      <td>52.448084</td>\n",
       "      <td>13.353378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:20:54</td>\n",
       "      <td>POINT (13.35283 52.44752)</td>\n",
       "      <td>[0.73, 0.61, 0.0, 0.11, 0.46, 0.42, 0.2, 0.06,...</td>\n",
       "      <td>52.447518</td>\n",
       "      <td>13.352827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12351 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRIP_ID  PERSON_ID                TIME                   geometry  \\\n",
       "0       978933      17246 2022-10-21 14:59:24  POINT (13.31753 52.53094)   \n",
       "1       978933      17246 2022-10-21 15:02:10  POINT (13.32791 52.53281)   \n",
       "2       978933      17246 2022-10-21 15:10:39  POINT (13.36288 52.53582)   \n",
       "3       978933      17246 2022-10-21 15:13:28  POINT (13.36931 52.52905)   \n",
       "4       978933      17246 2022-10-21 15:16:03  POINT (13.36997 52.52837)   \n",
       "...        ...        ...                 ...                        ...   \n",
       "12346  1015191      16370 2022-11-17 22:09:33  POINT (13.36541 52.47671)   \n",
       "12347  1015191      16370 2022-11-17 22:15:28  POINT (13.35614 52.46070)   \n",
       "12348  1015191      16370 2022-11-17 22:17:07  POINT (13.35593 52.45973)   \n",
       "12349  1015191      16370 2022-11-17 22:19:27  POINT (13.35338 52.44808)   \n",
       "12350  1015191      16370 2022-11-17 22:20:54  POINT (13.35283 52.44752)   \n",
       "\n",
       "                                    geographical_context        lat        lng  \n",
       "0      [0.36, 0.22, 0.04, 0.17, 0.46, 0.55, 0.01, 0.3...  52.530942  13.317532  \n",
       "1      [0.83, 0.35, 0.05, 0.4, 0.99, 0.84, 0.02, 0.27...  52.532806  13.327908  \n",
       "2      [0.18, 0.27, 0.03, 0.09, 0.49, 0.27, 0.16, 0.2...  52.535821  13.362884  \n",
       "3      [0.27, 0.4, 0.07, 0.16, 0.45, 0.53, 0.14, 0.19...  52.529052  13.369314  \n",
       "4      [0.26, 0.39, 0.08, 0.15, 0.43, 0.55, 0.25, 0.2...  52.528374  13.369971  \n",
       "...                                                  ...        ...        ...  \n",
       "12346  [0.09, 0.26, 0.01, 0.03, 0.28, 0.34, 0.02, 0.0...  52.476712  13.365414  \n",
       "12347  [0.02, 0.48, 0.0, 0.02, 1.0, 0.34, 0.15, 0.02,...  52.460702  13.356144  \n",
       "12348  [0.02, 0.59, 0.0, 0.03, 1.0, 0.34, 0.22, 0.02,...  52.459734  13.355926  \n",
       "12349  [0.29, 0.39, 0.0, 0.07, 0.3, 0.22, 0.16, 0.05,...  52.448084  13.353378  \n",
       "12350  [0.73, 0.61, 0.0, 0.11, 0.46, 0.42, 0.2, 0.06,...  52.447518  13.352827  \n",
       "\n",
       "[12351 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247efab7",
   "metadata": {},
   "source": [
    "## Filter trajectories that lie outside of berlin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bec9cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3460: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/usr/local/lib/python3.8/dist-packages/skmob/core/trajectorydataframe.py:322: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  tile_ids = gpd.sjoin(gdf, tessellation, how=how, op='within')[[constants.TILE_ID]]\n"
     ]
    }
   ],
   "source": [
    "tessellation = tilers.tiler.get(\"squared\", base_shape='Berlin, Germany', meters=500)\n",
    "\n",
    "tdf = skmob.TrajDataFrame(points)\n",
    "mapped = tdf.mapping(tessellation, remove_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5714f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = set(points.index).difference(mapped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4ddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_traj_ids = []\n",
    "for i, point in points.iterrows():\n",
    "    if i in filtered_indices:\n",
    "        drop_traj_ids.append(point.TRIP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6edf75b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drop_traj_ids) == len(points) - len(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063f1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = points.query('TRIP_ID not in @drop_traj_ids').reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581ce99",
   "metadata": {},
   "source": [
    "## Filter users with less than n trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4549938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "# Count the number of unique values for each ID\n",
    "unique_counts = points.groupby('PERSON_ID')['TRIP_ID'].nunique()\n",
    "# Filter out the IDs with less than n unique values\n",
    "filtered_ids = unique_counts[unique_counts >= n].index.tolist()\n",
    "points = points[points['PERSON_ID'].isin(filtered_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb9d7e",
   "metadata": {},
   "source": [
    "## Geo Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf74f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_points = points.groupby('TRIP_ID').count()['PERSON_ID'].max()\n",
    "geographical_context_dim = len(points['geographical_context'].iloc[0])\n",
    "\n",
    "X_geo_context = np.zeros((points.TRIP_ID.nunique(), max_points, geographical_context_dim))\n",
    "Y = np.zeros((points.TRIP_ID.nunique(),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888ff189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    # get the trajectory id\n",
    "    traj_id = traj[0]\n",
    "\n",
    "    # get the user id\n",
    "    user_id = traj[1]['PERSON_ID'].iloc[0]\n",
    "\n",
    "    Y[index] = user_id\n",
    "\n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geo_context[index, idx] = point['geographical_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe9e29da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 10) [[0.36 0.22 0.04 0.17 0.46 0.55 0.01 0.3  1.   0.02]\n",
      " [0.83 0.35 0.05 0.4  0.99 0.84 0.02 0.27 1.   0.01]\n",
      " [0.18 0.27 0.03 0.09 0.49 0.27 0.16 0.21 1.   0.01]\n",
      " [0.27 0.4  0.07 0.16 0.45 0.53 0.14 0.19 1.   0.  ]\n",
      " [0.26 0.39 0.08 0.15 0.43 0.55 0.25 0.2  1.   0.  ]\n",
      " [0.18 0.27 0.02 0.09 0.51 0.25 0.2  0.2  1.   0.01]\n",
      " [0.46 0.29 0.04 0.15 0.75 0.47 0.1  0.25 1.   0.03]\n",
      " [0.44 0.32 0.06 0.12 0.76 0.45 0.16 0.3  1.   0.04]\n",
      " [0.44 0.32 0.06 0.12 0.77 0.45 0.16 0.3  1.   0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geo_context.shape, X_geo_context[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df4044",
   "metadata": {},
   "source": [
    "## Geo type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8741c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b4f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_type = np.asarray(points.geographical_context.apply(lambda x: np.argmax(x)).tolist()).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d7ba457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 4, 5, 6, 7, 8])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_geo_type = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc_geo_type.fit(geo_type)\n",
    "enc_geo_type.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa3caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['geo_type'] = enc_geo_type.transform(geo_type).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8bf6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_type_dim = len(points['geo_type'].iloc[0])\n",
    "\n",
    "\n",
    "X_geo_type = np.zeros((points.TRIP_ID.nunique(), max_points, geo_type_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geo_type[index, idx, :] = point['geo_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19652710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 7) [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geo_type.shape, X_geo_type[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf95d01",
   "metadata": {},
   "source": [
    "## Geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f07a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "357ad171",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['bin_geohash'] = points.geometry.apply(lambda x: geohash.bin_geohash(x.y, x.x, precision=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47011b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_dim = len(points['bin_geohash'].iloc[0])\n",
    "\n",
    "\n",
    "X_geohash = np.zeros((points.TRIP_ID.nunique(), max_points, geohash_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geohash[index, idx, :] = point['bin_geohash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2452a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 40) [[1. 1. 0. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 1.]\n",
      " [1. 1. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geohash.shape, X_geohash[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c1a10",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7252f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_time = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2513a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hour from TIME column and reshape to array wiht one feature\n",
    "hour = np.asarray(points.TIME.dt.hour).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84fa660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_time.fit(hour)\n",
    "enc_time.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3250537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['hour'] = enc_time.transform(hour).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1e88499",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_dim = len(points['hour'].iloc[0])\n",
    "\n",
    "\n",
    "X_hour = np.zeros((points.TRIP_ID.nunique(), max_points, hour_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_hour[index, idx, :] = point['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "661e2a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 23) [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_hour.shape, X_hour[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd39eec",
   "metadata": {},
   "source": [
    "## Merge Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf7acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "keys = ['bin_geohash', 'hour', 'geographical_context', 'geo_type']\n",
    "\n",
    "X = [X_geohash, X_hour, X_geo_context, X_geo_type]\n",
    "\n",
    "vocab_size = []\n",
    "X = Concatenate(axis=2)(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80b77b",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aef66d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, RepeatVector, GRU, Embedding, Dense, TimeDistributed, Lambda, Bidirectional, Masking\n",
    "from keras.initializers import he_uniform\n",
    "from keras.regularizers import l1\n",
    "from attention import Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0b05bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500\n",
    "EMBEDDER_SIZE = 150\n",
    "timesteps = int(max_points)\n",
    "\n",
    "# input_geohash = keras.Input(shape=(timesteps,geohash_dim))\n",
    "# input_hour = keras.Input(shape=(timesteps,hour_dim))\n",
    "# input_geo_context = keras.Input(shape=(timesteps,geographical_context_dim))\n",
    "# input_geo_type = keras.Input(shape=(timesteps,geo_type_dim))\n",
    "\n",
    "# inputs = [input_geohash, input_hour, input_geo_context, input_geo_type]\n",
    "# hidden_input = Concatenate(axis=2)(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps,geohash_dim+hour_dim+geographical_context_dim+geo_type_dim))\n",
    "\n",
    "# masked = Masking(mask_value=0.,\n",
    "#                 input_shape=(timesteps, features))(inputs)\n",
    "\n",
    "# e_geohash = Embedding(geohash_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geohash')(input_geohash)\n",
    "# e_hour = Embedding(hour_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_hour')(input_hour)\n",
    "# e_geo_context = Embedding(geographical_context_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geo_context')(input_geo_context)\n",
    "# e_geo_type = Embedding(geo_type_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geo_type')(input_geo_type)\n",
    "\n",
    "# e_geohash = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geohash)\n",
    "# e_hour = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_hour)\n",
    "# e_geo_context = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geo_context)\n",
    "# e_geo_type = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geo_type)\n",
    "\n",
    "# embeddings = [e_geohash, e_hour, e_geo_context, e_geo_type]\n",
    "# hidden_input = Concatenate(axis=2)(embeddings)\n",
    "\n",
    "encoded = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(inputs)\n",
    "encoded = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(encoded)\n",
    "\n",
    "encoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(encoded)\n",
    "encoded = Bidirectional(GRU(latent_dim, return_sequences=False, recurrent_regularizer=l1(0.02)))(encoded)\n",
    "\n",
    "# encoded = Attention(units=500)(encoded)\n",
    "\n",
    "z_mean = Dense(latent_dim)(encoded)\n",
    "z_log_sigma = Dense(latent_dim)(encoded)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(decoded)\n",
    "decoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(decoded)\n",
    "\n",
    "decoded = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "decoded = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "\n",
    "output_geohash = TimeDistributed(Dense(geohash_dim, kernel_initializer=he_uniform(), activation='sigmoid'), name='output_geohash')(decoded)\n",
    "output_hour = TimeDistributed(Dense(hour_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_hour')(decoded)\n",
    "output_geo_context = TimeDistributed(Dense(geographical_context_dim, kernel_initializer=he_uniform(), activation='tanh'), name='output_geo_context')(decoded)\n",
    "output_geo_type = TimeDistributed(Dense(geo_type_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_geo_type')(decoded)\n",
    "outputs = [output_geohash, output_hour, output_geo_context, output_geo_type]\n",
    "\n",
    "outputs = Concatenate(axis=2)(outputs)\n",
    "\n",
    "# d_4 = Dense(units=2000, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "# d_5 = Dense(units=500, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(d_4)\n",
    "# d_6 = Dense(units=500, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(d_5)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, outputs)\n",
    "encoder = keras.Model(inputs, encoded)\n",
    "decoder = keras.Model(encoded, outputs)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# sequence_autoencoder.compile(optimizer='adam', \n",
    "#                              metrics=['accuracy'],\n",
    "#                             loss={'output_geohash': 'binary_crossentropy', 'output_hour': 'categorical_crossentropy', 'output_geo_context': 'mse', 'output_geo_type': 'categorical_crossentropy'})\n",
    "\n",
    "sequence_autoencoder.compile(optimizer='adam', \n",
    "                             metrics=['accuracy'],\n",
    "                            loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8714ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 36, 80)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 36, 128)      10368       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 36, 256)      33024       ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_12 (Bidirectiona  (None, 36, 1000)    2274000     ['dense_31[0][0]']               \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_13 (Bidirectiona  (None, 1000)        4506000     ['bidirectional_12[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 36, 1000)    0           ['bidirectional_13[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_14 (Bidirectiona  (None, 36, 1000)    4506000     ['repeat_vector_3[0][0]']        \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_15 (Bidirectiona  (None, 36, 1000)    4506000     ['bidirectional_14[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 36, 256)      256256      ['bidirectional_15[0][0]']       \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 36, 128)      32896       ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " output_geohash (TimeDistribute  (None, 36, 40)      5160        ['dense_35[0][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " output_hour (TimeDistributed)  (None, 36, 23)       2967        ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " output_geo_context (TimeDistri  (None, 36, 10)      1290        ['dense_35[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " output_geo_type (TimeDistribut  (None, 36, 7)       903         ['dense_35[0][0]']               \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 36, 80)       0           ['output_geohash[0][0]',         \n",
      "                                                                  'output_hour[0][0]',            \n",
      "                                                                  'output_geo_context[0][0]',     \n",
      "                                                                  'output_geo_type[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,134,864\n",
      "Trainable params: 16,134,864\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1503eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 10s 55ms/step - loss: 2244.1433 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1654.4951 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1197.2808 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 850.8095 - accuracy: 1.5027e-04\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 593.3475 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 407.3020 - accuracy: 0.0027\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 275.9765 - accuracy: 0.0051\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 185.5991 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 123.7784 - accuracy: 2.1467e-05\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 83.7330 - accuracy: 0.0039\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 58.0958 - accuracy: 0.0339\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 41.7481 - accuracy: 0.0039\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 31.3922 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 25.1122 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 21.4234 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 19.0124 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 17.3386 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 16.4388 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 15.9065 - accuracy: 0.0043\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 15.5416 - accuracy: 0.0094\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.2753 - accuracy: 0.0019\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.3207 - accuracy: 8.5866e-04\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.2704 - accuracy: 0.0018\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0607 - accuracy: 0.0019\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 14.9203 - accuracy: 4.2933e-05\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0715 - accuracy: 0.0030\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9758 - accuracy: 8.5866e-05\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0501 - accuracy: 0.0024\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0982 - accuracy: 0.0022\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.0172 - accuracy: 0.0017\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0471 - accuracy: 4.2933e-04\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0130 - accuracy: 0.0041\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9369 - accuracy: 9.8746e-04\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9259 - accuracy: 0.0089\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0268 - accuracy: 0.0046\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.1643 - accuracy: 0.0120\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9838 - accuracy: 0.0046\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9924 - accuracy: 0.0035\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9983 - accuracy: 0.0034\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9594 - accuracy: 0.0015\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9083 - accuracy: 0.0019\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9844 - accuracy: 0.0017\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.2006 - accuracy: 0.0038\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0704 - accuracy: 0.0030\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8793 - accuracy: 2.5760e-04\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9671 - accuracy: 0.0019\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9587 - accuracy: 5.3666e-04\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0323 - accuracy: 0.0011\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9962 - accuracy: 6.2253e-04\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0113 - accuracy: 9.6600e-04\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0098 - accuracy: 2.1467e-04\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0007 - accuracy: 5.1520e-04\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9872 - accuracy: 6.0106e-04\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9235 - accuracy: 4.2933e-04\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9653 - accuracy: 0.0016\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0630 - accuracy: 2.1467e-04\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9562 - accuracy: 0.0012\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0165 - accuracy: 5.7960e-04\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0665 - accuracy: 1.9320e-04\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9328 - accuracy: 1.7173e-04\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8668 - accuracy: 4.2933e-04\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9986 - accuracy: 1.0733e-04\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0840 - accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0068 - accuracy: 8.5866e-05\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9036 - accuracy: 7.7280e-04\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0407 - accuracy: 8.1573e-04\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9759 - accuracy: 0.0016\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9847 - accuracy: 0.0027\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8704 - accuracy: 0.0019\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9351 - accuracy: 0.0035\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0793 - accuracy: 0.0016\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0523 - accuracy: 8.8013e-04\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0277 - accuracy: 0.0017\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9165 - accuracy: 0.0018\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8608 - accuracy: 0.0042\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0384 - accuracy: 0.0025\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9781 - accuracy: 0.0027\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0232 - accuracy: 0.0015\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0060 - accuracy: 0.0043\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9523 - accuracy: 0.0022\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8668 - accuracy: 0.0026\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9398 - accuracy: 0.0019\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0836 - accuracy: 0.0017\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9970 - accuracy: 0.0027\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9309 - accuracy: 0.0046\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9936 - accuracy: 0.0028\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9597 - accuracy: 0.0028\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9938 - accuracy: 0.0031\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9040 - accuracy: 0.0031\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9080 - accuracy: 0.0039\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0235 - accuracy: 0.0064\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0777 - accuracy: 0.0038\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9546 - accuracy: 0.0049\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8927 - accuracy: 0.0043\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9645 - accuracy: 0.0050\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0297 - accuracy: 0.0021\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8652 - accuracy: 0.0055\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9526 - accuracy: 0.0048\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0473 - accuracy: 0.0039\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0008 - accuracy: 0.0044\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9091 - accuracy: 0.0029\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9348 - accuracy: 0.0038\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0171 - accuracy: 0.0031\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9419 - accuracy: 0.0056\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8498 - accuracy: 0.0041\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0683 - accuracy: 0.0042\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0025 - accuracy: 0.0061\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9506 - accuracy: 0.0035\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8981 - accuracy: 0.0059\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9265 - accuracy: 0.0055\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9459 - accuracy: 0.0049\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9906 - accuracy: 0.0074\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0722 - accuracy: 0.0076\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9403 - accuracy: 0.0070\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9246 - accuracy: 0.0072\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9648 - accuracy: 0.0080\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8305 - accuracy: 0.0095\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9523 - accuracy: 0.0067\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0558 - accuracy: 0.0068\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0158 - accuracy: 0.0064\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9144 - accuracy: 0.0104\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9391 - accuracy: 0.0095\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9941 - accuracy: 0.0100\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9133 - accuracy: 0.0102\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8517 - accuracy: 0.0091\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0217 - accuracy: 0.0151\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0383 - accuracy: 0.0117\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0306 - accuracy: 0.0110\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8653 - accuracy: 0.0109\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8415 - accuracy: 0.0109\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9263 - accuracy: 0.0068\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0196 - accuracy: 0.0093\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0120 - accuracy: 0.0126\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9781 - accuracy: 0.0103\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9197 - accuracy: 0.0100\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9898 - accuracy: 0.0131\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8390 - accuracy: 0.0138\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8941 - accuracy: 0.0144\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0114 - accuracy: 0.0175\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9824 - accuracy: 0.0203\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9268 - accuracy: 0.0230\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9651 - accuracy: 0.0300\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0731 - accuracy: 0.0292\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8789 - accuracy: 0.0269\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7875 - accuracy: 0.0238\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9901 - accuracy: 0.0222\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9623 - accuracy: 0.0284\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0271 - accuracy: 0.0311\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9314 - accuracy: 0.0291\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9057 - accuracy: 0.0289\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9550 - accuracy: 0.0360\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9635 - accuracy: 0.0378\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9009 - accuracy: 0.0392\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9241 - accuracy: 0.0266\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9990 - accuracy: 0.0150\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0429 - accuracy: 0.0180\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8903 - accuracy: 0.0102\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9053 - accuracy: 0.0095\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8954 - accuracy: 0.0088\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9192 - accuracy: 0.0086\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9663 - accuracy: 0.0081\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0297 - accuracy: 0.0102\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0390 - accuracy: 0.0079\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8965 - accuracy: 0.0111\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7887 - accuracy: 0.0076\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9181 - accuracy: 0.0065\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9249 - accuracy: 0.0079\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0028 - accuracy: 0.0056\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0040 - accuracy: 0.0052\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9410 - accuracy: 0.0079\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9312 - accuracy: 0.0100\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9222 - accuracy: 0.0107\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8865 - accuracy: 0.0122\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8628 - accuracy: 0.0155\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9498 - accuracy: 0.0177\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0986 - accuracy: 0.0202\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8520 - accuracy: 0.0252\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9109 - accuracy: 0.0333\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9839 - accuracy: 0.0383\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9145 - accuracy: 0.0373\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8217 - accuracy: 0.0491\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9190 - accuracy: 0.0466\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0769 - accuracy: 0.0479\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9633 - accuracy: 0.0515\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8481 - accuracy: 0.0605\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9140 - accuracy: 0.0579\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9114 - accuracy: 0.0625\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9591 - accuracy: 0.0668\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8775 - accuracy: 0.0741\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9606 - accuracy: 0.0821\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0022 - accuracy: 0.0815\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9377 - accuracy: 0.0834\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9060 - accuracy: 0.0939\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8601 - accuracy: 0.0973\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8485 - accuracy: 0.0981\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0054 - accuracy: 0.0996\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9530 - accuracy: 0.1020\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9815 - accuracy: 0.1000\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9711 - accuracy: 0.1048\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8728 - accuracy: 0.1089\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7788 - accuracy: 0.1110\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9230 - accuracy: 0.1095\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0574 - accuracy: 0.0882\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9837 - accuracy: 0.0907\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8511 - accuracy: 0.0906\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9486 - accuracy: 0.0862\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8854 - accuracy: 0.0852\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9320 - accuracy: 0.0909\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.8924 - accuracy: 0.0932\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.8923 - accuracy: 0.0936\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9935 - accuracy: 0.0985\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9857 - accuracy: 0.1059\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9475 - accuracy: 0.1041\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8399 - accuracy: 0.1041\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8592 - accuracy: 0.0997\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9803 - accuracy: 0.0857\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8876 - accuracy: 0.0739\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9728 - accuracy: 0.0540\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9584 - accuracy: 0.0406\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9224 - accuracy: 0.0437\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8627 - accuracy: 0.0471\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8982 - accuracy: 0.0609\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9887 - accuracy: 0.0704\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9170 - accuracy: 0.0793\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8260 - accuracy: 0.0770\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9732 - accuracy: 0.0741\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9904 - accuracy: 0.0720\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9338 - accuracy: 0.0568\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8210 - accuracy: 0.0562\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9006 - accuracy: 0.0649\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9502 - accuracy: 0.0703\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9920 - accuracy: 0.0782\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9294 - accuracy: 0.0719\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8514 - accuracy: 0.0750\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8865 - accuracy: 0.0795\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9797 - accuracy: 0.0750\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7958 - accuracy: 0.0752\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9312 - accuracy: 0.0811\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0481 - accuracy: 0.0825\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9274 - accuracy: 0.0850\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8572 - accuracy: 0.0942\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8958 - accuracy: 0.0992\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9244 - accuracy: 0.0993\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8743 - accuracy: 0.1047\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8569 - accuracy: 0.1103\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0170 - accuracy: 0.1166\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9573 - accuracy: 0.1222\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9329 - accuracy: 0.1260\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8480 - accuracy: 0.1253\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8365 - accuracy: 0.1274\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8893 - accuracy: 0.1294\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9540 - accuracy: 0.1338\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0196 - accuracy: 0.1389\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8862 - accuracy: 0.1401\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8481 - accuracy: 0.1402\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9617 - accuracy: 0.1453\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8231 - accuracy: 0.1461\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9176 - accuracy: 0.1489\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9882 - accuracy: 0.1482\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9764 - accuracy: 0.1502\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8071 - accuracy: 0.1503\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8552 - accuracy: 0.1505\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9737 - accuracy: 0.1491\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9113 - accuracy: 0.1472\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8177 - accuracy: 0.1466\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9754 - accuracy: 0.1489\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9663 - accuracy: 0.1499\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9538 - accuracy: 0.1493\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8741 - accuracy: 0.1514\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8185 - accuracy: 0.1547\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8962 - accuracy: 0.1541\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9453 - accuracy: 0.1565\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9126 - accuracy: 0.1558\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9064 - accuracy: 0.1557\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9352 - accuracy: 0.1560\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9601 - accuracy: 0.1582\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8039 - accuracy: 0.1590\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8959 - accuracy: 0.1610\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9210 - accuracy: 0.1617\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9048 - accuracy: 0.1634\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9269 - accuracy: 0.1645\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9401 - accuracy: 0.1639\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9906 - accuracy: 0.1634\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8455 - accuracy: 0.1619\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7181 - accuracy: 0.1526\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9606 - accuracy: 0.1507\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9917 - accuracy: 0.1501\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0011 - accuracy: 0.1471\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8733 - accuracy: 0.1464\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8456 - accuracy: 0.1463\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8659 - accuracy: 0.1482\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9096 - accuracy: 0.1483\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9241 - accuracy: 0.1510\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8788 - accuracy: 0.1541\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9540 - accuracy: 0.1537\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0067 - accuracy: 0.1516\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8213 - accuracy: 0.1454\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8466 - accuracy: 0.1432\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8929 - accuracy: 0.1411\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9074 - accuracy: 0.1446\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8892 - accuracy: 0.1421\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9569 - accuracy: 0.1464\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9655 - accuracy: 0.1502\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8992 - accuracy: 0.1527\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7928 - accuracy: 0.1550\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9013 - accuracy: 0.1556\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8827 - accuracy: 0.1548\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9730 - accuracy: 0.1552\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9042 - accuracy: 0.1539\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8883 - accuracy: 0.1518\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9311 - accuracy: 0.1553\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8788 - accuracy: 0.1580\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8431 - accuracy: 0.1576\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8513 - accuracy: 0.1580\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9259 - accuracy: 0.1592\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0407 - accuracy: 0.1625\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8667 - accuracy: 0.1584\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8691 - accuracy: 0.1569\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9168 - accuracy: 0.1552\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8450 - accuracy: 0.1554\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7762 - accuracy: 0.1572\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9129 - accuracy: 0.1580\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0951 - accuracy: 0.1584\n",
      "Epoch 324/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9101 - accuracy: 0.1590\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8034 - accuracy: 0.1607\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9186 - accuracy: 0.1620\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8346 - accuracy: 0.1613\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9004 - accuracy: 0.1624\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8887 - accuracy: 0.1615\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9489 - accuracy: 0.1623\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9195 - accuracy: 0.1617\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9108 - accuracy: 0.1632\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8541 - accuracy: 0.1631\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8438 - accuracy: 0.1617\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8616 - accuracy: 0.1638\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9699 - accuracy: 0.1636\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9101 - accuracy: 0.1606\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9381 - accuracy: 0.1615\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8979 - accuracy: 0.1585\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8420 - accuracy: 0.1590\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7986 - accuracy: 0.1507\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8810 - accuracy: 0.1426\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0247 - accuracy: 0.1425\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9700 - accuracy: 0.1450\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7963 - accuracy: 0.1397\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8970 - accuracy: 0.1287\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9043 - accuracy: 0.1115\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9189 - accuracy: 0.0885\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8449 - accuracy: 0.0923\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8462 - accuracy: 0.0820\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9386 - accuracy: 0.0943\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9689 - accuracy: 0.0974\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9293 - accuracy: 0.1102\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8025 - accuracy: 0.1064\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8288 - accuracy: 0.1146\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9642 - accuracy: 0.1203\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8202 - accuracy: 0.1231\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9201 - accuracy: 0.1276\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9733 - accuracy: 0.1324\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8999 - accuracy: 0.1388\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8063 - accuracy: 0.1428\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8622 - accuracy: 0.1459\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9258 - accuracy: 0.1483\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8724 - accuracy: 0.1480\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8454 - accuracy: 0.1517\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9777 - accuracy: 0.1526\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9380 - accuracy: 0.1488\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8910 - accuracy: 0.1408\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7675 - accuracy: 0.1401\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8357 - accuracy: 0.1402\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9395 - accuracy: 0.1366\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9755 - accuracy: 0.1351\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9201 - accuracy: 0.1356\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8572 - accuracy: 0.1308\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8194 - accuracy: 0.1258\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9197 - accuracy: 0.1265\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8172 - accuracy: 0.1251\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9013 - accuracy: 0.1308\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9875 - accuracy: 0.1356\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9042 - accuracy: 0.1395\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8107 - accuracy: 0.1396\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8502 - accuracy: 0.1462\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9523 - accuracy: 0.1482\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8714 - accuracy: 0.1485\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8250 - accuracy: 0.1511\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9819 - accuracy: 0.1488\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8596 - accuracy: 0.1492\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8979 - accuracy: 0.1516\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8480 - accuracy: 0.1468\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8198 - accuracy: 0.1443\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8875 - accuracy: 0.1440\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9497 - accuracy: 0.1399\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9263 - accuracy: 0.1388\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8533 - accuracy: 0.1376\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8927 - accuracy: 0.1382\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9338 - accuracy: 0.1396\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7644 - accuracy: 0.1426\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8676 - accuracy: 0.1414\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9289 - accuracy: 0.1473\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9435 - accuracy: 0.1482\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8375 - accuracy: 0.1512\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8545 - accuracy: 0.1536\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9707 - accuracy: 0.1571\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8622 - accuracy: 0.1583\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7221 - accuracy: 0.1595\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9227 - accuracy: 0.1623\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9694 - accuracy: 0.1624\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9210 - accuracy: 0.1613\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8306 - accuracy: 0.1615\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8239 - accuracy: 0.1613\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8505 - accuracy: 0.1611\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9289 - accuracy: 0.1604\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9354 - accuracy: 0.1580\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9032 - accuracy: 0.1581\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9032 - accuracy: 0.1581\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8462 - accuracy: 0.1592\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9001 - accuracy: 0.1570\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7694 - accuracy: 0.1551\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8845 - accuracy: 0.1457\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9192 - accuracy: 0.1517\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8876 - accuracy: 0.1228\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8966 - accuracy: 0.1119\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9186 - accuracy: 0.1180\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9471 - accuracy: 0.1217\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8043 - accuracy: 0.1250\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.7656 - accuracy: 0.1267\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9105 - accuracy: 0.1346\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9076 - accuracy: 0.1332\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9615 - accuracy: 0.1334\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8454 - accuracy: 0.1372\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8228 - accuracy: 0.1392\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8801 - accuracy: 0.1367\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.8929 - accuracy: 0.1340\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 14.8665 - accuracy: 0.1376\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8560 - accuracy: 0.1366\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8953 - accuracy: 0.1270\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9793 - accuracy: 0.1302\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8217 - accuracy: 0.1261\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8257 - accuracy: 0.1207\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8639 - accuracy: 0.1280\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9111 - accuracy: 0.1280\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8117 - accuracy: 0.1330\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9170 - accuracy: 0.1361\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9781 - accuracy: 0.1417\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8426 - accuracy: 0.1414\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7463 - accuracy: 0.1491\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8815 - accuracy: 0.1525\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8641 - accuracy: 0.1536\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9269 - accuracy: 0.1580\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9111 - accuracy: 0.1619\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8509 - accuracy: 0.1616\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9231 - accuracy: 0.1634\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8613 - accuracy: 0.1643\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7771 - accuracy: 0.1659\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8116 - accuracy: 0.1668\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9178 - accuracy: 0.1674\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0097 - accuracy: 0.1691\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8278 - accuracy: 0.1693\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8558 - accuracy: 0.1686\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8499 - accuracy: 0.1658\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8315 - accuracy: 0.1673\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8044 - accuracy: 0.1658\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9150 - accuracy: 0.1575\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0340 - accuracy: 0.1578\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8970 - accuracy: 0.1604\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7442 - accuracy: 0.1631\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8557 - accuracy: 0.1580\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8257 - accuracy: 0.1542\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9035 - accuracy: 0.1514\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8958 - accuracy: 0.1462\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9163 - accuracy: 0.1468\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8665 - accuracy: 0.1447\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8663 - accuracy: 0.1444\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8840 - accuracy: 0.1446\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8078 - accuracy: 0.1520\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8144 - accuracy: 0.1577\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9501 - accuracy: 0.1603\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8450 - accuracy: 0.1619\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8794 - accuracy: 0.1629\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9336 - accuracy: 0.1608\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8514 - accuracy: 0.1625\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7624 - accuracy: 0.1632\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8542 - accuracy: 0.1643\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9560 - accuracy: 0.1659\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9273 - accuracy: 0.1666\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7889 - accuracy: 0.1647\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8842 - accuracy: 0.1673\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8692 - accuracy: 0.1672\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8756 - accuracy: 0.1688\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7521 - accuracy: 0.1696\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8421 - accuracy: 0.1707\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9889 - accuracy: 0.1718\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9320 - accuracy: 0.1728\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8735 - accuracy: 0.1726\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7841 - accuracy: 0.1738\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7685 - accuracy: 0.1752\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9174 - accuracy: 0.1760\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8351 - accuracy: 0.1762\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9315 - accuracy: 0.1768\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9491 - accuracy: 0.1773\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8587 - accuracy: 0.1779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1698aa66d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_autoencoder.fit(X, X,\n",
    "                epochs=500,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53891a2",
   "metadata": {},
   "source": [
    "## Evaluation & Simple Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce04c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of persons in data 72\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import attack\n",
    "import geopandas as gp\n",
    "gdf = gp.read_file('../data/freemove/raw_full.geojson', crs='EPSG:4326')\n",
    "gdf = gdf[gdf['TRIP_ID'].isin(points.TRIP_ID)]\n",
    "true_mapping = gdf[['TRIP_ID', 'PERSON_ID']].sort_values('TRIP_ID').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print('Number of persons in data', points.PERSON_ID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bddd3cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 10ms/step\n",
      "Homogeneity: 0.022\n",
      "Completeness: 0.234\n",
      "V-measure: 0.040\n",
      "Rand index: 0.207\n",
      "ARI: 0.001\n",
      "MI: 0.085\n",
      "NMI: 0.040\n",
      "AMI: 0.021\n",
      "Cluster accuracy: 0.068\n",
      "Homogeneity: 0.536\n",
      "Completeness: 0.497\n",
      "V-measure: 0.516\n",
      "Rand index: 0.967\n",
      "ARI: 0.142\n",
      "MI: 2.090\n",
      "NMI: 0.516\n",
      "AMI: 0.306\n",
      "Cluster accuracy: 0.278\n",
      "Homogeneity: 0.000\n",
      "Completeness: 1.000\n",
      "V-measure: 0.000\n",
      "Rand index: 0.024\n",
      "ARI: 0.000\n",
      "MI: 0.000\n",
      "NMI: 0.000\n",
      "AMI: 0.000\n",
      "Cluster accuracy: 0.058\n"
     ]
    }
   ],
   "source": [
    "# Evaluate base line hdbscan\n",
    "y = attack.getGroundTruth(true_mapping)\n",
    "import hdbscan\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "pred = encoder.predict(X)\n",
    "\n",
    "h_dbscan = hdbscan.HDBSCAN()\n",
    "h_dbscan.fit(pred)\n",
    "\n",
    "kmeans = KMeans(n_clusters=72, random_state=0, n_init=20).fit(pred)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10).fit(pred)\n",
    "\n",
    "attack.evaluate(h_dbscan.labels_, true_mapping)\n",
    "attack.evaluate(kmeans.labels_, true_mapping)\n",
    "attack.evaluate(dbscan.labels_, true_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631b4a3",
   "metadata": {},
   "source": [
    "## DETECT Joint Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d7f782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, RepeatVector, GRU, Bidirectional, InputSpec\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class ClusteringLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "         Measure the similarity between embedded point z_i and centroid Âµ_j.\n",
    "                 q_ij = 1/(1+dist(x_i, Âµ_j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab6f0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d307f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 8000\n",
    "update_interval = 140\n",
    "index_array = np.arange(X.shape[0])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "tol = 0.001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca447eb3",
   "metadata": {},
   "source": [
    "# Simple (First train AE then refine Clustering with KLD loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36092ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize Clustering Layer KMEANS\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "N_CLUSTERS = 72\n",
    "\n",
    "# Build clustering model\n",
    "clustering_layer = ClusteringLayer(N_CLUSTERS, name='clustering')(encoder.output)\n",
    "model = keras.Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "model.compile(optimizer=opt, loss='kld')\n",
    "\n",
    "# Initialize cluster centers using k-means.\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(X))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "# Get labels (ground truth)\n",
    "y = attack.getGroundTruth(true_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4da1f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.28825, nmi = 0.53513, ari = 0.15959  ; loss= 0\n",
      "Iter 140: acc = 0.29289, nmi = 0.53364, ari = 0.15715  ; loss= 4.98642\n",
      "Iter 280: acc = 0.29598, nmi = 0.53360, ari = 0.15579  ; loss= 5.7236\n",
      "Iter 420: acc = 0.28516, nmi = 0.52341, ari = 0.14236  ; loss= 6.825\n",
      "Iter 560: acc = 0.28748, nmi = 0.52328, ari = 0.14179  ; loss= 7.2276\n",
      "Iter 700: acc = 0.29134, nmi = 0.52612, ari = 0.14461  ; loss= 7.11497\n",
      "Iter 840: acc = 0.29134, nmi = 0.52285, ari = 0.14414  ; loss= 6.56727\n",
      "Iter 980: acc = 0.29134, nmi = 0.52282, ari = 0.14444  ; loss= 6.23553\n",
      "Iter 1120: acc = 0.29057, nmi = 0.52283, ari = 0.14461  ; loss= 7.44327\n",
      "Iter 1260: acc = 0.29212, nmi = 0.52328, ari = 0.14568  ; loss= 6.62974\n",
      "Iter 1400: acc = 0.29212, nmi = 0.52262, ari = 0.14502  ; loss= 5.9629\n",
      "Iter 1540: acc = 0.29212, nmi = 0.52307, ari = 0.14430  ; loss= 6.27522\n",
      "Iter 1680: acc = 0.28825, nmi = 0.52183, ari = 0.14330  ; loss= 6.64078\n",
      "Iter 1820: acc = 0.29134, nmi = 0.52427, ari = 0.14427  ; loss= 7.33977\n",
      "Iter 1960: acc = 0.29057, nmi = 0.52210, ari = 0.14224  ; loss= 7.02252\n",
      "Iter 2100: acc = 0.28980, nmi = 0.52289, ari = 0.14304  ; loss= 6.46347\n",
      "Iter 2240: acc = 0.29134, nmi = 0.52330, ari = 0.14291  ; loss= 6.17009\n",
      "Iter 2380: acc = 0.28980, nmi = 0.52190, ari = 0.14230  ; loss= 7.23591\n",
      "Iter 2520: acc = 0.28980, nmi = 0.52423, ari = 0.14371  ; loss= 6.46483\n",
      "Iter 2660: acc = 0.28980, nmi = 0.52385, ari = 0.14405  ; loss= 6.32802\n",
      "Iter 2800: acc = 0.28980, nmi = 0.52360, ari = 0.14328  ; loss= 6.27149\n",
      "Iter 2940: acc = 0.29057, nmi = 0.52431, ari = 0.14370  ; loss= 6.76694\n",
      "Iter 3080: acc = 0.28980, nmi = 0.52385, ari = 0.14354  ; loss= 7.05806\n",
      "Iter 3220: acc = 0.29057, nmi = 0.52432, ari = 0.14434  ; loss= 6.99158\n",
      "Iter 3360: acc = 0.28980, nmi = 0.52421, ari = 0.14406  ; loss= 6.58173\n",
      "Iter 3500: acc = 0.28980, nmi = 0.52417, ari = 0.14423  ; loss= 6.43713\n",
      "Iter 3640: acc = 0.28980, nmi = 0.52429, ari = 0.14390  ; loss= 7.04194\n",
      "Iter 3780: acc = 0.28980, nmi = 0.52427, ari = 0.14368  ; loss= 6.53615\n",
      "Iter 3920: acc = 0.28903, nmi = 0.52422, ari = 0.14392  ; loss= 6.05832\n",
      "Iter 4060: acc = 0.28980, nmi = 0.52424, ari = 0.14418  ; loss= 6.33011\n",
      "Iter 4200: acc = 0.28903, nmi = 0.52443, ari = 0.14419  ; loss= 6.82833\n",
      "Iter 4340: acc = 0.29057, nmi = 0.52479, ari = 0.14469  ; loss= 7.03064\n",
      "Iter 4480: acc = 0.28980, nmi = 0.52356, ari = 0.14349  ; loss= 6.76624\n",
      "Iter 4620: acc = 0.29057, nmi = 0.52477, ari = 0.14467  ; loss= 6.40049\n",
      "Iter 4760: acc = 0.29057, nmi = 0.52442, ari = 0.14457  ; loss= 6.06934\n",
      "Iter 4900: acc = 0.28980, nmi = 0.52405, ari = 0.14446  ; loss= 7.23294\n",
      "Iter 5040: acc = 0.28980, nmi = 0.52288, ari = 0.14295  ; loss= 6.3886\n",
      "Iter 5180: acc = 0.28980, nmi = 0.52429, ari = 0.14422  ; loss= 6.06386\n",
      "Iter 5320: acc = 0.28825, nmi = 0.52365, ari = 0.14358  ; loss= 6.24453\n",
      "Iter 5460: acc = 0.28980, nmi = 0.52396, ari = 0.14372  ; loss= 6.75262\n",
      "Iter 5600: acc = 0.28980, nmi = 0.52437, ari = 0.14435  ; loss= 7.05429\n",
      "Iter 5740: acc = 0.28980, nmi = 0.52469, ari = 0.14462  ; loss= 7.12068\n",
      "Iter 5880: acc = 0.28980, nmi = 0.52288, ari = 0.14295  ; loss= 6.33483\n",
      "Iter 6020: acc = 0.28903, nmi = 0.52424, ari = 0.14388  ; loss= 6.23194\n",
      "Iter 6160: acc = 0.28980, nmi = 0.52432, ari = 0.14451  ; loss= 6.88296\n",
      "Iter 6300: acc = 0.28825, nmi = 0.52426, ari = 0.14423  ; loss= 6.41322\n",
      "Iter 6440: acc = 0.28903, nmi = 0.52411, ari = 0.14393  ; loss= 6.14249\n",
      "Iter 6580: acc = 0.29057, nmi = 0.52392, ari = 0.14386  ; loss= 6.28535\n",
      "Iter 6720: acc = 0.29057, nmi = 0.52444, ari = 0.14514  ; loss= 6.5533\n",
      "Iter 6860: acc = 0.28980, nmi = 0.52480, ari = 0.14506  ; loss= 6.98347\n",
      "Iter 7000: acc = 0.29057, nmi = 0.52360, ari = 0.14375  ; loss= 6.76285\n",
      "Iter 7140: acc = 0.29057, nmi = 0.52427, ari = 0.14403  ; loss= 6.38115\n",
      "Iter 7280: acc = 0.28903, nmi = 0.52457, ari = 0.14412  ; loss= 6.23741\n",
      "Iter 7420: acc = 0.29134, nmi = 0.52486, ari = 0.14490  ; loss= 6.91365\n",
      "Iter 7560: acc = 0.29134, nmi = 0.52557, ari = 0.14519  ; loss= 6.33102\n",
      "Iter 7700: acc = 0.28980, nmi = 0.52449, ari = 0.14417  ; loss= 6.1211\n",
      "Iter 7840: acc = 0.29057, nmi = 0.52493, ari = 0.14499  ; loss= 6.18221\n",
      "Iter 7980: acc = 0.29057, nmi = 0.52514, ari = 0.14537  ; loss= 6.76614\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(X, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(attack.cluster_acc(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
    "    loss = model.train_on_batch(x=tf.gather(X, indices=idx), y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974a33a",
   "metadata": {},
   "source": [
    "# Advanced (Train AE and Clustering Simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865113d",
   "metadata": {},
   "source": [
    "**Important:** Do not forget to reinitialize the AE before running the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4126b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "N_CLUSTERS = 72\n",
    "\n",
    "# (re)initialize clustering layer\n",
    "clustering_layer = ClusteringLayer(N_CLUSTERS, name='clustering')(encoder.output)\n",
    "\n",
    "# Train AE and clustering layer at the same time\n",
    "model = keras.Model(inputs=inputs,\n",
    "            outputs=[clustering_layer, sequence_autoencoder.output])\n",
    "pretrain_optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ada9dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.10046, nmi = 0.14096, ari = 0.02553  ; loss= [14.77079  0.49049  0.02395]\n",
      "Iter 140: acc = 0.08578, nmi = 0.10227, ari = 0.00949  ; loss= [1.503691e+01 7.000000e-05 2.427000e-02]\n",
      "Iter 280: acc = 0.10046, nmi = 0.15124, ari = 0.02319  ; loss= [14.88898  0.       0.02138]\n",
      "Iter 420: acc = 0.10896, nmi = 0.17563, ari = 0.03253  ; loss= [1.484727e+01 1.000000e-05 2.219000e-02]\n",
      "Iter 560: acc = 0.13833, nmi = 0.23023, ari = 0.04790  ; loss= [1.498289e+01 1.000000e-05 1.916000e-02]\n",
      "Iter 700: acc = 0.19474, nmi = 0.32634, ari = 0.07177  ; loss= [1.481378e+01 3.000000e-05 1.844000e-02]\n",
      "Iter 840: acc = 0.20711, nmi = 0.37116, ari = 0.08635  ; loss= [1.501879e+01 5.000000e-05 1.900000e-02]\n",
      "Iter 980: acc = 0.20015, nmi = 0.36085, ari = 0.07436  ; loss= [1.491256e+01 1.800000e-04 1.703000e-02]\n",
      "Iter 1120: acc = 0.20170, nmi = 0.37403, ari = 0.06870  ; loss= [1.487374e+01 4.000000e-04 1.658000e-02]\n",
      "Iter 1260: acc = 0.21870, nmi = 0.40721, ari = 0.08320  ; loss= [1.483837e+01 2.600000e-03 1.695000e-02]\n",
      "Iter 1400: acc = 0.22798, nmi = 0.42813, ari = 0.08738  ; loss= [14.91216  0.01694  0.01498]\n",
      "Iter 1540: acc = 0.21638, nmi = 0.42942, ari = 0.09013  ; loss= [14.74854  0.07193  0.01684]\n",
      "Iter 1680: acc = 0.22102, nmi = 0.43673, ari = 0.09241  ; loss= [14.91447  0.21886  0.01838]\n",
      "Iter 1820: acc = 0.21716, nmi = 0.42840, ari = 0.08809  ; loss= [14.88429  0.28448  0.01615]\n",
      "Iter 1960: acc = 0.22643, nmi = 0.43310, ari = 0.09311  ; loss= [14.78851  0.33096  0.01901]\n",
      "Iter 2100: acc = 0.22179, nmi = 0.43413, ari = 0.09068  ; loss= [14.80235  0.32229  0.02046]\n",
      "Iter 2240: acc = 0.22334, nmi = 0.43243, ari = 0.09191  ; loss= [14.95177  0.4038   0.01766]\n",
      "Iter 2380: acc = 0.22334, nmi = 0.43278, ari = 0.09193  ; loss= [14.70428  0.33481  0.02018]\n",
      "Iter 2520: acc = 0.22411, nmi = 0.43780, ari = 0.09229  ; loss= [14.9068   0.39389  0.01929]\n",
      "Iter 2660: acc = 0.22334, nmi = 0.43840, ari = 0.09283  ; loss= [14.77852  0.3147   0.02067]\n",
      "Iter 2800: acc = 0.22488, nmi = 0.43865, ari = 0.09207  ; loss= [14.71756  0.33858  0.01736]\n",
      "Iter 2940: acc = 0.22334, nmi = 0.43805, ari = 0.09222  ; loss= [14.75786  0.3092   0.01995]\n",
      "Iter 3080: acc = 0.22411, nmi = 0.43979, ari = 0.09410  ; loss= [14.84454  0.32468  0.01871]\n",
      "Iter 3220: acc = 0.22411, nmi = 0.43762, ari = 0.09270  ; loss= [14.63301  0.3672   0.01792]\n",
      "Iter 3360: acc = 0.22720, nmi = 0.44085, ari = 0.09328  ; loss= [14.83338  0.27892  0.02123]\n",
      "Iter 3500: acc = 0.22488, nmi = 0.43873, ari = 0.09527  ; loss= [14.76404  0.30322  0.01944]\n",
      "Iter 3640: acc = 0.22643, nmi = 0.43691, ari = 0.09319  ; loss= [14.69468  0.27383  0.01792]\n",
      "Iter 3780: acc = 0.22566, nmi = 0.43768, ari = 0.09378  ; loss= [14.68664  0.25061  0.01761]\n",
      "Iter 3920: acc = 0.22875, nmi = 0.43929, ari = 0.09675  ; loss= [14.76744  0.24388  0.01479]\n",
      "Iter 4060: acc = 0.22334, nmi = 0.43722, ari = 0.09317  ; loss= [14.59313  0.22614  0.02234]\n",
      "Iter 4200: acc = 0.22798, nmi = 0.43651, ari = 0.09335  ; loss= [14.77721  0.22807  0.02024]\n",
      "Iter 4340: acc = 0.22566, nmi = 0.43797, ari = 0.09314  ; loss= [14.67547  0.21875  0.01553]\n",
      "Iter 4480: acc = 0.22411, nmi = 0.43917, ari = 0.09326  ; loss= [14.65285  0.22058  0.01545]\n",
      "Iter 4620: acc = 0.22875, nmi = 0.43390, ari = 0.09552  ; loss= [14.6736   0.25322  0.01991]\n",
      "Iter 4760: acc = 0.22720, nmi = 0.43719, ari = 0.09268  ; loss= [14.75696  0.19354  0.01872]\n",
      "Iter 4900: acc = 0.22488, nmi = 0.43884, ari = 0.09335  ; loss= [14.59383  0.21282  0.01977]\n",
      "Iter 5040: acc = 0.22798, nmi = 0.43780, ari = 0.09440  ; loss= [14.69937  0.22636  0.01548]\n",
      "Iter 5180: acc = 0.22643, nmi = 0.43886, ari = 0.09405  ; loss= [14.63543  0.20536  0.01743]\n",
      "Iter 5320: acc = 0.22334, nmi = 0.43663, ari = 0.09314  ; loss= [1.463985e+01 1.811700e-01 1.437000e-02]\n",
      "Iter 5460: acc = 0.22257, nmi = 0.43637, ari = 0.09312  ; loss= [14.62852  0.21708  0.021  ]\n",
      "Iter 5600: acc = 0.22720, nmi = 0.43923, ari = 0.09481  ; loss= [14.71292  0.18954  0.01721]\n",
      "Iter 5740: acc = 0.22643, nmi = 0.43487, ari = 0.09357  ; loss= [14.53532  0.18308  0.01572]\n",
      "Iter 5880: acc = 0.22488, nmi = 0.43576, ari = 0.09465  ; loss= [14.71671  0.18678  0.01751]\n",
      "Iter 6020: acc = 0.22643, nmi = 0.43695, ari = 0.09316  ; loss= [1.464714e+01 1.692100e-01 1.331000e-02]\n",
      "Iter 6160: acc = 0.22411, nmi = 0.43664, ari = 0.09321  ; loss= [14.62201  0.16434  0.01608]\n",
      "Iter 6300: acc = 0.22334, nmi = 0.43617, ari = 0.09374  ; loss= [14.60279  0.18731  0.01618]\n",
      "Iter 6440: acc = 0.22488, nmi = 0.43822, ari = 0.09529  ; loss= [1.467318e+01 1.597200e-01 1.246000e-02]\n",
      "Iter 6580: acc = 0.22566, nmi = 0.43733, ari = 0.09318  ; loss= [1.452107e+01 1.665000e-01 1.379000e-02]\n",
      "Iter 6720: acc = 0.22411, nmi = 0.43592, ari = 0.09329  ; loss= [1.466318e+01 1.759400e-01 1.424000e-02]\n",
      "Iter 6860: acc = 0.22643, nmi = 0.43808, ari = 0.09661  ; loss= [1.45949e+01 1.42990e-01 1.18500e-02]\n",
      "Iter 7000: acc = 0.22720, nmi = 0.43772, ari = 0.09466  ; loss= [1.457175e+01 1.946600e-01 1.297000e-02]\n",
      "Iter 7140: acc = 0.22488, nmi = 0.43586, ari = 0.09326  ; loss= [1.458593e+01 1.435300e-01 1.279000e-02]\n",
      "Iter 7280: acc = 0.22720, nmi = 0.43930, ari = 0.09564  ; loss= [1.471025e+01 1.725600e-01 1.112000e-02]\n",
      "Iter 7420: acc = 0.22720, nmi = 0.43549, ari = 0.09463  ; loss= [1.44955e+01 1.44240e-01 1.23200e-02]\n",
      "Iter 7560: acc = 0.22488, nmi = 0.43789, ari = 0.09361  ; loss= [1.46611e+01 1.41280e-01 1.37800e-02]\n",
      "Iter 7700: acc = 0.22643, nmi = 0.43811, ari = 0.09450  ; loss= [1.460281e+01 1.537400e-01 1.270000e-02]\n",
      "Iter 7840: acc = 0.22566, nmi = 0.43868, ari = 0.09431  ; loss= [1.454945e+01 1.472500e-01 1.130000e-02]\n",
      "Iter 7980: acc = 0.22643, nmi = 0.43257, ari = 0.09518  ; loss= [1.45775e+01 1.38840e-01 1.32300e-02]\n"
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(X, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(attack.cluster_acc(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
    "    loss = model.train_on_batch(x=tf.gather(X, indices=idx), y=[p[idx], tf.gather(X, indices=idx)])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "masterthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
