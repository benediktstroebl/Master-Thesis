{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b04802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:28:31.920158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 18:28:33.411017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.412196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.413761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.415299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.419221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.420371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.421918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.423444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.424980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.426109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.427632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.429162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.431279: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 18:28:33.440231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.441836: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.443369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.982407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.983990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.985542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-22 18:28:33.987056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38397 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import os\n",
    "from ast import literal_eval as make_tuple\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import skmob\n",
    "from skmob.tessellation import tilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c754cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_pickle('../data/freemove/freemove_point_geographical_context.pickle')\n",
    "points['lat'] = points.geometry.apply(lambda x: x.y)\n",
    "points['lng'] = points.geometry.apply(lambda x: x.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7d84ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geographical_context</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 14:59:24</td>\n",
       "      <td>POINT (13.31753 52.53094)</td>\n",
       "      <td>[0.36, 0.22, 0.04, 0.17, 0.46, 0.55, 0.01, 0.3...</td>\n",
       "      <td>52.530942</td>\n",
       "      <td>13.317532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:02:10</td>\n",
       "      <td>POINT (13.32791 52.53281)</td>\n",
       "      <td>[0.83, 0.35, 0.05, 0.4, 0.99, 0.84, 0.02, 0.27...</td>\n",
       "      <td>52.532806</td>\n",
       "      <td>13.327908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:10:39</td>\n",
       "      <td>POINT (13.36288 52.53582)</td>\n",
       "      <td>[0.18, 0.27, 0.03, 0.09, 0.49, 0.27, 0.16, 0.2...</td>\n",
       "      <td>52.535821</td>\n",
       "      <td>13.362884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:13:28</td>\n",
       "      <td>POINT (13.36931 52.52905)</td>\n",
       "      <td>[0.27, 0.4, 0.07, 0.16, 0.45, 0.53, 0.14, 0.19...</td>\n",
       "      <td>52.529052</td>\n",
       "      <td>13.369314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978933</td>\n",
       "      <td>17246</td>\n",
       "      <td>2022-10-21 15:16:03</td>\n",
       "      <td>POINT (13.36997 52.52837)</td>\n",
       "      <td>[0.26, 0.39, 0.08, 0.15, 0.43, 0.55, 0.25, 0.2...</td>\n",
       "      <td>52.528374</td>\n",
       "      <td>13.369971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12346</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:09:33</td>\n",
       "      <td>POINT (13.36541 52.47671)</td>\n",
       "      <td>[0.09, 0.26, 0.01, 0.03, 0.28, 0.34, 0.02, 0.0...</td>\n",
       "      <td>52.476712</td>\n",
       "      <td>13.365414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:15:28</td>\n",
       "      <td>POINT (13.35614 52.46070)</td>\n",
       "      <td>[0.02, 0.48, 0.0, 0.02, 1.0, 0.34, 0.15, 0.02,...</td>\n",
       "      <td>52.460702</td>\n",
       "      <td>13.356144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:17:07</td>\n",
       "      <td>POINT (13.35593 52.45973)</td>\n",
       "      <td>[0.02, 0.59, 0.0, 0.03, 1.0, 0.34, 0.22, 0.02,...</td>\n",
       "      <td>52.459734</td>\n",
       "      <td>13.355926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:19:27</td>\n",
       "      <td>POINT (13.35338 52.44808)</td>\n",
       "      <td>[0.29, 0.39, 0.0, 0.07, 0.3, 0.22, 0.16, 0.05,...</td>\n",
       "      <td>52.448084</td>\n",
       "      <td>13.353378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>1015191</td>\n",
       "      <td>16370</td>\n",
       "      <td>2022-11-17 22:20:54</td>\n",
       "      <td>POINT (13.35283 52.44752)</td>\n",
       "      <td>[0.73, 0.61, 0.0, 0.11, 0.46, 0.42, 0.2, 0.06,...</td>\n",
       "      <td>52.447518</td>\n",
       "      <td>13.352827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRIP_ID  PERSON_ID                TIME                   geometry  \\\n",
       "0       978933      17246 2022-10-21 14:59:24  POINT (13.31753 52.53094)   \n",
       "1       978933      17246 2022-10-21 15:02:10  POINT (13.32791 52.53281)   \n",
       "2       978933      17246 2022-10-21 15:10:39  POINT (13.36288 52.53582)   \n",
       "3       978933      17246 2022-10-21 15:13:28  POINT (13.36931 52.52905)   \n",
       "4       978933      17246 2022-10-21 15:16:03  POINT (13.36997 52.52837)   \n",
       "...        ...        ...                 ...                        ...   \n",
       "12346  1015191      16370 2022-11-17 22:09:33  POINT (13.36541 52.47671)   \n",
       "12347  1015191      16370 2022-11-17 22:15:28  POINT (13.35614 52.46070)   \n",
       "12348  1015191      16370 2022-11-17 22:17:07  POINT (13.35593 52.45973)   \n",
       "12349  1015191      16370 2022-11-17 22:19:27  POINT (13.35338 52.44808)   \n",
       "12350  1015191      16370 2022-11-17 22:20:54  POINT (13.35283 52.44752)   \n",
       "\n",
       "                                    geographical_context        lat        lng  \n",
       "0      [0.36, 0.22, 0.04, 0.17, 0.46, 0.55, 0.01, 0.3...  52.530942  13.317532  \n",
       "1      [0.83, 0.35, 0.05, 0.4, 0.99, 0.84, 0.02, 0.27...  52.532806  13.327908  \n",
       "2      [0.18, 0.27, 0.03, 0.09, 0.49, 0.27, 0.16, 0.2...  52.535821  13.362884  \n",
       "3      [0.27, 0.4, 0.07, 0.16, 0.45, 0.53, 0.14, 0.19...  52.529052  13.369314  \n",
       "4      [0.26, 0.39, 0.08, 0.15, 0.43, 0.55, 0.25, 0.2...  52.528374  13.369971  \n",
       "...                                                  ...        ...        ...  \n",
       "12346  [0.09, 0.26, 0.01, 0.03, 0.28, 0.34, 0.02, 0.0...  52.476712  13.365414  \n",
       "12347  [0.02, 0.48, 0.0, 0.02, 1.0, 0.34, 0.15, 0.02,...  52.460702  13.356144  \n",
       "12348  [0.02, 0.59, 0.0, 0.03, 1.0, 0.34, 0.22, 0.02,...  52.459734  13.355926  \n",
       "12349  [0.29, 0.39, 0.0, 0.07, 0.3, 0.22, 0.16, 0.05,...  52.448084  13.353378  \n",
       "12350  [0.73, 0.61, 0.0, 0.11, 0.46, 0.42, 0.2, 0.06,...  52.447518  13.352827  \n",
       "\n",
       "[12351 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247efab7",
   "metadata": {},
   "source": [
    "## Filter trajectories that lie outside of berlin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bec9cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3460: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/usr/local/lib/python3.8/dist-packages/skmob/core/trajectorydataframe.py:322: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: +init=epsg:4326 +type=crs\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  tile_ids = gpd.sjoin(gdf, tessellation, how=how, op='within')[[constants.TILE_ID]]\n"
     ]
    }
   ],
   "source": [
    "tessellation = tilers.tiler.get(\"squared\", base_shape='Berlin, Germany', meters=500)\n",
    "\n",
    "tdf = skmob.TrajDataFrame(points)\n",
    "mapped = tdf.mapping(tessellation, remove_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5714f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = set(points.index).difference(mapped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4ddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_traj_ids = []\n",
    "for i, point in points.iterrows():\n",
    "    if i in filtered_indices:\n",
    "        drop_traj_ids.append(point.TRIP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edf75b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drop_traj_ids) == len(points) - len(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063f1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = points.query('TRIP_ID not in @drop_traj_ids').reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581ce99",
   "metadata": {},
   "source": [
    "## Filter users with less than n trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4549938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "# Count the number of unique values for each ID\n",
    "unique_counts = points.groupby('PERSON_ID')['TRIP_ID'].nunique()\n",
    "# Filter out the IDs with less than n unique values\n",
    "filtered_ids = unique_counts[unique_counts >= n].index.tolist()\n",
    "points = points[points['PERSON_ID'].isin(filtered_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb9d7e",
   "metadata": {},
   "source": [
    "## Geo Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf74f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_points = points.groupby('TRIP_ID').count()['PERSON_ID'].max()\n",
    "geographical_context_dim = len(points['geographical_context'].iloc[0])\n",
    "\n",
    "X_geo_context = np.zeros((points.TRIP_ID.nunique(), max_points, geographical_context_dim))\n",
    "Y = np.zeros((points.TRIP_ID.nunique(),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888ff189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    # get the trajectory id\n",
    "    traj_id = traj[0]\n",
    "\n",
    "    # get the user id\n",
    "    user_id = traj[1]['PERSON_ID'].iloc[0]\n",
    "\n",
    "    Y[index] = user_id\n",
    "\n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geo_context[index, idx] = point['geographical_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe9e29da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 10) [[0.36 0.22 0.04 0.17 0.46 0.55 0.01 0.3  1.   0.02]\n",
      " [0.83 0.35 0.05 0.4  0.99 0.84 0.02 0.27 1.   0.01]\n",
      " [0.18 0.27 0.03 0.09 0.49 0.27 0.16 0.21 1.   0.01]\n",
      " [0.27 0.4  0.07 0.16 0.45 0.53 0.14 0.19 1.   0.  ]\n",
      " [0.26 0.39 0.08 0.15 0.43 0.55 0.25 0.2  1.   0.  ]\n",
      " [0.18 0.27 0.02 0.09 0.51 0.25 0.2  0.2  1.   0.01]\n",
      " [0.46 0.29 0.04 0.15 0.75 0.47 0.1  0.25 1.   0.03]\n",
      " [0.44 0.32 0.06 0.12 0.76 0.45 0.16 0.3  1.   0.04]\n",
      " [0.44 0.32 0.06 0.12 0.77 0.45 0.16 0.3  1.   0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geo_context.shape, X_geo_context[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df4044",
   "metadata": {},
   "source": [
    "## Geo type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8741c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b4f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_type = np.asarray(points.geographical_context.apply(lambda x: np.argmax(x)).tolist()).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7ba457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 4, 5, 6, 7, 8])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_geo_type = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc_geo_type.fit(geo_type)\n",
    "enc_geo_type.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfa3caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['geo_type'] = enc_geo_type.transform(geo_type).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8bf6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_type_dim = len(points['geo_type'].iloc[0])\n",
    "\n",
    "\n",
    "X_geo_type = np.zeros((points.TRIP_ID.nunique(), max_points, geo_type_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geo_type[index, idx, :] = point['geo_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19652710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 7) [[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geo_type.shape, X_geo_type[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf95d01",
   "metadata": {},
   "source": [
    "## Geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f07a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "357ad171",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['bin_geohash'] = points.geometry.apply(lambda x: geohash.bin_geohash(x.y, x.x, precision=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47011b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_dim = len(points['bin_geohash'].iloc[0])\n",
    "\n",
    "\n",
    "X_geohash = np.zeros((points.TRIP_ID.nunique(), max_points, geohash_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_geohash[index, idx, :] = point['bin_geohash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2452a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 40) [[1. 1. 0. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 1.]\n",
      " [1. 1. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_geohash.shape, X_geohash[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c1a10",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7252f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_time = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2513a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hour from TIME column and reshape to array wiht one feature\n",
    "hour = np.asarray(points.TIME.dt.hour).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84fa660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_time.fit(hour)\n",
    "enc_time.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3250537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points['hour'] = enc_time.transform(hour).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1e88499",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_dim = len(points['hour'].iloc[0])\n",
    "\n",
    "\n",
    "X_hour = np.zeros((points.TRIP_ID.nunique(), max_points, hour_dim))\n",
    "\n",
    "# convert points into numpy array for each trajectory\n",
    "for index, traj in enumerate(points.groupby('TRIP_ID')):    \n",
    "    for idx, point in traj[1].reset_index(drop=True).iterrows():\n",
    "        X_hour[index, idx, :] = point['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "661e2a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 36, 23) [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_hour.shape, X_hour[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd39eec",
   "metadata": {},
   "source": [
    "## Merge Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf7acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "keys = ['bin_geohash', 'hour', 'geographical_context', 'geo_type']\n",
    "\n",
    "X = [X_geohash, X_hour, X_geo_context, X_geo_type]\n",
    "\n",
    "vocab_size = []\n",
    "X = Concatenate(axis=2)(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07555905",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mattack\u001b[39;00m\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, X)\n\u001b[0;32m----> 6\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, attack\u001b[38;5;241m.\u001b[39mgetGroundTruth(\u001b[43mtrue_mapping\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('X.npy', X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80b77b",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aef66d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, RepeatVector, GRU, Embedding, Dense, TimeDistributed, Lambda, Bidirectional, Masking\n",
    "from keras.initializers import he_uniform\n",
    "from keras.regularizers import l1\n",
    "from attention import Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0b05bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500\n",
    "EMBEDDER_SIZE = 150\n",
    "timesteps = int(max_points)\n",
    "\n",
    "# input_geohash = keras.Input(shape=(timesteps,geohash_dim))\n",
    "# input_hour = keras.Input(shape=(timesteps,hour_dim))\n",
    "# input_geo_context = keras.Input(shape=(timesteps,geographical_context_dim))\n",
    "# input_geo_type = keras.Input(shape=(timesteps,geo_type_dim))\n",
    "\n",
    "# inputs = [input_geohash, input_hour, input_geo_context, input_geo_type]\n",
    "# hidden_input = Concatenate(axis=2)(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps,geohash_dim+hour_dim+geographical_context_dim+geo_type_dim))\n",
    "\n",
    "# masked = Masking(mask_value=0.,\n",
    "#                 input_shape=(timesteps, features))(inputs)\n",
    "\n",
    "# e_geohash = Embedding(geohash_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geohash')(input_geohash)\n",
    "# e_hour = Embedding(hour_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_hour')(input_hour)\n",
    "# e_geo_context = Embedding(geographical_context_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geo_context')(input_geo_context)\n",
    "# e_geo_type = Embedding(geo_type_dim,\n",
    "#                       EMBEDDER_SIZE,\n",
    "#                       input_length=timesteps,\n",
    "#                       name='e_geo_type')(input_geo_type)\n",
    "\n",
    "# e_geohash = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geohash)\n",
    "# e_hour = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_hour)\n",
    "# e_geo_context = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geo_context)\n",
    "# e_geo_type = Dense(units=EMBEDDER_SIZE, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(input_geo_type)\n",
    "\n",
    "# embeddings = [e_geohash, e_hour, e_geo_context, e_geo_type]\n",
    "# hidden_input = Concatenate(axis=2)(embeddings)\n",
    "\n",
    "encoded = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(inputs)\n",
    "encoded = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(encoded)\n",
    "\n",
    "encoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(encoded)\n",
    "encoded = Bidirectional(GRU(latent_dim, return_sequences=False, recurrent_regularizer=l1(0.02)))(encoded)\n",
    "\n",
    "# encoded = Attention(units=500)(encoded)\n",
    "\n",
    "z_mean = Dense(latent_dim)(encoded)\n",
    "z_log_sigma = Dense(latent_dim)(encoded)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(decoded)\n",
    "decoded = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))(decoded)\n",
    "\n",
    "decoded = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "decoded = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "\n",
    "output_geohash = TimeDistributed(Dense(geohash_dim, kernel_initializer=he_uniform(), activation='sigmoid'), name='output_geohash')(decoded)\n",
    "output_hour = TimeDistributed(Dense(hour_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_hour')(decoded)\n",
    "output_geo_context = TimeDistributed(Dense(geographical_context_dim, kernel_initializer=he_uniform(), activation='tanh'), name='output_geo_context')(decoded)\n",
    "output_geo_type = TimeDistributed(Dense(geo_type_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_geo_type')(decoded)\n",
    "outputs = [output_geohash, output_hour, output_geo_context, output_geo_type]\n",
    "\n",
    "outputs = Concatenate(axis=2)(outputs)\n",
    "\n",
    "# d_4 = Dense(units=2000, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(decoded)\n",
    "# d_5 = Dense(units=500, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(d_4)\n",
    "# d_6 = Dense(units=500, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))(d_5)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, outputs)\n",
    "encoder = keras.Model(inputs, encoded)\n",
    "decoder = keras.Model(encoded, outputs)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# sequence_autoencoder.compile(optimizer='adam', \n",
    "#                              metrics=['accuracy'],\n",
    "#                             loss={'output_geohash': 'binary_crossentropy', 'output_hour': 'categorical_crossentropy', 'output_geo_context': 'mse', 'output_geo_type': 'categorical_crossentropy'})\n",
    "\n",
    "sequence_autoencoder.compile(optimizer='adam', \n",
    "                             metrics=['accuracy'],\n",
    "                            loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8714ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 36, 80)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 36, 128)      10368       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 36, 256)      33024       ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_12 (Bidirectiona  (None, 36, 1000)    2274000     ['dense_31[0][0]']               \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_13 (Bidirectiona  (None, 1000)        4506000     ['bidirectional_12[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 36, 1000)    0           ['bidirectional_13[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_14 (Bidirectiona  (None, 36, 1000)    4506000     ['repeat_vector_3[0][0]']        \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_15 (Bidirectiona  (None, 36, 1000)    4506000     ['bidirectional_14[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 36, 256)      256256      ['bidirectional_15[0][0]']       \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 36, 128)      32896       ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " output_geohash (TimeDistribute  (None, 36, 40)      5160        ['dense_35[0][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " output_hour (TimeDistributed)  (None, 36, 23)       2967        ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " output_geo_context (TimeDistri  (None, 36, 10)      1290        ['dense_35[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " output_geo_type (TimeDistribut  (None, 36, 7)       903         ['dense_35[0][0]']               \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 36, 80)       0           ['output_geohash[0][0]',         \n",
      "                                                                  'output_hour[0][0]',            \n",
      "                                                                  'output_geo_context[0][0]',     \n",
      "                                                                  'output_geo_type[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,134,864\n",
      "Trainable params: 16,134,864\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1503eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 10s 55ms/step - loss: 2244.1433 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1654.4951 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1197.2808 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 850.8095 - accuracy: 1.5027e-04\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 593.3475 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 407.3020 - accuracy: 0.0027\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 275.9765 - accuracy: 0.0051\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 185.5991 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 123.7784 - accuracy: 2.1467e-05\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 83.7330 - accuracy: 0.0039\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 58.0958 - accuracy: 0.0339\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 41.7481 - accuracy: 0.0039\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 31.3922 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 25.1122 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 21.4234 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 19.0124 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 17.3386 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 16.4388 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 15.9065 - accuracy: 0.0043\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 15.5416 - accuracy: 0.0094\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.2753 - accuracy: 0.0019\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.3207 - accuracy: 8.5866e-04\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.2704 - accuracy: 0.0018\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0607 - accuracy: 0.0019\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 14.9203 - accuracy: 4.2933e-05\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0715 - accuracy: 0.0030\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9758 - accuracy: 8.5866e-05\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0501 - accuracy: 0.0024\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0982 - accuracy: 0.0022\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.0172 - accuracy: 0.0017\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0471 - accuracy: 4.2933e-04\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0130 - accuracy: 0.0041\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9369 - accuracy: 9.8746e-04\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9259 - accuracy: 0.0089\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0268 - accuracy: 0.0046\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.1643 - accuracy: 0.0120\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9838 - accuracy: 0.0046\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9924 - accuracy: 0.0035\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9983 - accuracy: 0.0034\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9594 - accuracy: 0.0015\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9083 - accuracy: 0.0019\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9844 - accuracy: 0.0017\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.2006 - accuracy: 0.0038\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0704 - accuracy: 0.0030\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8793 - accuracy: 2.5760e-04\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9671 - accuracy: 0.0019\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9587 - accuracy: 5.3666e-04\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0323 - accuracy: 0.0011\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9962 - accuracy: 6.2253e-04\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0113 - accuracy: 9.6600e-04\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0098 - accuracy: 2.1467e-04\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0007 - accuracy: 5.1520e-04\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9872 - accuracy: 6.0106e-04\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9235 - accuracy: 4.2933e-04\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9653 - accuracy: 0.0016\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0630 - accuracy: 2.1467e-04\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9562 - accuracy: 0.0012\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0165 - accuracy: 5.7960e-04\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0665 - accuracy: 1.9320e-04\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9328 - accuracy: 1.7173e-04\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8668 - accuracy: 4.2933e-04\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9986 - accuracy: 1.0733e-04\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0840 - accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0068 - accuracy: 8.5866e-05\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9036 - accuracy: 7.7280e-04\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0407 - accuracy: 8.1573e-04\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9759 - accuracy: 0.0016\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9847 - accuracy: 0.0027\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8704 - accuracy: 0.0019\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9351 - accuracy: 0.0035\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0793 - accuracy: 0.0016\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0523 - accuracy: 8.8013e-04\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0277 - accuracy: 0.0017\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9165 - accuracy: 0.0018\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8608 - accuracy: 0.0042\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0384 - accuracy: 0.0025\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9781 - accuracy: 0.0027\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0232 - accuracy: 0.0015\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0060 - accuracy: 0.0043\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9523 - accuracy: 0.0022\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8668 - accuracy: 0.0026\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9398 - accuracy: 0.0019\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0836 - accuracy: 0.0017\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9970 - accuracy: 0.0027\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9309 - accuracy: 0.0046\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9936 - accuracy: 0.0028\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9597 - accuracy: 0.0028\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9938 - accuracy: 0.0031\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9040 - accuracy: 0.0031\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9080 - accuracy: 0.0039\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0235 - accuracy: 0.0064\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0777 - accuracy: 0.0038\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9546 - accuracy: 0.0049\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8927 - accuracy: 0.0043\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9645 - accuracy: 0.0050\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0297 - accuracy: 0.0021\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8652 - accuracy: 0.0055\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9526 - accuracy: 0.0048\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0473 - accuracy: 0.0039\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0008 - accuracy: 0.0044\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9091 - accuracy: 0.0029\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9348 - accuracy: 0.0038\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0171 - accuracy: 0.0031\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9419 - accuracy: 0.0056\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8498 - accuracy: 0.0041\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0683 - accuracy: 0.0042\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0025 - accuracy: 0.0061\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9506 - accuracy: 0.0035\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8981 - accuracy: 0.0059\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9265 - accuracy: 0.0055\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9459 - accuracy: 0.0049\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9906 - accuracy: 0.0074\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0722 - accuracy: 0.0076\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9403 - accuracy: 0.0070\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9246 - accuracy: 0.0072\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9648 - accuracy: 0.0080\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8305 - accuracy: 0.0095\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9523 - accuracy: 0.0067\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0558 - accuracy: 0.0068\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0158 - accuracy: 0.0064\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9144 - accuracy: 0.0104\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9391 - accuracy: 0.0095\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9941 - accuracy: 0.0100\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9133 - accuracy: 0.0102\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8517 - accuracy: 0.0091\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0217 - accuracy: 0.0151\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0383 - accuracy: 0.0117\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0306 - accuracy: 0.0110\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8653 - accuracy: 0.0109\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8415 - accuracy: 0.0109\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9263 - accuracy: 0.0068\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0196 - accuracy: 0.0093\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0120 - accuracy: 0.0126\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9781 - accuracy: 0.0103\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9197 - accuracy: 0.0100\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9898 - accuracy: 0.0131\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8390 - accuracy: 0.0138\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8941 - accuracy: 0.0144\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0114 - accuracy: 0.0175\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9824 - accuracy: 0.0203\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9268 - accuracy: 0.0230\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9651 - accuracy: 0.0300\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0731 - accuracy: 0.0292\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8789 - accuracy: 0.0269\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7875 - accuracy: 0.0238\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9901 - accuracy: 0.0222\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9623 - accuracy: 0.0284\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0271 - accuracy: 0.0311\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9314 - accuracy: 0.0291\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9057 - accuracy: 0.0289\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9550 - accuracy: 0.0360\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9635 - accuracy: 0.0378\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9009 - accuracy: 0.0392\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9241 - accuracy: 0.0266\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9990 - accuracy: 0.0150\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0429 - accuracy: 0.0180\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8903 - accuracy: 0.0102\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9053 - accuracy: 0.0095\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8954 - accuracy: 0.0088\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9192 - accuracy: 0.0086\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9663 - accuracy: 0.0081\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0297 - accuracy: 0.0102\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0390 - accuracy: 0.0079\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8965 - accuracy: 0.0111\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7887 - accuracy: 0.0076\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9181 - accuracy: 0.0065\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9249 - accuracy: 0.0079\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0028 - accuracy: 0.0056\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0040 - accuracy: 0.0052\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9410 - accuracy: 0.0079\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9312 - accuracy: 0.0100\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9222 - accuracy: 0.0107\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8865 - accuracy: 0.0122\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8628 - accuracy: 0.0155\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9498 - accuracy: 0.0177\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0986 - accuracy: 0.0202\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8520 - accuracy: 0.0252\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9109 - accuracy: 0.0333\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9839 - accuracy: 0.0383\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9145 - accuracy: 0.0373\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8217 - accuracy: 0.0491\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9190 - accuracy: 0.0466\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0769 - accuracy: 0.0479\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9633 - accuracy: 0.0515\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8481 - accuracy: 0.0605\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9140 - accuracy: 0.0579\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9114 - accuracy: 0.0625\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9591 - accuracy: 0.0668\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8775 - accuracy: 0.0741\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9606 - accuracy: 0.0821\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0022 - accuracy: 0.0815\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9377 - accuracy: 0.0834\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9060 - accuracy: 0.0939\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8601 - accuracy: 0.0973\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8485 - accuracy: 0.0981\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0054 - accuracy: 0.0996\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9530 - accuracy: 0.1020\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9815 - accuracy: 0.1000\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9711 - accuracy: 0.1048\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8728 - accuracy: 0.1089\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7788 - accuracy: 0.1110\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9230 - accuracy: 0.1095\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0574 - accuracy: 0.0882\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9837 - accuracy: 0.0907\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8511 - accuracy: 0.0906\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9486 - accuracy: 0.0862\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8854 - accuracy: 0.0852\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9320 - accuracy: 0.0909\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.8924 - accuracy: 0.0932\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.8923 - accuracy: 0.0936\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9935 - accuracy: 0.0985\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9857 - accuracy: 0.1059\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9475 - accuracy: 0.1041\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8399 - accuracy: 0.1041\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8592 - accuracy: 0.0997\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9803 - accuracy: 0.0857\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8876 - accuracy: 0.0739\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9728 - accuracy: 0.0540\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9584 - accuracy: 0.0406\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9224 - accuracy: 0.0437\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8627 - accuracy: 0.0471\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8982 - accuracy: 0.0609\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9887 - accuracy: 0.0704\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9170 - accuracy: 0.0793\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8260 - accuracy: 0.0770\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9732 - accuracy: 0.0741\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9904 - accuracy: 0.0720\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9338 - accuracy: 0.0568\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8210 - accuracy: 0.0562\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9006 - accuracy: 0.0649\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9502 - accuracy: 0.0703\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9920 - accuracy: 0.0782\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9294 - accuracy: 0.0719\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8514 - accuracy: 0.0750\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8865 - accuracy: 0.0795\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9797 - accuracy: 0.0750\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7958 - accuracy: 0.0752\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9312 - accuracy: 0.0811\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0481 - accuracy: 0.0825\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9274 - accuracy: 0.0850\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8572 - accuracy: 0.0942\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8958 - accuracy: 0.0992\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9244 - accuracy: 0.0993\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8743 - accuracy: 0.1047\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8569 - accuracy: 0.1103\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0170 - accuracy: 0.1166\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9573 - accuracy: 0.1222\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9329 - accuracy: 0.1260\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8480 - accuracy: 0.1253\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8365 - accuracy: 0.1274\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8893 - accuracy: 0.1294\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9540 - accuracy: 0.1338\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0196 - accuracy: 0.1389\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8862 - accuracy: 0.1401\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8481 - accuracy: 0.1402\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9617 - accuracy: 0.1453\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8231 - accuracy: 0.1461\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9176 - accuracy: 0.1489\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9882 - accuracy: 0.1482\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9764 - accuracy: 0.1502\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8071 - accuracy: 0.1503\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8552 - accuracy: 0.1505\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9737 - accuracy: 0.1491\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9113 - accuracy: 0.1472\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8177 - accuracy: 0.1466\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9754 - accuracy: 0.1489\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9663 - accuracy: 0.1499\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9538 - accuracy: 0.1493\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8741 - accuracy: 0.1514\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8185 - accuracy: 0.1547\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8962 - accuracy: 0.1541\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9453 - accuracy: 0.1565\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9126 - accuracy: 0.1558\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9064 - accuracy: 0.1557\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9352 - accuracy: 0.1560\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9601 - accuracy: 0.1582\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8039 - accuracy: 0.1590\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8959 - accuracy: 0.1610\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9210 - accuracy: 0.1617\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9048 - accuracy: 0.1634\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9269 - accuracy: 0.1645\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9401 - accuracy: 0.1639\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9906 - accuracy: 0.1634\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8455 - accuracy: 0.1619\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7181 - accuracy: 0.1526\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9606 - accuracy: 0.1507\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9917 - accuracy: 0.1501\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0011 - accuracy: 0.1471\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8733 - accuracy: 0.1464\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8456 - accuracy: 0.1463\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8659 - accuracy: 0.1482\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9096 - accuracy: 0.1483\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9241 - accuracy: 0.1510\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8788 - accuracy: 0.1541\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9540 - accuracy: 0.1537\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0067 - accuracy: 0.1516\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8213 - accuracy: 0.1454\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8466 - accuracy: 0.1432\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8929 - accuracy: 0.1411\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9074 - accuracy: 0.1446\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8892 - accuracy: 0.1421\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9569 - accuracy: 0.1464\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9655 - accuracy: 0.1502\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8992 - accuracy: 0.1527\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7928 - accuracy: 0.1550\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9013 - accuracy: 0.1556\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8827 - accuracy: 0.1548\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9730 - accuracy: 0.1552\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9042 - accuracy: 0.1539\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8883 - accuracy: 0.1518\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9311 - accuracy: 0.1553\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8788 - accuracy: 0.1580\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8431 - accuracy: 0.1576\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8513 - accuracy: 0.1580\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9259 - accuracy: 0.1592\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0407 - accuracy: 0.1625\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8667 - accuracy: 0.1584\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8691 - accuracy: 0.1569\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9168 - accuracy: 0.1552\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8450 - accuracy: 0.1554\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7762 - accuracy: 0.1572\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9129 - accuracy: 0.1580\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0951 - accuracy: 0.1584\n",
      "Epoch 324/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9101 - accuracy: 0.1590\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8034 - accuracy: 0.1607\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9186 - accuracy: 0.1620\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8346 - accuracy: 0.1613\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9004 - accuracy: 0.1624\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8887 - accuracy: 0.1615\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9489 - accuracy: 0.1623\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9195 - accuracy: 0.1617\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9108 - accuracy: 0.1632\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8541 - accuracy: 0.1631\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8438 - accuracy: 0.1617\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8616 - accuracy: 0.1638\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9699 - accuracy: 0.1636\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9101 - accuracy: 0.1606\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9381 - accuracy: 0.1615\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8979 - accuracy: 0.1585\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8420 - accuracy: 0.1590\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7986 - accuracy: 0.1507\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8810 - accuracy: 0.1426\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0247 - accuracy: 0.1425\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9700 - accuracy: 0.1450\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7963 - accuracy: 0.1397\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8970 - accuracy: 0.1287\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9043 - accuracy: 0.1115\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9189 - accuracy: 0.0885\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8449 - accuracy: 0.0923\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8462 - accuracy: 0.0820\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9386 - accuracy: 0.0943\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9689 - accuracy: 0.0974\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9293 - accuracy: 0.1102\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8025 - accuracy: 0.1064\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8288 - accuracy: 0.1146\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9642 - accuracy: 0.1203\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8202 - accuracy: 0.1231\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9201 - accuracy: 0.1276\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9733 - accuracy: 0.1324\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8999 - accuracy: 0.1388\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8063 - accuracy: 0.1428\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8622 - accuracy: 0.1459\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9258 - accuracy: 0.1483\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8724 - accuracy: 0.1480\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8454 - accuracy: 0.1517\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9777 - accuracy: 0.1526\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9380 - accuracy: 0.1488\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8910 - accuracy: 0.1408\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7675 - accuracy: 0.1401\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8357 - accuracy: 0.1402\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9395 - accuracy: 0.1366\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9755 - accuracy: 0.1351\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9201 - accuracy: 0.1356\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8572 - accuracy: 0.1308\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8194 - accuracy: 0.1258\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9197 - accuracy: 0.1265\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8172 - accuracy: 0.1251\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9013 - accuracy: 0.1308\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9875 - accuracy: 0.1356\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9042 - accuracy: 0.1395\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8107 - accuracy: 0.1396\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8502 - accuracy: 0.1462\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9523 - accuracy: 0.1482\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8714 - accuracy: 0.1485\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8250 - accuracy: 0.1511\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9819 - accuracy: 0.1488\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8596 - accuracy: 0.1492\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8979 - accuracy: 0.1516\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8480 - accuracy: 0.1468\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8198 - accuracy: 0.1443\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8875 - accuracy: 0.1440\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9497 - accuracy: 0.1399\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9263 - accuracy: 0.1388\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8533 - accuracy: 0.1376\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8927 - accuracy: 0.1382\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9338 - accuracy: 0.1396\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7644 - accuracy: 0.1426\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8676 - accuracy: 0.1414\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9289 - accuracy: 0.1473\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9435 - accuracy: 0.1482\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8375 - accuracy: 0.1512\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8545 - accuracy: 0.1536\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9707 - accuracy: 0.1571\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8622 - accuracy: 0.1583\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7221 - accuracy: 0.1595\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9227 - accuracy: 0.1623\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9694 - accuracy: 0.1624\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9210 - accuracy: 0.1613\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8306 - accuracy: 0.1615\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8239 - accuracy: 0.1613\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8505 - accuracy: 0.1611\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9289 - accuracy: 0.1604\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9354 - accuracy: 0.1580\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9032 - accuracy: 0.1581\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9032 - accuracy: 0.1581\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8462 - accuracy: 0.1592\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9001 - accuracy: 0.1570\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7694 - accuracy: 0.1551\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8845 - accuracy: 0.1457\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9192 - accuracy: 0.1517\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8876 - accuracy: 0.1228\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8966 - accuracy: 0.1119\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9186 - accuracy: 0.1180\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9471 - accuracy: 0.1217\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8043 - accuracy: 0.1250\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.7656 - accuracy: 0.1267\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9105 - accuracy: 0.1346\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9076 - accuracy: 0.1332\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9615 - accuracy: 0.1334\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8454 - accuracy: 0.1372\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8228 - accuracy: 0.1392\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8801 - accuracy: 0.1367\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.8929 - accuracy: 0.1340\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 14.8665 - accuracy: 0.1376\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8560 - accuracy: 0.1366\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8953 - accuracy: 0.1270\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9793 - accuracy: 0.1302\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8217 - accuracy: 0.1261\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8257 - accuracy: 0.1207\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8639 - accuracy: 0.1280\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9111 - accuracy: 0.1280\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8117 - accuracy: 0.1330\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9170 - accuracy: 0.1361\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9781 - accuracy: 0.1417\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8426 - accuracy: 0.1414\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7463 - accuracy: 0.1491\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8815 - accuracy: 0.1525\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8641 - accuracy: 0.1536\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9269 - accuracy: 0.1580\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9111 - accuracy: 0.1619\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8509 - accuracy: 0.1616\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9231 - accuracy: 0.1634\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8613 - accuracy: 0.1643\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7771 - accuracy: 0.1659\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8116 - accuracy: 0.1668\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9178 - accuracy: 0.1674\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0097 - accuracy: 0.1691\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8278 - accuracy: 0.1693\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8558 - accuracy: 0.1686\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8499 - accuracy: 0.1658\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8315 - accuracy: 0.1673\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8044 - accuracy: 0.1658\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9150 - accuracy: 0.1575\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0340 - accuracy: 0.1578\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8970 - accuracy: 0.1604\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7442 - accuracy: 0.1631\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8557 - accuracy: 0.1580\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8257 - accuracy: 0.1542\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9035 - accuracy: 0.1514\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8958 - accuracy: 0.1462\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9163 - accuracy: 0.1468\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8665 - accuracy: 0.1447\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8663 - accuracy: 0.1444\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8840 - accuracy: 0.1446\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8078 - accuracy: 0.1520\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8144 - accuracy: 0.1577\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9501 - accuracy: 0.1603\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8450 - accuracy: 0.1619\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8794 - accuracy: 0.1629\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9336 - accuracy: 0.1608\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8514 - accuracy: 0.1625\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7624 - accuracy: 0.1632\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8542 - accuracy: 0.1643\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9560 - accuracy: 0.1659\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9273 - accuracy: 0.1666\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7889 - accuracy: 0.1647\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8842 - accuracy: 0.1673\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8692 - accuracy: 0.1672\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8756 - accuracy: 0.1688\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7521 - accuracy: 0.1696\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8421 - accuracy: 0.1707\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9889 - accuracy: 0.1718\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9320 - accuracy: 0.1728\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8735 - accuracy: 0.1726\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7841 - accuracy: 0.1738\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7685 - accuracy: 0.1752\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9174 - accuracy: 0.1760\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8351 - accuracy: 0.1762\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9315 - accuracy: 0.1768\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9491 - accuracy: 0.1773\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8587 - accuracy: 0.1779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1698aa66d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_autoencoder.fit(X, X,\n",
    "                epochs=500,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53891a2",
   "metadata": {},
   "source": [
    "## Evaluation & Simple Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce04c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of persons in data 72\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import attack\n",
    "import geopandas as gp\n",
    "gdf = gp.read_file('../data/freemove/raw_full.geojson', crs='EPSG:4326')\n",
    "gdf = gdf[gdf['TRIP_ID'].isin(points.TRIP_ID)]\n",
    "true_mapping = gdf[['TRIP_ID', 'PERSON_ID']].sort_values('TRIP_ID').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "np.save('Y.npy', attack.getGroundTruth(true_mapping))\n",
    "\n",
    "print('Number of persons in data', points.PERSON_ID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bddd3cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 10ms/step\n",
      "Homogeneity: 0.022\n",
      "Completeness: 0.234\n",
      "V-measure: 0.040\n",
      "Rand index: 0.207\n",
      "ARI: 0.001\n",
      "MI: 0.085\n",
      "NMI: 0.040\n",
      "AMI: 0.021\n",
      "Cluster accuracy: 0.068\n",
      "Homogeneity: 0.536\n",
      "Completeness: 0.497\n",
      "V-measure: 0.516\n",
      "Rand index: 0.967\n",
      "ARI: 0.142\n",
      "MI: 2.090\n",
      "NMI: 0.516\n",
      "AMI: 0.306\n",
      "Cluster accuracy: 0.278\n",
      "Homogeneity: 0.000\n",
      "Completeness: 1.000\n",
      "V-measure: 0.000\n",
      "Rand index: 0.024\n",
      "ARI: 0.000\n",
      "MI: 0.000\n",
      "NMI: 0.000\n",
      "AMI: 0.000\n",
      "Cluster accuracy: 0.058\n"
     ]
    }
   ],
   "source": [
    "# Evaluate base line hdbscan\n",
    "y = attack.getGroundTruth(true_mapping)\n",
    "import hdbscan\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "pred = encoder.predict(X)\n",
    "\n",
    "h_dbscan = hdbscan.HDBSCAN()\n",
    "h_dbscan.fit(pred)\n",
    "\n",
    "kmeans = KMeans(n_clusters=72, random_state=0, n_init=20).fit(pred)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10).fit(pred)\n",
    "\n",
    "attack.evaluate(h_dbscan.labels_, true_mapping)\n",
    "attack.evaluate(kmeans.labels_, true_mapping)\n",
    "attack.evaluate(dbscan.labels_, true_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1aff3",
   "metadata": {},
   "source": [
    "## DETECT Joint Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c940bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, RepeatVector, GRU, Bidirectional, InputSpec\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class ClusteringLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "         Measure the similarity between embedded point z_i and centroid µ_j.\n",
    "                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70531686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3aa78930",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 8000\n",
    "update_interval = 140\n",
    "index_array = np.arange(X.shape[0])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "tol = 0.001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d0bfa",
   "metadata": {},
   "source": [
    "# Simple (First train AE then refine Clustering with KLD loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f20a2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize Clustering Layer KMEANS\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "N_CLUSTERS = 72\n",
    "\n",
    "# Build clustering model\n",
    "clustering_layer = ClusteringLayer(N_CLUSTERS, name='clustering')(encoder.output)\n",
    "model = keras.Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "model.compile(optimizer=opt, loss='kld')\n",
    "\n",
    "# Initialize cluster centers using k-means.\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(X))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "# Get labels (ground truth)\n",
    "y = attack.getGroundTruth(true_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e6d9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.28825, nmi = 0.53513, ari = 0.15959  ; loss= 0\n",
      "Iter 140: acc = 0.29289, nmi = 0.53364, ari = 0.15715  ; loss= 4.98642\n",
      "Iter 280: acc = 0.29598, nmi = 0.53360, ari = 0.15579  ; loss= 5.7236\n",
      "Iter 420: acc = 0.28516, nmi = 0.52341, ari = 0.14236  ; loss= 6.825\n",
      "Iter 560: acc = 0.28748, nmi = 0.52328, ari = 0.14179  ; loss= 7.2276\n",
      "Iter 700: acc = 0.29134, nmi = 0.52612, ari = 0.14461  ; loss= 7.11497\n",
      "Iter 840: acc = 0.29134, nmi = 0.52285, ari = 0.14414  ; loss= 6.56727\n",
      "Iter 980: acc = 0.29134, nmi = 0.52282, ari = 0.14444  ; loss= 6.23553\n",
      "Iter 1120: acc = 0.29057, nmi = 0.52283, ari = 0.14461  ; loss= 7.44327\n",
      "Iter 1260: acc = 0.29212, nmi = 0.52328, ari = 0.14568  ; loss= 6.62974\n",
      "Iter 1400: acc = 0.29212, nmi = 0.52262, ari = 0.14502  ; loss= 5.9629\n",
      "Iter 1540: acc = 0.29212, nmi = 0.52307, ari = 0.14430  ; loss= 6.27522\n",
      "Iter 1680: acc = 0.28825, nmi = 0.52183, ari = 0.14330  ; loss= 6.64078\n",
      "Iter 1820: acc = 0.29134, nmi = 0.52427, ari = 0.14427  ; loss= 7.33977\n",
      "Iter 1960: acc = 0.29057, nmi = 0.52210, ari = 0.14224  ; loss= 7.02252\n",
      "Iter 2100: acc = 0.28980, nmi = 0.52289, ari = 0.14304  ; loss= 6.46347\n",
      "Iter 2240: acc = 0.29134, nmi = 0.52330, ari = 0.14291  ; loss= 6.17009\n",
      "Iter 2380: acc = 0.28980, nmi = 0.52190, ari = 0.14230  ; loss= 7.23591\n",
      "Iter 2520: acc = 0.28980, nmi = 0.52423, ari = 0.14371  ; loss= 6.46483\n",
      "Iter 2660: acc = 0.28980, nmi = 0.52385, ari = 0.14405  ; loss= 6.32802\n",
      "Iter 2800: acc = 0.28980, nmi = 0.52360, ari = 0.14328  ; loss= 6.27149\n",
      "Iter 2940: acc = 0.29057, nmi = 0.52431, ari = 0.14370  ; loss= 6.76694\n",
      "Iter 3080: acc = 0.28980, nmi = 0.52385, ari = 0.14354  ; loss= 7.05806\n",
      "Iter 3220: acc = 0.29057, nmi = 0.52432, ari = 0.14434  ; loss= 6.99158\n",
      "Iter 3360: acc = 0.28980, nmi = 0.52421, ari = 0.14406  ; loss= 6.58173\n",
      "Iter 3500: acc = 0.28980, nmi = 0.52417, ari = 0.14423  ; loss= 6.43713\n",
      "Iter 3640: acc = 0.28980, nmi = 0.52429, ari = 0.14390  ; loss= 7.04194\n",
      "Iter 3780: acc = 0.28980, nmi = 0.52427, ari = 0.14368  ; loss= 6.53615\n",
      "Iter 3920: acc = 0.28903, nmi = 0.52422, ari = 0.14392  ; loss= 6.05832\n",
      "Iter 4060: acc = 0.28980, nmi = 0.52424, ari = 0.14418  ; loss= 6.33011\n",
      "Iter 4200: acc = 0.28903, nmi = 0.52443, ari = 0.14419  ; loss= 6.82833\n",
      "Iter 4340: acc = 0.29057, nmi = 0.52479, ari = 0.14469  ; loss= 7.03064\n",
      "Iter 4480: acc = 0.28980, nmi = 0.52356, ari = 0.14349  ; loss= 6.76624\n",
      "Iter 4620: acc = 0.29057, nmi = 0.52477, ari = 0.14467  ; loss= 6.40049\n",
      "Iter 4760: acc = 0.29057, nmi = 0.52442, ari = 0.14457  ; loss= 6.06934\n",
      "Iter 4900: acc = 0.28980, nmi = 0.52405, ari = 0.14446  ; loss= 7.23294\n",
      "Iter 5040: acc = 0.28980, nmi = 0.52288, ari = 0.14295  ; loss= 6.3886\n",
      "Iter 5180: acc = 0.28980, nmi = 0.52429, ari = 0.14422  ; loss= 6.06386\n",
      "Iter 5320: acc = 0.28825, nmi = 0.52365, ari = 0.14358  ; loss= 6.24453\n",
      "Iter 5460: acc = 0.28980, nmi = 0.52396, ari = 0.14372  ; loss= 6.75262\n",
      "Iter 5600: acc = 0.28980, nmi = 0.52437, ari = 0.14435  ; loss= 7.05429\n",
      "Iter 5740: acc = 0.28980, nmi = 0.52469, ari = 0.14462  ; loss= 7.12068\n",
      "Iter 5880: acc = 0.28980, nmi = 0.52288, ari = 0.14295  ; loss= 6.33483\n",
      "Iter 6020: acc = 0.28903, nmi = 0.52424, ari = 0.14388  ; loss= 6.23194\n",
      "Iter 6160: acc = 0.28980, nmi = 0.52432, ari = 0.14451  ; loss= 6.88296\n",
      "Iter 6300: acc = 0.28825, nmi = 0.52426, ari = 0.14423  ; loss= 6.41322\n",
      "Iter 6440: acc = 0.28903, nmi = 0.52411, ari = 0.14393  ; loss= 6.14249\n",
      "Iter 6580: acc = 0.29057, nmi = 0.52392, ari = 0.14386  ; loss= 6.28535\n",
      "Iter 6720: acc = 0.29057, nmi = 0.52444, ari = 0.14514  ; loss= 6.5533\n",
      "Iter 6860: acc = 0.28980, nmi = 0.52480, ari = 0.14506  ; loss= 6.98347\n",
      "Iter 7000: acc = 0.29057, nmi = 0.52360, ari = 0.14375  ; loss= 6.76285\n",
      "Iter 7140: acc = 0.29057, nmi = 0.52427, ari = 0.14403  ; loss= 6.38115\n",
      "Iter 7280: acc = 0.28903, nmi = 0.52457, ari = 0.14412  ; loss= 6.23741\n",
      "Iter 7420: acc = 0.29134, nmi = 0.52486, ari = 0.14490  ; loss= 6.91365\n",
      "Iter 7560: acc = 0.29134, nmi = 0.52557, ari = 0.14519  ; loss= 6.33102\n",
      "Iter 7700: acc = 0.28980, nmi = 0.52449, ari = 0.14417  ; loss= 6.1211\n",
      "Iter 7840: acc = 0.29057, nmi = 0.52493, ari = 0.14499  ; loss= 6.18221\n",
      "Iter 7980: acc = 0.29057, nmi = 0.52514, ari = 0.14537  ; loss= 6.76614\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(X, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(attack.cluster_acc(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
    "    loss = model.train_on_batch(x=tf.gather(X, indices=idx), y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b311ecd",
   "metadata": {},
   "source": [
    "# Advanced (Train AE and Clustering Simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448670c",
   "metadata": {},
   "source": [
    "**Important:** Do not forget to reinitialize the AE before running the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7effe932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "N_CLUSTERS = 72\n",
    "\n",
    "# (re)initialize clustering layer\n",
    "clustering_layer = ClusteringLayer(N_CLUSTERS, name='clustering')(encoder.output)\n",
    "\n",
    "# Train AE and clustering layer at the same time\n",
    "model = keras.Model(inputs=inputs,\n",
    "            outputs=[clustering_layer, sequence_autoencoder.output])\n",
    "pretrain_optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83dea8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.10046, nmi = 0.14096, ari = 0.02553  ; loss= [14.77079  0.49049  0.02395]\n",
      "Iter 140: acc = 0.08578, nmi = 0.10227, ari = 0.00949  ; loss= [1.503691e+01 7.000000e-05 2.427000e-02]\n",
      "Iter 280: acc = 0.10046, nmi = 0.15124, ari = 0.02319  ; loss= [14.88898  0.       0.02138]\n",
      "Iter 420: acc = 0.10896, nmi = 0.17563, ari = 0.03253  ; loss= [1.484727e+01 1.000000e-05 2.219000e-02]\n",
      "Iter 560: acc = 0.13833, nmi = 0.23023, ari = 0.04790  ; loss= [1.498289e+01 1.000000e-05 1.916000e-02]\n",
      "Iter 700: acc = 0.19474, nmi = 0.32634, ari = 0.07177  ; loss= [1.481378e+01 3.000000e-05 1.844000e-02]\n",
      "Iter 840: acc = 0.20711, nmi = 0.37116, ari = 0.08635  ; loss= [1.501879e+01 5.000000e-05 1.900000e-02]\n",
      "Iter 980: acc = 0.20015, nmi = 0.36085, ari = 0.07436  ; loss= [1.491256e+01 1.800000e-04 1.703000e-02]\n",
      "Iter 1120: acc = 0.20170, nmi = 0.37403, ari = 0.06870  ; loss= [1.487374e+01 4.000000e-04 1.658000e-02]\n",
      "Iter 1260: acc = 0.21870, nmi = 0.40721, ari = 0.08320  ; loss= [1.483837e+01 2.600000e-03 1.695000e-02]\n",
      "Iter 1400: acc = 0.22798, nmi = 0.42813, ari = 0.08738  ; loss= [14.91216  0.01694  0.01498]\n",
      "Iter 1540: acc = 0.21638, nmi = 0.42942, ari = 0.09013  ; loss= [14.74854  0.07193  0.01684]\n",
      "Iter 1680: acc = 0.22102, nmi = 0.43673, ari = 0.09241  ; loss= [14.91447  0.21886  0.01838]\n",
      "Iter 1820: acc = 0.21716, nmi = 0.42840, ari = 0.08809  ; loss= [14.88429  0.28448  0.01615]\n",
      "Iter 1960: acc = 0.22643, nmi = 0.43310, ari = 0.09311  ; loss= [14.78851  0.33096  0.01901]\n",
      "Iter 2100: acc = 0.22179, nmi = 0.43413, ari = 0.09068  ; loss= [14.80235  0.32229  0.02046]\n",
      "Iter 2240: acc = 0.22334, nmi = 0.43243, ari = 0.09191  ; loss= [14.95177  0.4038   0.01766]\n",
      "Iter 2380: acc = 0.22334, nmi = 0.43278, ari = 0.09193  ; loss= [14.70428  0.33481  0.02018]\n",
      "Iter 2520: acc = 0.22411, nmi = 0.43780, ari = 0.09229  ; loss= [14.9068   0.39389  0.01929]\n",
      "Iter 2660: acc = 0.22334, nmi = 0.43840, ari = 0.09283  ; loss= [14.77852  0.3147   0.02067]\n",
      "Iter 2800: acc = 0.22488, nmi = 0.43865, ari = 0.09207  ; loss= [14.71756  0.33858  0.01736]\n",
      "Iter 2940: acc = 0.22334, nmi = 0.43805, ari = 0.09222  ; loss= [14.75786  0.3092   0.01995]\n",
      "Iter 3080: acc = 0.22411, nmi = 0.43979, ari = 0.09410  ; loss= [14.84454  0.32468  0.01871]\n",
      "Iter 3220: acc = 0.22411, nmi = 0.43762, ari = 0.09270  ; loss= [14.63301  0.3672   0.01792]\n",
      "Iter 3360: acc = 0.22720, nmi = 0.44085, ari = 0.09328  ; loss= [14.83338  0.27892  0.02123]\n",
      "Iter 3500: acc = 0.22488, nmi = 0.43873, ari = 0.09527  ; loss= [14.76404  0.30322  0.01944]\n",
      "Iter 3640: acc = 0.22643, nmi = 0.43691, ari = 0.09319  ; loss= [14.69468  0.27383  0.01792]\n",
      "Iter 3780: acc = 0.22566, nmi = 0.43768, ari = 0.09378  ; loss= [14.68664  0.25061  0.01761]\n",
      "Iter 3920: acc = 0.22875, nmi = 0.43929, ari = 0.09675  ; loss= [14.76744  0.24388  0.01479]\n",
      "Iter 4060: acc = 0.22334, nmi = 0.43722, ari = 0.09317  ; loss= [14.59313  0.22614  0.02234]\n",
      "Iter 4200: acc = 0.22798, nmi = 0.43651, ari = 0.09335  ; loss= [14.77721  0.22807  0.02024]\n",
      "Iter 4340: acc = 0.22566, nmi = 0.43797, ari = 0.09314  ; loss= [14.67547  0.21875  0.01553]\n",
      "Iter 4480: acc = 0.22411, nmi = 0.43917, ari = 0.09326  ; loss= [14.65285  0.22058  0.01545]\n",
      "Iter 4620: acc = 0.22875, nmi = 0.43390, ari = 0.09552  ; loss= [14.6736   0.25322  0.01991]\n",
      "Iter 4760: acc = 0.22720, nmi = 0.43719, ari = 0.09268  ; loss= [14.75696  0.19354  0.01872]\n",
      "Iter 4900: acc = 0.22488, nmi = 0.43884, ari = 0.09335  ; loss= [14.59383  0.21282  0.01977]\n",
      "Iter 5040: acc = 0.22798, nmi = 0.43780, ari = 0.09440  ; loss= [14.69937  0.22636  0.01548]\n",
      "Iter 5180: acc = 0.22643, nmi = 0.43886, ari = 0.09405  ; loss= [14.63543  0.20536  0.01743]\n",
      "Iter 5320: acc = 0.22334, nmi = 0.43663, ari = 0.09314  ; loss= [1.463985e+01 1.811700e-01 1.437000e-02]\n",
      "Iter 5460: acc = 0.22257, nmi = 0.43637, ari = 0.09312  ; loss= [14.62852  0.21708  0.021  ]\n",
      "Iter 5600: acc = 0.22720, nmi = 0.43923, ari = 0.09481  ; loss= [14.71292  0.18954  0.01721]\n",
      "Iter 5740: acc = 0.22643, nmi = 0.43487, ari = 0.09357  ; loss= [14.53532  0.18308  0.01572]\n",
      "Iter 5880: acc = 0.22488, nmi = 0.43576, ari = 0.09465  ; loss= [14.71671  0.18678  0.01751]\n",
      "Iter 6020: acc = 0.22643, nmi = 0.43695, ari = 0.09316  ; loss= [1.464714e+01 1.692100e-01 1.331000e-02]\n",
      "Iter 6160: acc = 0.22411, nmi = 0.43664, ari = 0.09321  ; loss= [14.62201  0.16434  0.01608]\n",
      "Iter 6300: acc = 0.22334, nmi = 0.43617, ari = 0.09374  ; loss= [14.60279  0.18731  0.01618]\n",
      "Iter 6440: acc = 0.22488, nmi = 0.43822, ari = 0.09529  ; loss= [1.467318e+01 1.597200e-01 1.246000e-02]\n",
      "Iter 6580: acc = 0.22566, nmi = 0.43733, ari = 0.09318  ; loss= [1.452107e+01 1.665000e-01 1.379000e-02]\n",
      "Iter 6720: acc = 0.22411, nmi = 0.43592, ari = 0.09329  ; loss= [1.466318e+01 1.759400e-01 1.424000e-02]\n",
      "Iter 6860: acc = 0.22643, nmi = 0.43808, ari = 0.09661  ; loss= [1.45949e+01 1.42990e-01 1.18500e-02]\n",
      "Iter 7000: acc = 0.22720, nmi = 0.43772, ari = 0.09466  ; loss= [1.457175e+01 1.946600e-01 1.297000e-02]\n",
      "Iter 7140: acc = 0.22488, nmi = 0.43586, ari = 0.09326  ; loss= [1.458593e+01 1.435300e-01 1.279000e-02]\n",
      "Iter 7280: acc = 0.22720, nmi = 0.43930, ari = 0.09564  ; loss= [1.471025e+01 1.725600e-01 1.112000e-02]\n",
      "Iter 7420: acc = 0.22720, nmi = 0.43549, ari = 0.09463  ; loss= [1.44955e+01 1.44240e-01 1.23200e-02]\n",
      "Iter 7560: acc = 0.22488, nmi = 0.43789, ari = 0.09361  ; loss= [1.46611e+01 1.41280e-01 1.37800e-02]\n",
      "Iter 7700: acc = 0.22643, nmi = 0.43811, ari = 0.09450  ; loss= [1.460281e+01 1.537400e-01 1.270000e-02]\n",
      "Iter 7840: acc = 0.22566, nmi = 0.43868, ari = 0.09431  ; loss= [1.454945e+01 1.472500e-01 1.130000e-02]\n",
      "Iter 7980: acc = 0.22643, nmi = 0.43257, ari = 0.09518  ; loss= [1.45775e+01 1.38840e-01 1.32300e-02]\n"
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(X, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(attack.cluster_acc(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
    "    loss = model.train_on_batch(x=tf.gather(X, indices=idx), y=[p[idx], tf.gather(X, indices=idx)])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa5afc",
   "metadata": {},
   "source": [
    "## DC-GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0aefa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "import random\n",
    "\n",
    "class DataGenerator():\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, X, Y, alpha=1000, batch_size=100, num_constrains=0, q=0, ml=0, shuffle=True, l=0):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.q = q\n",
    "        self.num_constrains = num_constrains\n",
    "        self.ml = ml\n",
    "        self.X = X\n",
    "        if l == 0:\n",
    "            self.l = len(Y)\n",
    "        else:\n",
    "            self.l = l\n",
    "        self.Y = Y\n",
    "        self.W, self.ml_ind1, self.ml_ind2, self.cl_ind1, self.cl_ind2 = self.get_W()\n",
    "        print(self.W.shape)\n",
    "        print(self.W)\n",
    "        print(self.ml_ind1)\n",
    "        print(self.W.data)\n",
    "        self.ind1 = np.concatenate([self.ml_ind1,self.cl_ind1])\n",
    "        self.ind2 = np.concatenate([self.ml_ind2,self.cl_ind2])\n",
    "        self.indexes = np.arange(len(self.Y))\n",
    "        self.ind_constr = np.arange(self.num_constrains)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def transitive_closure(self, ml_ind1, ml_ind2, cl_ind1, cl_ind2, n):\n",
    "        \"\"\"\n",
    "        This function calculate the total transtive closure for must-links and the full entailment\n",
    "        for cannot-links.\n",
    "\n",
    "        # Arguments\n",
    "            ml_ind1, ml_ind2 = instances within a pair of must-link constraints\n",
    "            cl_ind1, cl_ind2 = instances within a pair of cannot-link constraints\n",
    "            n = total training instance number\n",
    "        # Return\n",
    "            transtive closure (must-links)\n",
    "            entailment of cannot-links\n",
    "        \"\"\"\n",
    "        ml_graph = dict()\n",
    "        cl_graph = dict()\n",
    "        for i in range(n):\n",
    "            ml_graph[i] = set()\n",
    "            cl_graph[i] = set()\n",
    "\n",
    "        def add_both(d, i, j):\n",
    "            d[i].add(j)\n",
    "            d[j].add(i)\n",
    "\n",
    "        for (i, j) in zip(ml_ind1, ml_ind2):\n",
    "            add_both(ml_graph, i, j)\n",
    "\n",
    "        def dfs(i, graph, visited, component):\n",
    "            visited[i] = True\n",
    "            for j in graph[i]:\n",
    "                if not visited[j]:\n",
    "                    dfs(j, graph, visited, component)\n",
    "            component.append(i)\n",
    "\n",
    "        visited = [False] * n\n",
    "        for i in range(n):\n",
    "            if not visited[i]:\n",
    "                component = []\n",
    "                dfs(i, ml_graph, visited, component)\n",
    "                for x1 in component:\n",
    "                    for x2 in component:\n",
    "                        if x1 != x2:\n",
    "                            ml_graph[x1].add(x2)\n",
    "        for (i, j) in zip(cl_ind1, cl_ind2):\n",
    "            add_both(cl_graph, i, j)\n",
    "            for y in ml_graph[j]:\n",
    "                add_both(cl_graph, i, y)\n",
    "            for x in ml_graph[i]:\n",
    "                add_both(cl_graph, x, j)\n",
    "                for y in ml_graph[j]:\n",
    "                    add_both(cl_graph, x, y)\n",
    "        ml_res_set = set()\n",
    "        cl_res_set = set()\n",
    "        for i in ml_graph:\n",
    "            for j in ml_graph[i]:\n",
    "                if j != i and j in cl_graph[i]:\n",
    "                    raise Exception('inconsistent constraints between %d and %d' % (i, j))\n",
    "                if i <= j:\n",
    "                    ml_res_set.add((i, j))\n",
    "                else:\n",
    "                    ml_res_set.add((j, i))\n",
    "        for i in cl_graph:\n",
    "            for j in cl_graph[i]:\n",
    "                if i <= j:\n",
    "                    cl_res_set.add((i, j))\n",
    "                else:\n",
    "                    cl_res_set.add((j, i))\n",
    "        ml_res1, ml_res2 = [], []\n",
    "        cl_res1, cl_res2 = [], []\n",
    "        for (x, y) in ml_res_set:\n",
    "            ml_res1.append(x)\n",
    "            ml_res2.append(y)\n",
    "        for (x, y) in cl_res_set:\n",
    "            cl_res1.append(x)\n",
    "            cl_res2.append(y)\n",
    "        return np.array(ml_res1), np.array(ml_res2), np.array(cl_res1), np.array(cl_res2)\n",
    "\n",
    "    def generate_random_pair(self, y, num, q):\n",
    "        \"\"\"\n",
    "        Generate random pairwise constraints.\n",
    "        \"\"\"\n",
    "        ml_ind1, ml_ind2 = [], []\n",
    "        cl_ind1, cl_ind2 = [], []\n",
    "        while num > 0:\n",
    "            tmp1 = random.randint(0, self.l - 1)\n",
    "            tmp2 = random.randint(0, self.l - 1)\n",
    "            ii = np.random.uniform(0,1)\n",
    "            if tmp1 == tmp2:\n",
    "                continue\n",
    "            # If the samples belong to the same cluster in fact\n",
    "            if y[tmp1] == y[tmp2]:\n",
    "                # Append must-link constraints for unflipped constrains (>q)\n",
    "                if ii >= q:\n",
    "                    ml_ind1.append(tmp1)\n",
    "                    ml_ind2.append(tmp2)\n",
    "                else:\n",
    "                    cl_ind1.append(tmp1)\n",
    "                    cl_ind2.append(tmp2)\n",
    "            \n",
    "            else:\n",
    "                # If not, append cannot-link constraints for unflipped constrains (>q)\n",
    "                if ii >= q:\n",
    "                    cl_ind1.append(tmp1)\n",
    "                    cl_ind2.append(tmp2)\n",
    "                else:\n",
    "                    ml_ind1.append(tmp1)\n",
    "                    ml_ind2.append(tmp2)\n",
    "            num -= 1\n",
    "        return np.array(ml_ind1), np.array(ml_ind2), np.array(cl_ind1), np.array(cl_ind2)\n",
    "\n",
    "    def generate_random_pair_ml(self, y, num):\n",
    "        \"\"\"\n",
    "        Generate random pairwise constraints.\n",
    "        \"\"\"\n",
    "        ml_ind1, ml_ind2 = [], []\n",
    "        cl_ind1, cl_ind2 = [], []\n",
    "        while num > 0:\n",
    "            tmp1 = random.randint(0, y.shape[0] - 1)\n",
    "            tmp2 = random.randint(0, y.shape[0] - 1)\n",
    "            ii = np.random.uniform(0,1)\n",
    "            if tmp1 == tmp2:\n",
    "                continue\n",
    "            if y[tmp1] == y[tmp2]:\n",
    "                ml_ind1.append(tmp1)\n",
    "                ml_ind2.append(tmp2)\n",
    "                num -= 1\n",
    "        return np.array(ml_ind1), np.array(ml_ind2), np.array(cl_ind1), np.array(cl_ind2)\n",
    "\n",
    "    def generate_random_pair_cl(self, y, num):\n",
    "        \"\"\"\n",
    "        Generate random pairwise constraints.\n",
    "        \"\"\"\n",
    "        ml_ind1, ml_ind2 = [], []\n",
    "        cl_ind1, cl_ind2 = [], []\n",
    "        while num > 0:\n",
    "            tmp1 = random.randint(0, y.shape[0] - 1)\n",
    "            tmp2 = random.randint(0, y.shape[0] - 1)\n",
    "            ii = np.random.uniform(0,1)\n",
    "            if tmp1 == tmp2:\n",
    "                continue\n",
    "            if y[tmp1] != y[tmp2]:\n",
    "                cl_ind1.append(tmp1)\n",
    "                cl_ind2.append(tmp2)\n",
    "                num -= 1\n",
    "        return np.array(ml_ind1), np.array(ml_ind2), np.array(cl_ind1), np.array(cl_ind2)\n",
    "\n",
    "    def get_W(self):\n",
    "        if self.ml==0:\n",
    "            ml_ind1, ml_ind2, cl_ind1, cl_ind2 = self.generate_random_pair(self.Y, self.num_constrains, self.q)\n",
    "            if self.q == 0:\n",
    "                ml_ind1, ml_ind2, cl_ind1, cl_ind2 = self.transitive_closure(ml_ind1, ml_ind2, cl_ind1, cl_ind2, self.X.shape[0])\n",
    "        elif self.ml == 1:\n",
    "            ml_ind1, ml_ind2, cl_ind1, cl_ind2 = self.generate_random_pair_ml(self.Y, self.num_constrains)\n",
    "        elif self.ml == -1:\n",
    "            ml_ind1, ml_ind2, cl_ind1, cl_ind2 = self.generate_random_pair_cl(self.Y, self.num_constrains)\n",
    "        print(\"\\nNumber of ml constraints: %d, cl constraints: %d.\\n \" % (len(ml_ind1), len(cl_ind1)))\n",
    "        \n",
    "        #W = np.zeros([len(self.X), len(self.X)])\n",
    "        #for i in range(len(ml_ind1)):\n",
    "        #    W[ml_ind1[i], ml_ind2[i]] = 1\n",
    "        #    W[ml_ind2[i], ml_ind1[i]] = 1\n",
    "        #for i in range(len(cl_ind1)):\n",
    "        #    W[cl_ind1[i], cl_ind2[i]] = -1\n",
    "        #    W[cl_ind2[i], cl_ind1[i]] = -1\n",
    "        #W = csr_matrix(W)\n",
    "\n",
    "        #if self.num_constrains > 0:\n",
    "        if False:\n",
    "            ml_ind1= np.load(\"source/data1_pos.npy\")\n",
    "            ml_ind2= np.load(\"source/data2_pos.npy\")\n",
    "            cl_ind1=np.load(\"source/data1_neg.npy\")\n",
    "            cl_ind2= np.load(\"source/data2_neg.npy\")\n",
    "\n",
    "        ind1 = np.concatenate([ml_ind1, ml_ind2, cl_ind1, cl_ind2])\n",
    "        ind2 = np.concatenate([ml_ind2, ml_ind1, cl_ind2, cl_ind1])\n",
    "        data = np.concatenate([np.ones(len(ml_ind1)*2), np.ones(len(cl_ind1)*2)*-1])\n",
    "        W = csr_matrix((data, (ind1, ind2)), shape=(len(self.X), len(self.X)))\n",
    "        W = W.tanh().rint()\n",
    "        return W, ml_ind1, ml_ind2, cl_ind1, cl_ind2\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def gen(self):\n",
    "        while True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            np.random.shuffle(self.ind_constr)\n",
    "            for index in range(int(len(self.X)/ self.batch_size)):\n",
    "                indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "                X = tf.gather(self.X, indices=indexes)\n",
    "                Y = tf.gather(self.Y, indices=indexes)\n",
    "#                 X = self.X[indexes]\n",
    "#                 Y = self.Y[indexes]\n",
    "                W = self.W[indexes][:, indexes]* self.alpha\n",
    "                ind1, ind2 = csr_matrix_indices(W)\n",
    "                data = W.data\n",
    "                yield (X, (ind1, ind2, data)), {\"output_1\": X, \"output_4\": Y}\n",
    "            for index in range(self.num_constrains// self.batch_size):\n",
    "                indexes = self.ind_constr[index * self.batch_size//2:(index + 1) * self.batch_size//2]\n",
    "                indexes = np.concatenate([self.ind1[indexes], self.ind2[indexes]])\n",
    "                np.random.shuffle(indexes)\n",
    "                X = tf.gather(self.X, indices=indexes)\n",
    "                Y = tf.gather(self.Y, indices=indexes)\n",
    "#                 X = self.X[indexes]\n",
    "#                 Y = self.Y[indexes]\n",
    "                W = self.W[indexes][:, indexes]* self.alpha\n",
    "                ind1, ind2 = csr_matrix_indices(W)\n",
    "                data = W.data\n",
    "                #W = W.toarray()\n",
    "                yield (X, (ind1,ind2, data)), {\"output_1\": X, \"output_4\": Y}\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, encoded_size):\n",
    "        super(Encoder, self).__init__(name='encoder')\n",
    "        self.dense1 = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))\n",
    "        self.dense2 = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))\n",
    "        \n",
    "        self.rnn1 = Bidirectional(GRU(encoded_size, return_sequences=True, recurrent_regularizer=l1(0.02)))\n",
    "        self.rnn2 = Bidirectional(GRU(encoded_size, return_sequences=False, recurrent_regularizer=l1(0.02)))\n",
    "        \n",
    "        \n",
    "        self.mu = Dense(encoded_size, activation=None)\n",
    "        self.sigma = Dense(encoded_size, activation=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.dense1(inputs)\n",
    "        encoded = self.dense2(encoded)\n",
    "\n",
    "        encoded = self.rnn1(encoded)\n",
    "        encoded = self.rnn2(encoded)\n",
    "\n",
    "        mu = self.mu(encoded)\n",
    "        sigma = self.sigma(encoded)\n",
    "        \n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, latent_dim, timesteps):\n",
    "        super(Decoder, self).__init__(name='dec')\n",
    "        self.repeat_vector = RepeatVector(timesteps)\n",
    "        \n",
    "        self.rnn1 = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))\n",
    "        self.rnn2 = Bidirectional(GRU(latent_dim, return_sequences=True, recurrent_regularizer=l1(0.02)))\n",
    "\n",
    "        self.dense1 = Dense(units=256, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))\n",
    "        self.dense2 = Dense(units=128, activation='relu', use_bias=True, kernel_initializer=he_uniform(seed=1))\n",
    "\n",
    "        self.output_geohash = TimeDistributed(Dense(geohash_dim, kernel_initializer=he_uniform(), activation='sigmoid'), name='output_geohash')\n",
    "        self.output_hour = TimeDistributed(Dense(hour_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_hour')\n",
    "        self.output_geo_context = TimeDistributed(Dense(geographical_context_dim, kernel_initializer=he_uniform(), activation='tanh'), name='output_geo_context')\n",
    "        self.output_geo_type = TimeDistributed(Dense(geo_type_dim, kernel_initializer=he_uniform(), activation='softmax'), name='output_geo_type')\n",
    "\n",
    "        self.concat = Concatenate(axis=2)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.repeat_vector(inputs)\n",
    "        x = self.rnn1(x)\n",
    "        x = self.rnn2(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        output_geohash = self.output_geohash(x)\n",
    "        output_hour = self.output_hour(x)\n",
    "        output_geo_context = self.output_geo_context(x)\n",
    "        output_geo_type = self.output_geo_type(x)\n",
    "        outputs = self.concat([output_geohash, output_hour, output_geo_context, output_geo_type])\n",
    "        return outputs\n",
    "\n",
    "class AE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(500)\n",
    "        self.decoder = Decoder(timesteps=int(max_points))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "\n",
    "tfd = tfp.distributions    \n",
    "class DCGMM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DCGMM, self).__init__(name=\"DCGMM\")#, dynamic=True)\n",
    "        self.encoded_size = 500\n",
    "        self.num_clusters = 72\n",
    "\n",
    "        self.encoder = Encoder(self.encoded_size)\n",
    "        self.decoder = Decoder(self.encoded_size, timesteps=int(max_points))\n",
    "\n",
    "        self.c_mu = tf.Variable(tf.ones([self.num_clusters, self.encoded_size]), name=\"mu\")\n",
    "        self.log_c_sigma = tf.Variable(tf.ones([self.num_clusters, self.encoded_size]), name=\"sigma\")\n",
    "        self.prior = tf.constant(tf.ones([self.num_clusters]) * (\n",
    "                1 / self.num_clusters))  # tf.Variable(tf.ones([self.num_clusters]), name=\"prior\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs, W = inputs\n",
    "        z_mu, log_z_sigma = self.encoder(inputs)\n",
    "        z = tfd.MultivariateNormalDiag(loc=z_mu, scale_diag=tf.math.sqrt(tf.math.exp(log_z_sigma)))\n",
    "        z_sample = z.sample()\n",
    "\n",
    "        log_z_sigma_tile = tf.expand_dims(log_z_sigma, axis=-2)\n",
    "        c = tf.constant([1, self.num_clusters, 1], tf.int32)\n",
    "        log_z_sigma_tile = tf.tile(log_z_sigma_tile, c)\n",
    "\n",
    "        z_mu_tile = tf.expand_dims(z_mu, axis=-2)\n",
    "        c = tf.constant([1, self.num_clusters, 1], tf.int32)\n",
    "        z_mu_tile = tf.tile(z_mu_tile, c)\n",
    "\n",
    "        c_sigma = tf.math.exp(self.log_c_sigma)\n",
    "        p_z_c = tf.stack([tf.math.log(\n",
    "            tfd.MultivariateNormalDiag(loc=self.c_mu[i, :], scale_diag=tf.math.sqrt(c_sigma[i, :])).prob(\n",
    "                z_sample) + 1e-30) for i in range(self.num_clusters)], axis=-1)\n",
    "\n",
    "        prior = self.prior\n",
    "\n",
    "        p_c_z = tf.math.log(prior + tf.keras.backend.epsilon()) + p_z_c\n",
    "\n",
    "        norm_s = tf.math.log(1e-30 + tf.math.reduce_sum(tf.math.exp(p_c_z), axis=-1, keepdims=True))\n",
    "        c = tf.constant([1, self.num_clusters], tf.int32)\n",
    "        norm = tf.tile(norm_s, c)\n",
    "        p_c_z = tf.math.exp(p_c_z - norm)\n",
    "\n",
    "        loss_1a = tf.math.log(c_sigma + tf.keras.backend.epsilon())\n",
    "\n",
    "        loss_1b = tf.math.exp(log_z_sigma_tile) / (c_sigma + tf.keras.backend.epsilon())\n",
    "\n",
    "        loss_1c = tf.math.square(z_mu_tile - self.c_mu) / (c_sigma + tf.keras.backend.epsilon())\n",
    "\n",
    "        loss_1d = self.encoded_size * tf.math.log(tf.keras.backend.constant(2 * np.pi))\n",
    "\n",
    "        loss_1a = tf.multiply(p_c_z, tf.math.reduce_sum(loss_1a, axis=-1))\n",
    "        loss_1b = tf.multiply(p_c_z, tf.math.reduce_sum(loss_1b, axis=-1))\n",
    "        loss_1c = tf.multiply(p_c_z, tf.math.reduce_sum(loss_1c, axis=-1))\n",
    "        loss_1d = tf.multiply(p_c_z, loss_1d)\n",
    "\n",
    "        loss_1a = 1 / 2 * tf.reduce_sum(loss_1a, axis=-1)\n",
    "        loss_1b = 1 / 2 * tf.reduce_sum(loss_1b, axis=-1)\n",
    "        loss_1c = 1 / 2 * tf.reduce_sum(loss_1c, axis=-1)\n",
    "        loss_1d = 1 / 2 * tf.reduce_sum(loss_1d, axis=-1)\n",
    "\n",
    "        loss_2a = - tf.math.reduce_sum(tf.math.xlogy(p_c_z, prior), axis=-1)\n",
    "\n",
    "        if training:\n",
    "            ind1, ind2, data = W\n",
    "            ind1 = tf.reshape(ind1, [-1])\n",
    "            ind2 = tf.reshape(ind2, [-1])\n",
    "            data = tf.reshape(data, [-1])\n",
    "            ind = tf.stack([ind1, ind2], axis=0)\n",
    "            ind = tf.transpose(ind)\n",
    "            ind = tf.dtypes.cast(ind, tf.int64)\n",
    "            W_sparse = tf.SparseTensor(indices=ind, values=data, dense_shape=[len(inputs), len(inputs)])\n",
    "            W_sparse = tf.sparse.expand_dims(W_sparse, axis=-1)\n",
    "            W_tile = tf.sparse.concat(-1, [W_sparse] * self.num_clusters)\n",
    "            mul = W_tile.__mul__(p_c_z)\n",
    "            sum_j = tf.sparse.reduce_sum(mul, axis=-2)\n",
    "            loss_2a_constrain = - tf.math.reduce_sum(tf.multiply(p_c_z, sum_j), axis=-1)\n",
    "\n",
    "            self.add_loss(tf.math.reduce_mean(loss_2a_constrain))\n",
    "            self.add_metric(loss_2a_constrain, name='loss_2a_c', aggregation=\"mean\")\n",
    "\n",
    "        loss_2b = tf.math.reduce_sum(tf.math.xlogy(p_c_z, p_c_z), axis=-1)\n",
    "\n",
    "        loss_3 = - 1 / 2 * tf.reduce_sum(log_z_sigma + 1, axis=-1)\n",
    "\n",
    "        self.add_loss(tf.math.reduce_mean(loss_1a))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_1b))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_1c))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_1d))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_2a))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_2b))\n",
    "        self.add_loss(tf.math.reduce_mean(loss_3))\n",
    "        self.add_metric(loss_1a, name='loss_1a', aggregation=\"mean\")\n",
    "        self.add_metric(loss_1b, name='loss_1b', aggregation=\"mean\")\n",
    "        self.add_metric(loss_1c, name='loss_1c', aggregation=\"mean\")\n",
    "        self.add_metric(loss_1d, name='loss_1d', aggregation=\"mean\")\n",
    "        self.add_metric(loss_2a, name='loss_2a', aggregation=\"mean\")\n",
    "        self.add_metric(loss_2b, name='loss_2b', aggregation=\"mean\")\n",
    "        self.add_metric(loss_3, name='loss_3', aggregation=\"mean\")\n",
    "\n",
    "\n",
    "        dec = self.decoder(z_sample)\n",
    "        return dec, z_sample, p_z_c, p_c_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70842583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_DCGMM_freemove(inp, x_decoded_mean):\n",
    "    x = inp\n",
    "    loss = 80 * tf.keras.losses.MeanSquaredError()(x, x_decoded_mean)\n",
    "    return loss\n",
    "\n",
    "def accuracy_metric(inp, p_c_z):\n",
    "    y = inp\n",
    "    y_pred = tf.math.argmax(p_c_z, axis=-1)\n",
    "    return tf.numpy_function(attack.cluster_acc, [y, y_pred], tf.int64)\n",
    "\n",
    "def csr_matrix_indices(S):\n",
    "    \"\"\"\n",
    "    Return a list of the indices of nonzero entries of a csr_matrix S\n",
    "    \"\"\"\n",
    "    major_dim, minor_dim = S.shape\n",
    "    minor_indices = S.indices\n",
    "\n",
    "    major_indices = np.empty(len(minor_indices), dtype=S.indices.dtype)\n",
    "    scipy.sparse._sparsetools.expandptr(major_dim, S.indptr, major_indices)\n",
    "\n",
    "    return major_indices, minor_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02b3dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AE()\n",
    "ae.compile(optimizer='adam', metrics=['accuracy'], loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d977a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 11s 55ms/step - loss: 2244.3191 - accuracy: 0.3005\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1654.4998 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1197.2363 - accuracy: 0.0015\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 850.7198 - accuracy: 0.0011\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 593.1880 - accuracy: 0.0037\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 407.2518 - accuracy: 0.0015\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 275.9570 - accuracy: 0.0027\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 185.6154 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 123.7330 - accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 83.7596 - accuracy: 0.0177\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 58.1485 - accuracy: 0.0116\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 41.8025 - accuracy: 0.0020\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 31.4436 - accuracy: 3.6493e-04\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 25.1416 - accuracy: 6.4400e-05\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 21.4302 - accuracy: 8.1573e-04\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 19.0243 - accuracy: 0.0031\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 17.3437 - accuracy: 6.0106e-04\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 16.4452 - accuracy: 6.4400e-04\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.9115 - accuracy: 0.0017\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.5518 - accuracy: 6.4400e-05\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.2806 - accuracy: 6.4400e-04\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.3309 - accuracy: 0.0041\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.2784 - accuracy: 0.0056\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0730 - accuracy: 0.0012\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9316 - accuracy: 2.1467e-05\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0775 - accuracy: 3.6493e-04\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9799 - accuracy: 0.0021\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0637 - accuracy: 0.0030\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.1104 - accuracy: 6.8693e-04\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0266 - accuracy: 2.1467e-05\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0561 - accuracy: 4.5080e-04\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0215 - accuracy: 4.2933e-04\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9436 - accuracy: 0.0025\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9314 - accuracy: 0.0018\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0373 - accuracy: 7.2986e-04\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.1774 - accuracy: 6.4400e-05\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9859 - accuracy: 5.3666e-04\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9954 - accuracy: 0.0013\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0042 - accuracy: 8.5866e-05\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9667 - accuracy: 9.4453e-04\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9116 - accuracy: 0.0020\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9904 - accuracy: 2.3613e-04\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.2030 - accuracy: 0.0026\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0731 - accuracy: 0.0017\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8826 - accuracy: 0.0014\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9756 - accuracy: 7.2986e-04\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9635 - accuracy: 0.0043\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0375 - accuracy: 0.0038\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0070 - accuracy: 0.0037\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0232 - accuracy: 0.0060\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0193 - accuracy: 0.0046\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0106 - accuracy: 0.0059\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9985 - accuracy: 0.0124\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9332 - accuracy: 0.0050\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9760 - accuracy: 0.0105\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0780 - accuracy: 0.0067\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9641 - accuracy: 0.0063\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0220 - accuracy: 0.0070\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0755 - accuracy: 0.0086\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9394 - accuracy: 0.0079\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8728 - accuracy: 0.0097\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0040 - accuracy: 0.0028\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0890 - accuracy: 0.0016\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0134 - accuracy: 0.0024\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9105 - accuracy: 0.0015\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0484 - accuracy: 0.0012\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9775 - accuracy: 0.0020\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9925 - accuracy: 0.0017\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8760 - accuracy: 0.0017\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9383 - accuracy: 9.2306e-04\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0856 - accuracy: 0.0020\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0595 - accuracy: 0.0016\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0346 - accuracy: 0.0019\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9172 - accuracy: 0.0015\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8661 - accuracy: 0.0026\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0479 - accuracy: 0.0023\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9791 - accuracy: 0.0022\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0282 - accuracy: 0.0020\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0174 - accuracy: 0.0025\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9625 - accuracy: 0.0027\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8743 - accuracy: 0.0023\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9466 - accuracy: 0.0020\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0936 - accuracy: 0.0027\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0069 - accuracy: 0.0028\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.9380 - accuracy: 0.0013\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0025 - accuracy: 0.0024\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9671 - accuracy: 0.0027\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0000 - accuracy: 0.0027\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9091 - accuracy: 0.0026\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9175 - accuracy: 0.0030\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0322 - accuracy: 0.0026\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0862 - accuracy: 0.0018\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9590 - accuracy: 0.0016\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9002 - accuracy: 0.0014\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9747 - accuracy: 0.0018\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0412 - accuracy: 0.0013\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8714 - accuracy: 5.7960e-04\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9661 - accuracy: 4.2933e-05\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0587 - accuracy: 0.0022\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0112 - accuracy: 0.0034\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9229 - accuracy: 0.0057\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9440 - accuracy: 0.0055\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0259 - accuracy: 0.0017\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9518 - accuracy: 0.0025\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8625 - accuracy: 0.0048\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0824 - accuracy: 0.0032\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0078 - accuracy: 0.0021\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9585 - accuracy: 0.0029\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9055 - accuracy: 0.0036\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9324 - accuracy: 0.0039\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9526 - accuracy: 0.0034\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0012 - accuracy: 0.0016\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0839 - accuracy: 0.0034\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9496 - accuracy: 0.0030\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9354 - accuracy: 0.0022\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9753 - accuracy: 0.0033\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8378 - accuracy: 0.0052\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9610 - accuracy: 0.0035\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0679 - accuracy: 0.0068\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0286 - accuracy: 0.0045\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9180 - accuracy: 0.0055\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9429 - accuracy: 0.0038\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0015 - accuracy: 0.0021\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9252 - accuracy: 0.0032\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8608 - accuracy: 0.0038\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0333 - accuracy: 0.0019\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0449 - accuracy: 0.0027\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0368 - accuracy: 0.0037\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8726 - accuracy: 0.0051\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8449 - accuracy: 0.0047\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9334 - accuracy: 0.0057\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0314 - accuracy: 0.0040\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0177 - accuracy: 0.0037\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9885 - accuracy: 0.0033\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9313 - accuracy: 0.0031\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9970 - accuracy: 0.0036\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8399 - accuracy: 0.0037\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8993 - accuracy: 0.0033\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0222 - accuracy: 0.0029\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9930 - accuracy: 0.0028\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9368 - accuracy: 0.0022\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9698 - accuracy: 0.0027\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0809 - accuracy: 0.0029\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8827 - accuracy: 0.0027\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7954 - accuracy: 0.0028\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0039 - accuracy: 0.0025\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9662 - accuracy: 0.0027\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0340 - accuracy: 0.0021\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9425 - accuracy: 0.0034\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9143 - accuracy: 0.0030\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9594 - accuracy: 0.0028\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9742 - accuracy: 0.0020\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9041 - accuracy: 0.0019\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9274 - accuracy: 0.0027\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0025 - accuracy: 0.0030\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0489 - accuracy: 0.0016\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8935 - accuracy: 0.0023\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9073 - accuracy: 0.0022\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9013 - accuracy: 0.0020\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9297 - accuracy: 0.0023\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9731 - accuracy: 0.0018\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0365 - accuracy: 0.0024\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0485 - accuracy: 0.0024\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9053 - accuracy: 0.0029\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7917 - accuracy: 0.0029\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9249 - accuracy: 0.0029\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9342 - accuracy: 0.0022\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0190 - accuracy: 0.0029\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0222 - accuracy: 0.0027\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9548 - accuracy: 0.0023\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9445 - accuracy: 0.0022\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9319 - accuracy: 0.0029\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8924 - accuracy: 0.0024\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8741 - accuracy: 0.0041\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9643 - accuracy: 0.0043\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.1169 - accuracy: 0.0039\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8591 - accuracy: 0.0062\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9196 - accuracy: 0.0046\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9972 - accuracy: 0.0048\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9267 - accuracy: 0.0053\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8307 - accuracy: 0.0069\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9314 - accuracy: 0.0073\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0943 - accuracy: 0.0079\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9745 - accuracy: 0.0096\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8641 - accuracy: 0.0085\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9292 - accuracy: 0.0098\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9168 - accuracy: 0.0087\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9719 - accuracy: 0.0085\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8959 - accuracy: 0.0090\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9748 - accuracy: 0.0094\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0183 - accuracy: 0.0079\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9552 - accuracy: 0.0077\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9188 - accuracy: 0.0062\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8725 - accuracy: 0.0078\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8623 - accuracy: 0.0069\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0205 - accuracy: 0.0071\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9668 - accuracy: 0.0064\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9952 - accuracy: 0.0061\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9851 - accuracy: 0.0084\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8862 - accuracy: 0.0097\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.7854 - accuracy: 0.0081\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9307 - accuracy: 0.0111\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0688 - accuracy: 0.0122\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9998 - accuracy: 0.0140\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8638 - accuracy: 0.0152\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9596 - accuracy: 0.0150\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8893 - accuracy: 0.0183\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9420 - accuracy: 0.0174\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9051 - accuracy: 0.0203\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9028 - accuracy: 0.0198\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0109 - accuracy: 0.0215\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0002 - accuracy: 0.0202\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9594 - accuracy: 0.0224\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8461 - accuracy: 0.0228\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8708 - accuracy: 0.0216\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9927 - accuracy: 0.0220\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8888 - accuracy: 0.0238\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9836 - accuracy: 0.0260\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9753 - accuracy: 0.0279\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9357 - accuracy: 0.0268\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8683 - accuracy: 0.0329\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9086 - accuracy: 0.0349\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0012 - accuracy: 0.0368\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9269 - accuracy: 0.0390\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8411 - accuracy: 0.0374\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9878 - accuracy: 0.0352\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0006 - accuracy: 0.0297\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9472 - accuracy: 0.0307\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8354 - accuracy: 0.0297\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9212 - accuracy: 0.0207\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9685 - accuracy: 0.0193\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0080 - accuracy: 0.0125\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9472 - accuracy: 0.0083\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8699 - accuracy: 0.0101\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9035 - accuracy: 0.0150\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9995 - accuracy: 0.0069\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8115 - accuracy: 0.0065\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9431 - accuracy: 0.0070\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0676 - accuracy: 0.0061\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9438 - accuracy: 0.0087\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8713 - accuracy: 0.0128\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9046 - accuracy: 0.0114\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9366 - accuracy: 0.0117\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8871 - accuracy: 0.0103\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8730 - accuracy: 0.0112\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0307 - accuracy: 0.0154\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9657 - accuracy: 0.0167\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9442 - accuracy: 0.0172\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8585 - accuracy: 0.0199\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8478 - accuracy: 0.0207\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9008 - accuracy: 0.0255\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9687 - accuracy: 0.0234\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0324 - accuracy: 0.0279\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8952 - accuracy: 0.0288\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8617 - accuracy: 0.0311\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9739 - accuracy: 0.0304\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8271 - accuracy: 0.0320\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9281 - accuracy: 0.0344\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0036 - accuracy: 0.0359\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9927 - accuracy: 0.0408\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8130 - accuracy: 0.0392\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8669 - accuracy: 0.0420\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9875 - accuracy: 0.0399\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9212 - accuracy: 0.0375\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8266 - accuracy: 0.0459\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9913 - accuracy: 0.0450\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9745 - accuracy: 0.0449\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9596 - accuracy: 0.0506\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8844 - accuracy: 0.0478\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8271 - accuracy: 0.0539\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9087 - accuracy: 0.0568\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9568 - accuracy: 0.0537\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9291 - accuracy: 0.0532\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9201 - accuracy: 0.0381\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9458 - accuracy: 0.0314\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9747 - accuracy: 0.0327\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8128 - accuracy: 0.0364\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9071 - accuracy: 0.0339\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9374 - accuracy: 0.0350\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9217 - accuracy: 0.0316\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9400 - accuracy: 0.0263\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9546 - accuracy: 0.0211\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9998 - accuracy: 0.0260\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8523 - accuracy: 0.0273\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7261 - accuracy: 0.0307\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9688 - accuracy: 0.0289\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9955 - accuracy: 0.0308\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0132 - accuracy: 0.0343\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8823 - accuracy: 0.0325\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8510 - accuracy: 0.0385\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8721 - accuracy: 0.0426\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9139 - accuracy: 0.0425\n",
      "Epoch 293/500\n",
      "3/6 [==============>...............] - ETA: 0s - loss: 15.0151 - accuracy: 0.0487"
     ]
    }
   ],
   "source": [
    "ae.fit(X, X, epochs=500, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cbdecd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgmm = DCGMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bbd5ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 36, 80)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 36, 128)      10368       ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 36, 256)      33024       ['dense_164[1][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_66 (Bidirectiona  (None, 36, 1000)    2274000     ['dense_165[1][0]']              \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_67 (Bidirectiona  (None, 1000)        4506000     ['bidirectional_66[1][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 500)          500500      ['bidirectional_67[1][0]']       \n",
      "                                                                                                  \n",
      " repeat_vector_17 (RepeatVector  multiple            0           ['dense_166[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_68 (Bidirectiona  (None, 36, 1000)    3006000     ['repeat_vector_17[1][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_69 (Bidirectiona  (None, 36, 1000)    4506000     ['bidirectional_68[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 36, 256)      256256      ['bidirectional_69[0][0]']       \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 36, 128)      32896       ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " output_geohash (TimeDistribute  (None, 36, 40)      5160        ['dense_169[0][0]']              \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " output_hour (TimeDistributed)  (None, 36, 23)       2967        ['dense_169[0][0]']              \n",
      "                                                                                                  \n",
      " output_geo_context (TimeDistri  (None, 36, 10)      1290        ['dense_169[0][0]']              \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " output_geo_type (TimeDistribut  (None, 36, 7)       903         ['dense_169[0][0]']              \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 36, 80)       0           ['output_geohash[0][0]',         \n",
      "                                                                  'output_hour[0][0]',            \n",
      "                                                                  'output_geo_context[0][0]',     \n",
      "                                                                  'output_geo_type[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,135,364\n",
      "Trainable params: 15,135,364\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(int(max_points),geohash_dim+hour_dim+geographical_context_dim+geo_type_dim))\n",
    "\n",
    "e1 = dcgmm.encoder.dense1(inputs)\n",
    "e2 = dcgmm.encoder.dense2(e1)\n",
    "e3 = dcgmm.encoder.rnn1(e2)\n",
    "e4 = dcgmm.encoder.rnn2(e3)\n",
    "\n",
    "z = dcgmm.encoder.mu(e4)\n",
    "\n",
    "d1 = dcgmm.decoder.repeat_vector(z)\n",
    "d2 = dcgmm.decoder.rnn1(d1)\n",
    "d3 = dcgmm.decoder.rnn2(d2)\n",
    "d4 = dcgmm.decoder.dense1(d3)\n",
    "d5 = dcgmm.decoder.dense2(d4)\n",
    "\n",
    "d_geohash = dcgmm.decoder.output_geohash(d5)\n",
    "d_hour = dcgmm.decoder.output_hour(d5)\n",
    "d_geo_context = dcgmm.decoder.output_geo_context(d5)\n",
    "d_geo_type = dcgmm.decoder.output_geo_type(d5)\n",
    "dec = dcgmm.decoder.concat([d_geohash, d_hour, d_geo_context, d_geo_type])\n",
    "\n",
    "autoencoder = keras.Model(inputs=inputs, outputs=dec)\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa0f6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 13s 56ms/step - loss: 2244.1570 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1654.4304 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1197.1632 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 850.7393 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 593.3298 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 407.1435 - accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 275.8655 - accuracy: 0.1340\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 185.6460 - accuracy: 0.1069\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 123.8119 - accuracy: 0.1087\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 83.8573 - accuracy: 0.0707\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 58.2114 - accuracy: 0.0114\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 41.8436 - accuracy: 0.0035\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 31.4451 - accuracy: 0.0090\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 25.1562 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 21.4480 - accuracy: 0.0037\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 19.0102 - accuracy: 0.0307\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 17.3325 - accuracy: 0.0113\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 16.4463 - accuracy: 0.0138\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.9102 - accuracy: 0.0164\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.5485 - accuracy: 0.0032\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.2783 - accuracy: 0.0070\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 15.3273 - accuracy: 0.0026\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.2818 - accuracy: 4.2933e-05\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0693 - accuracy: 3.4347e-04\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9248 - accuracy: 0.0012\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0724 - accuracy: 0.0041\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9801 - accuracy: 0.0115\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0567 - accuracy: 9.6600e-04\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0986 - accuracy: 0.0012\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0216 - accuracy: 4.7227e-04\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0462 - accuracy: 6.4400e-05\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0164 - accuracy: 4.2933e-05\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9375 - accuracy: 1.0733e-04\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9259 - accuracy: 0.0021\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0297 - accuracy: 0.0012\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.1738 - accuracy: 0.0011\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9827 - accuracy: 0.0013\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9953 - accuracy: 0.0021\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0018 - accuracy: 0.0162\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9584 - accuracy: 0.0023\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9035 - accuracy: 0.0069\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9843 - accuracy: 0.0047\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.1986 - accuracy: 0.0029\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0713 - accuracy: 0.0019\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8787 - accuracy: 6.2253e-04\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9698 - accuracy: 0.0033\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9554 - accuracy: 0.0167\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0333 - accuracy: 0.0012\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9980 - accuracy: 0.0034\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0170 - accuracy: 0.0045\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0148 - accuracy: 0.0133\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0046 - accuracy: 0.0071\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9911 - accuracy: 0.0023\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9253 - accuracy: 0.0011\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9648 - accuracy: 0.0032\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0683 - accuracy: 0.0258\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9584 - accuracy: 0.0031\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0231 - accuracy: 0.0176\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0728 - accuracy: 0.0280\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9398 - accuracy: 0.0298\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8675 - accuracy: 0.0321\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0027 - accuracy: 0.0310\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0883 - accuracy: 0.0319\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0084 - accuracy: 0.0269\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9026 - accuracy: 0.0452\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0444 - accuracy: 0.0189\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9740 - accuracy: 0.0590\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9870 - accuracy: 0.0315\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8740 - accuracy: 0.0261\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9376 - accuracy: 0.0366\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0792 - accuracy: 0.0497\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0556 - accuracy: 0.0360\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0327 - accuracy: 0.0336\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9199 - accuracy: 0.0433\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8622 - accuracy: 0.0363\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0409 - accuracy: 0.0475\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9755 - accuracy: 0.0577\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0312 - accuracy: 0.0705\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0130 - accuracy: 0.0480\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9573 - accuracy: 0.0507\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 14.8687 - accuracy: 0.0542\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9399 - accuracy: 0.0506\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0888 - accuracy: 0.0620\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0007 - accuracy: 0.0526\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9278 - accuracy: 0.0532\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9963 - accuracy: 0.0439\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9632 - accuracy: 0.0430\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0007 - accuracy: 0.0440\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9033 - accuracy: 0.0522\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9104 - accuracy: 0.0554\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0232 - accuracy: 0.0575\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0767 - accuracy: 0.0469\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9553 - accuracy: 0.0383\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8941 - accuracy: 0.0510\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9681 - accuracy: 0.0442\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 15.0363 - accuracy: 0.0442\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8742 - accuracy: 0.0649\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9683 - accuracy: 0.0488\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0578 - accuracy: 0.0394\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0082 - accuracy: 0.0786\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9157 - accuracy: 0.0961\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9478 - accuracy: 0.0332\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0254 - accuracy: 0.0816\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9492 - accuracy: 0.0363\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8549 - accuracy: 0.0432\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0749 - accuracy: 0.0582\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0032 - accuracy: 0.0371\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9551 - accuracy: 0.0550\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9007 - accuracy: 0.0532\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9272 - accuracy: 0.0445\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9491 - accuracy: 0.0571\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9936 - accuracy: 0.0535\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0729 - accuracy: 0.0577\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9419 - accuracy: 0.0482\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9233 - accuracy: 0.0361\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9674 - accuracy: 0.0453\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8303 - accuracy: 0.0536\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9569 - accuracy: 0.0539\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0599 - accuracy: 0.0565\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0223 - accuracy: 0.0440\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9132 - accuracy: 0.0467\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9402 - accuracy: 0.0451\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9983 - accuracy: 0.0508\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9133 - accuracy: 0.0470\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8532 - accuracy: 0.0478\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0276 - accuracy: 0.0467\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0364 - accuracy: 0.0510\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0348 - accuracy: 0.0430\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8683 - accuracy: 0.0427\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8434 - accuracy: 0.0436\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9317 - accuracy: 0.0362\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0279 - accuracy: 0.0484\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0174 - accuracy: 0.0428\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9836 - accuracy: 0.0381\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9273 - accuracy: 0.0400\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9911 - accuracy: 0.0419\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8359 - accuracy: 0.0452\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8989 - accuracy: 0.0408\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0223 - accuracy: 0.0402\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9931 - accuracy: 0.0406\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9336 - accuracy: 0.0418\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9674 - accuracy: 0.0369\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0786 - accuracy: 0.0311\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8846 - accuracy: 0.0348\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7935 - accuracy: 0.0349\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0034 - accuracy: 0.0653\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9670 - accuracy: 0.0480\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0385 - accuracy: 0.0344\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9372 - accuracy: 0.0450\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9129 - accuracy: 0.0419\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9552 - accuracy: 0.0388\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9687 - accuracy: 0.0427\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9064 - accuracy: 0.0396\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9223 - accuracy: 0.0366\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 14.9977 - accuracy: 0.0421\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0486 - accuracy: 0.0377\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8919 - accuracy: 0.0399\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9116 - accuracy: 0.0368\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8962 - accuracy: 0.0344\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9218 - accuracy: 0.0384\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9690 - accuracy: 0.0320\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0357 - accuracy: 0.0328\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0488 - accuracy: 0.0412\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9018 - accuracy: 0.0365\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7926 - accuracy: 0.0361\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9206 - accuracy: 0.0378\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9307 - accuracy: 0.0320\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 15.0169 - accuracy: 0.0343\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0158 - accuracy: 0.0408\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9515 - accuracy: 0.0372\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9390 - accuracy: 0.0328\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9274 - accuracy: 0.0356\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8910 - accuracy: 0.0379\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8743 - accuracy: 0.0335\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9619 - accuracy: 0.0333\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.1152 - accuracy: 0.0371\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8617 - accuracy: 0.0303\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9193 - accuracy: 0.0353\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9948 - accuracy: 0.0275\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9228 - accuracy: 0.0360\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8282 - accuracy: 0.0289\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9324 - accuracy: 0.0310\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0944 - accuracy: 0.0311\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9729 - accuracy: 0.0378\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8598 - accuracy: 0.0377\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9284 - accuracy: 0.0473\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9164 - accuracy: 0.0458\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9724 - accuracy: 0.0409\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8913 - accuracy: 0.0381\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9781 - accuracy: 0.0285\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0223 - accuracy: 0.0436\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9536 - accuracy: 0.0304\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9174 - accuracy: 0.0554\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8703 - accuracy: 0.0275\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8595 - accuracy: 0.0302\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0162 - accuracy: 0.0226\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9647 - accuracy: 0.0337\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9972 - accuracy: 0.0316\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9823 - accuracy: 0.0289\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8842 - accuracy: 0.0274\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.7829 - accuracy: 0.0298\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9276 - accuracy: 0.0283\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0682 - accuracy: 0.0371\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9994 - accuracy: 0.0345\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8617 - accuracy: 0.0334\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9550 - accuracy: 0.0282\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8906 - accuracy: 0.0293\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9408 - accuracy: 0.0295\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9027 - accuracy: 0.0319\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9025 - accuracy: 0.0312\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0045 - accuracy: 0.0333\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0010 - accuracy: 0.0350\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9678 - accuracy: 0.0190\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8527 - accuracy: 0.0745\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8699 - accuracy: 0.0296\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9943 - accuracy: 0.0410\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8917 - accuracy: 0.0283\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9885 - accuracy: 0.0337\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9744 - accuracy: 0.0317\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9308 - accuracy: 0.0238\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8693 - accuracy: 0.0129\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9088 - accuracy: 0.0215\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0029 - accuracy: 0.0226\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9276 - accuracy: 0.0313\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8377 - accuracy: 0.0414\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9838 - accuracy: 0.0265\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9995 - accuracy: 0.0186\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9517 - accuracy: 0.0268\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8269 - accuracy: 0.0223\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9094 - accuracy: 0.0263\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9590 - accuracy: 0.0295\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 15.0000 - accuracy: 0.0244\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 14.9428 - accuracy: 0.0248\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.8614 - accuracy: 0.0279\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8977 - accuracy: 0.0352\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 14.9895 - accuracy: 0.0266\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.8049 - accuracy: 0.0279\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.9428 - accuracy: 0.0294\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 15.0607 - accuracy: 0.0334\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9388 - accuracy: 0.0249\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8660 - accuracy: 0.0286\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9078 - accuracy: 0.0254\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9394 - accuracy: 0.0261\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8826 - accuracy: 0.0291\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8683 - accuracy: 0.0269\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0307 - accuracy: 0.0316\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9685 - accuracy: 0.0289\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9477 - accuracy: 0.0270\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8584 - accuracy: 0.0277\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8418 - accuracy: 0.0309\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9006 - accuracy: 0.0263\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9723 - accuracy: 0.0232\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0384 - accuracy: 0.0272\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9003 - accuracy: 0.0286\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8638 - accuracy: 0.0273\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9762 - accuracy: 0.0255\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8289 - accuracy: 0.0207\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9348 - accuracy: 0.0210\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0038 - accuracy: 0.0234\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9935 - accuracy: 0.0278\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8180 - accuracy: 0.0255\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8623 - accuracy: 0.0237\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9862 - accuracy: 0.0193\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9217 - accuracy: 0.0248\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8292 - accuracy: 0.0255\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9905 - accuracy: 0.0186\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9743 - accuracy: 0.0190\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9625 - accuracy: 0.0209\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8832 - accuracy: 0.0205\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8304 - accuracy: 0.0234\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9070 - accuracy: 0.0224\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9584 - accuracy: 0.0209\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9279 - accuracy: 0.0207\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9178 - accuracy: 0.0195\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9462 - accuracy: 0.0211\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9720 - accuracy: 0.0208\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8128 - accuracy: 0.0210\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9106 - accuracy: 0.0200\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9369 - accuracy: 0.0191\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9155 - accuracy: 0.0194\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9359 - accuracy: 0.0202\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9563 - accuracy: 0.0224\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0009 - accuracy: 0.0176\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8541 - accuracy: 0.0174\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7228 - accuracy: 0.0184\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9667 - accuracy: 0.0203\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0011 - accuracy: 0.0163\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0197 - accuracy: 0.0198\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8824 - accuracy: 0.0182\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8496 - accuracy: 0.0169\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8734 - accuracy: 0.0196\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9141 - accuracy: 0.0188\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9394 - accuracy: 0.0177\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8957 - accuracy: 0.0202\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9694 - accuracy: 0.0202\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0195 - accuracy: 0.0172\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8278 - accuracy: 0.0151\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8566 - accuracy: 0.0193\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9027 - accuracy: 0.0207\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9197 - accuracy: 0.0193\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8951 - accuracy: 0.0182\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9691 - accuracy: 0.0181\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9810 - accuracy: 0.0193\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9076 - accuracy: 0.0191\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8014 - accuracy: 0.0193\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9121 - accuracy: 0.0210\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8933 - accuracy: 0.0186\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9889 - accuracy: 0.0200\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9162 - accuracy: 0.0214\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8995 - accuracy: 0.0202\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9434 - accuracy: 0.0205\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8907 - accuracy: 0.0198\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8520 - accuracy: 0.0209\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8606 - accuracy: 0.0231\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9425 - accuracy: 0.0209\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 15.0533 - accuracy: 0.0236\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8776 - accuracy: 0.0226\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8834 - accuracy: 0.0215\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9263 - accuracy: 0.0230\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8541 - accuracy: 0.0233\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7877 - accuracy: 0.0225\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9270 - accuracy: 0.0224\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.1125 - accuracy: 0.0247\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9265 - accuracy: 0.0195\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8134 - accuracy: 0.0240\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9300 - accuracy: 0.0216\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8381 - accuracy: 0.0224\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9121 - accuracy: 0.0229\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9040 - accuracy: 0.0245\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9643 - accuracy: 0.0228\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9316 - accuracy: 0.0251\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9217 - accuracy: 0.0235\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8674 - accuracy: 0.0266\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8502 - accuracy: 0.0280\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8740 - accuracy: 0.0255\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9855 - accuracy: 0.0257\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9209 - accuracy: 0.0224\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9533 - accuracy: 0.0222\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9144 - accuracy: 0.0229\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8520 - accuracy: 0.0227\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8007 - accuracy: 0.0201\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8905 - accuracy: 0.0242\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0416 - accuracy: 0.0257\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9850 - accuracy: 0.0222\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8071 - accuracy: 0.0216\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9042 - accuracy: 0.0237\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9077 - accuracy: 0.0250\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9303 - accuracy: 0.0207\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8527 - accuracy: 0.0204\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8548 - accuracy: 0.0220\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9522 - accuracy: 0.0234\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9779 - accuracy: 0.0249\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9411 - accuracy: 0.0251\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8151 - accuracy: 0.0235\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8381 - accuracy: 0.0250\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9785 - accuracy: 0.0257\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8302 - accuracy: 0.0269\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9369 - accuracy: 0.0339\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9902 - accuracy: 0.0362\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9121 - accuracy: 0.0336\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8170 - accuracy: 0.0375\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8733 - accuracy: 0.0391\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9427 - accuracy: 0.0365\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8807 - accuracy: 0.0417\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8593 - accuracy: 0.0427\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9977 - accuracy: 0.0397\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9491 - accuracy: 0.0446\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9040 - accuracy: 0.0434\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.7763 - accuracy: 0.0427\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8437 - accuracy: 0.0450\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9476 - accuracy: 0.0434\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9912 - accuracy: 0.0437\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9388 - accuracy: 0.0508\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8698 - accuracy: 0.0428\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8334 - accuracy: 0.0466\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9266 - accuracy: 0.0422\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8238 - accuracy: 0.0370\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9182 - accuracy: 0.0338\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 15.0051 - accuracy: 0.0325\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9208 - accuracy: 0.0361\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8227 - accuracy: 0.0297\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8628 - accuracy: 0.0302\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9657 - accuracy: 0.0290\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8887 - accuracy: 0.0275\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8343 - accuracy: 0.0371\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9959 - accuracy: 0.0368\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8733 - accuracy: 0.0444\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9096 - accuracy: 0.0406\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8595 - accuracy: 0.0471\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8319 - accuracy: 0.0532\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8995 - accuracy: 0.0524\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9619 - accuracy: 0.0592\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9394 - accuracy: 0.0651\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8620 - accuracy: 0.0701\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9082 - accuracy: 0.0716\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9534 - accuracy: 0.0595\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7742 - accuracy: 0.0536\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8865 - accuracy: 0.0500\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9505 - accuracy: 0.0362\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9610 - accuracy: 0.0379\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8581 - accuracy: 0.0210\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8745 - accuracy: 0.0196\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9936 - accuracy: 0.0211\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8771 - accuracy: 0.0134\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7348 - accuracy: 0.0091\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9386 - accuracy: 0.0101\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9856 - accuracy: 0.0150\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9422 - accuracy: 0.0158\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8458 - accuracy: 0.0112\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8384 - accuracy: 0.0126\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8618 - accuracy: 0.0172\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9431 - accuracy: 0.0187\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9517 - accuracy: 0.0217\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9163 - accuracy: 0.0254\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8559 - accuracy: 0.0291\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9100 - accuracy: 0.0310\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7797 - accuracy: 0.0374\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8970 - accuracy: 0.0377\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.9332 - accuracy: 0.0441\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8990 - accuracy: 0.0414\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9062 - accuracy: 0.0538\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9275 - accuracy: 0.0454\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9638 - accuracy: 0.0483\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8172 - accuracy: 0.0479\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7750 - accuracy: 0.0502\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9275 - accuracy: 0.0535\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9222 - accuracy: 0.0536\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9808 - accuracy: 0.0461\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8592 - accuracy: 0.0397\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.8319 - accuracy: 0.0370\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8923 - accuracy: 0.0317\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9109 - accuracy: 0.0381\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8840 - accuracy: 0.0449\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8724 - accuracy: 0.0408\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9133 - accuracy: 0.0419\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9936 - accuracy: 0.0495\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8294 - accuracy: 0.0446\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8427 - accuracy: 0.0302\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8786 - accuracy: 0.0326\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9254 - accuracy: 0.0342\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8296 - accuracy: 0.0345\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9347 - accuracy: 0.0284\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0014 - accuracy: 0.0350\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8570 - accuracy: 0.0295\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7582 - accuracy: 0.0260\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8960 - accuracy: 0.0286\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8818 - accuracy: 0.0293\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9473 - accuracy: 0.0374\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9305 - accuracy: 0.0294\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 14.8710 - accuracy: 0.0238\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.9368 - accuracy: 0.0196\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8759 - accuracy: 0.0217\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 14.7935 - accuracy: 0.0207\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8257 - accuracy: 0.0227\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9351 - accuracy: 0.0271\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0314 - accuracy: 0.0277\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8398 - accuracy: 0.0284\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8722 - accuracy: 0.0341\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8637 - accuracy: 0.0297\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8415 - accuracy: 0.0340\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8166 - accuracy: 0.0326\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9337 - accuracy: 0.0315\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 15.0539 - accuracy: 0.0298\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9138 - accuracy: 0.0278\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7538 - accuracy: 0.0272\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8619 - accuracy: 0.0227\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8330 - accuracy: 0.0166\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9244 - accuracy: 0.0133\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9177 - accuracy: 0.0162\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9355 - accuracy: 0.0105\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8830 - accuracy: 0.0129\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8757 - accuracy: 0.0127\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9002 - accuracy: 0.0112\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.8225 - accuracy: 0.0101\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8323 - accuracy: 0.0076\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9704 - accuracy: 0.0083\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8622 - accuracy: 0.0066\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8987 - accuracy: 0.0098\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.9500 - accuracy: 0.0109\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8653 - accuracy: 0.0154\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.7702 - accuracy: 0.0172\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8655 - accuracy: 0.0205\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9770 - accuracy: 0.0240\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9438 - accuracy: 0.0264\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8018 - accuracy: 0.0295\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9026 - accuracy: 0.0297\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8810 - accuracy: 0.0323\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8916 - accuracy: 0.0336\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7670 - accuracy: 0.0320\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8535 - accuracy: 0.0341\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 15.0043 - accuracy: 0.0402\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9524 - accuracy: 0.0416\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.8901 - accuracy: 0.0442\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 14.7991 - accuracy: 0.0482\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.7760 - accuracy: 0.0475\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 14.9282 - accuracy: 0.0573\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8490 - accuracy: 0.0600\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9578 - accuracy: 0.0630\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 14.9680 - accuracy: 0.0630\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 14.8702 - accuracy: 0.0611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e625712e0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', \n",
    "                             metrics=['accuracy'],\n",
    "                            loss='mse')\n",
    "\n",
    "autoencoder.fit(X, X,\n",
    "                epochs=500,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "72f3baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of ml constraints: 1050, cl constraints: 54465.\n",
      " \n",
      "(1294, 1294)\n",
      "  (0, 14)\t-1.0\n",
      "  (0, 26)\t-1.0\n",
      "  (0, 59)\t-1.0\n",
      "  (0, 235)\t-1.0\n",
      "  (0, 258)\t-1.0\n",
      "  (0, 296)\t-1.0\n",
      "  (0, 344)\t-1.0\n",
      "  (0, 374)\t-1.0\n",
      "  (0, 405)\t-1.0\n",
      "  (0, 465)\t-1.0\n",
      "  (0, 515)\t-1.0\n",
      "  (0, 516)\t-1.0\n",
      "  (0, 651)\t-1.0\n",
      "  (0, 654)\t-1.0\n",
      "  (0, 732)\t-1.0\n",
      "  (0, 738)\t-1.0\n",
      "  (0, 783)\t-1.0\n",
      "  (0, 806)\t-1.0\n",
      "  (0, 819)\t-1.0\n",
      "  (0, 852)\t-1.0\n",
      "  (0, 871)\t-1.0\n",
      "  (0, 890)\t-1.0\n",
      "  (0, 893)\t-1.0\n",
      "  (0, 960)\t-1.0\n",
      "  (0, 1012)\t-1.0\n",
      "  :\t:\n",
      "  (1293, 864)\t-1.0\n",
      "  (1293, 866)\t-1.0\n",
      "  (1293, 887)\t-1.0\n",
      "  (1293, 891)\t-1.0\n",
      "  (1293, 902)\t-1.0\n",
      "  (1293, 953)\t-1.0\n",
      "  (1293, 997)\t-1.0\n",
      "  (1293, 999)\t-1.0\n",
      "  (1293, 1000)\t-1.0\n",
      "  (1293, 1011)\t-1.0\n",
      "  (1293, 1036)\t-1.0\n",
      "  (1293, 1069)\t-1.0\n",
      "  (1293, 1077)\t-1.0\n",
      "  (1293, 1089)\t-1.0\n",
      "  (1293, 1112)\t-1.0\n",
      "  (1293, 1115)\t-1.0\n",
      "  (1293, 1120)\t-1.0\n",
      "  (1293, 1140)\t-1.0\n",
      "  (1293, 1142)\t-1.0\n",
      "  (1293, 1146)\t-1.0\n",
      "  (1293, 1149)\t-1.0\n",
      "  (1293, 1160)\t-1.0\n",
      "  (1293, 1170)\t-1.0\n",
      "  (1293, 1173)\t-1.0\n",
      "  (1293, 1238)\t-1.0\n",
      "[115 929 528 ... 359 728 522]\n",
      "[-1. -1. -1. ... -1. -1. -1.]\n",
      "\n",
      "Number of ml constraints: 0, cl constraints: 0.\n",
      " \n",
      "(200, 200)\n",
      "\n",
      "[]\n",
      "[]\n",
      "Epoch 1/500\n",
      "40/40 [==============================] - 38s 245ms/step - loss: 69.4569 - output_1_loss: 4.2173 - output_4_accuracy_metric: 0.1016 - loss_1a: 126.0462 - loss_1b: 227.1980 - loss_1c: 7.9494 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -626.7408 - loss_2a_c: 68.6853 - val_loss: -51.0030 - val_output_1_loss: 3.1845 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 128.2538 - val_loss_1b: 253.2208 - val_loss_1c: 0.3668 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -682.4837 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 2/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 260.3178 - output_1_loss: 3.0657 - output_4_accuracy_metric: 0.2367 - loss_1a: 130.6147 - loss_1b: 249.9581 - loss_1c: 0.2105 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -684.2474 - loss_2a_c: 317.1133 - val_loss: -60.1108 - val_output_1_loss: 3.2736 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 133.1152 - val_loss_1b: 250.1312 - val_loss_1c: 0.1003 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -689.5316 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 3/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 258.7224 - output_1_loss: 3.0550 - output_4_accuracy_metric: 0.2336 - loss_1a: 135.5085 - loss_1b: 249.8055 - loss_1c: 0.0657 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -694.0317 - loss_2a_c: 321.5079 - val_loss: -65.7682 - val_output_1_loss: 3.1426 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 138.0289 - val_loss_1b: 249.6026 - val_loss_1c: 0.0452 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -698.8919 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 4/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 243.9281 - output_1_loss: 3.0301 - output_4_accuracy_metric: 0.2367 - loss_1a: 140.4334 - loss_1b: 249.8870 - loss_1c: 0.0337 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -703.9988 - loss_2a_c: 311.9049 - val_loss: -69.7320 - val_output_1_loss: 3.1763 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 142.9637 - val_loss_1b: 249.1329 - val_loss_1c: 0.0295 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -708.3098 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 5/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 223.3920 - output_1_loss: 2.9052 - output_4_accuracy_metric: 0.2156 - loss_1a: 145.3744 - loss_1b: 249.9223 - loss_1c: 0.0226 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -713.9293 - loss_2a_c: 296.4427 - val_loss: -74.5846 - val_output_1_loss: 3.2124 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 147.9106 - val_loss_1b: 250.0660 - val_loss_1c: 0.0196 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -719.1524 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 6/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 238.5137 - output_1_loss: 2.9518 - output_4_accuracy_metric: 0.2313 - loss_1a: 150.3244 - loss_1b: 249.8905 - loss_1c: 0.0210 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -723.8015 - loss_2a_c: 316.5707 - val_loss: -80.3229 - val_output_1_loss: 3.1902 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 152.8631 - val_loss_1b: 249.9559 - val_loss_1c: 0.0233 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -728.9465 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 7/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 225.2674 - output_1_loss: 2.9843 - output_4_accuracy_metric: 0.2164 - loss_1a: 155.2794 - loss_1b: 249.9214 - loss_1c: 0.0241 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -733.7484 - loss_2a_c: 308.3242 - val_loss: -85.4870 - val_output_1_loss: 3.0929 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 157.8201 - val_loss_1b: 250.7369 - val_loss_1c: 0.0239 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -739.6440 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 8/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 246.6800 - output_1_loss: 2.9808 - output_4_accuracy_metric: 0.2344 - loss_1a: 160.2378 - loss_1b: 249.9319 - loss_1c: 0.0248 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -743.6777 - loss_2a_c: 334.7458 - val_loss: -90.2794 - val_output_1_loss: 2.9603 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 162.7798 - val_loss_1b: 249.8526 - val_loss_1c: 0.0210 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -748.6819 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 9/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 220.6725 - output_1_loss: 3.0143 - output_4_accuracy_metric: 0.2352 - loss_1a: 165.1978 - loss_1b: 249.9063 - loss_1c: 0.0247 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -753.5692 - loss_2a_c: 313.5869 - val_loss: -94.7617 - val_output_1_loss: 3.1901 - val_output_4_accuracy_metric: 0.1302 - val_loss_1a: 167.7404 - val_loss_1b: 249.7185 - val_loss_1c: 0.0243 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -758.4682 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 10/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 220.6721 - output_1_loss: 2.9400 - output_4_accuracy_metric: 0.2531 - loss_1a: 170.1586 - loss_1b: 249.8435 - loss_1c: 0.0302 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -763.3958 - loss_2a_c: 318.4696 - val_loss: -100.0252 - val_output_1_loss: 3.1383 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 172.7011 - val_loss_1b: 252.5109 - val_loss_1c: 0.0262 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -771.1570 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 11/500\n",
      "40/40 [==============================] - 4s 92ms/step - loss: 57.6058 - output_1_loss: 3.0724 - output_4_accuracy_metric: 0.1625 - loss_1a: 175.1198 - loss_1b: 250.1720 - loss_1c: 0.0534 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -773.4874 - loss_2a_c: 160.1029 - val_loss: -104.9685 - val_output_1_loss: 3.1489 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 177.6636 - val_loss_1b: 249.1870 - val_loss_1c: 0.0542 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -777.7246 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 12/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 104.9038 - output_1_loss: 3.1284 - output_4_accuracy_metric: 0.1797 - loss_1a: 180.0796 - loss_1b: 249.6093 - loss_1c: 0.0581 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -782.9492 - loss_2a_c: 212.2951 - val_loss: -110.6205 - val_output_1_loss: 3.0012 - val_output_4_accuracy_metric: 0.1302 - val_loss_1a: 182.6210 - val_loss_1b: 250.0181 - val_loss_1c: 0.0472 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -788.5231 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 90ms/step - loss: 212.2177 - output_1_loss: 2.8866 - output_4_accuracy_metric: 0.2313 - loss_1a: 185.0391 - loss_1b: 249.9150 - loss_1c: 0.0549 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -793.2595 - loss_2a_c: 325.1429 - val_loss: -114.6581 - val_output_1_loss: 3.0599 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 187.5813 - val_loss_1b: 249.6274 - val_loss_1c: 0.0564 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -798.0515 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 14/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 201.1147 - output_1_loss: 2.8524 - output_4_accuracy_metric: 0.2422 - loss_1a: 189.9983 - loss_1b: 249.7713 - loss_1c: 0.0703 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -802.9781 - loss_2a_c: 318.9037 - val_loss: -119.2122 - val_output_1_loss: 3.0998 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 192.5392 - val_loss_1b: 249.2120 - val_loss_1c: 0.0690 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -807.4941 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 15/500\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 177.4272 - output_1_loss: 2.9468 - output_4_accuracy_metric: 0.2320 - loss_1a: 194.9566 - loss_1b: 249.9329 - loss_1c: 0.0802 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -813.0976 - loss_2a_c: 300.1319 - val_loss: -125.2520 - val_output_1_loss: 3.1103 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 197.4982 - val_loss_1b: 250.5083 - val_loss_1c: 0.0663 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -818.7674 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 16/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 194.5039 - output_1_loss: 2.8558 - output_4_accuracy_metric: 0.2227 - loss_1a: 199.9152 - loss_1b: 249.8833 - loss_1c: 0.0836 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -822.9782 - loss_2a_c: 322.3759 - val_loss: -129.9783 - val_output_1_loss: 3.0748 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 202.4559 - val_loss_1b: 250.0849 - val_loss_1c: 0.1161 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -828.2591 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 17/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 176.3011 - output_1_loss: 2.7404 - output_4_accuracy_metric: 0.2250 - loss_1a: 204.8722 - loss_1b: 249.8913 - loss_1c: 0.0865 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -832.9022 - loss_2a_c: 309.3008 - val_loss: -134.9055 - val_output_1_loss: 2.9622 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 207.4123 - val_loss_1b: 249.1966 - val_loss_1c: 0.0729 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -837.2896 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 18/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 175.3629 - output_1_loss: 2.9098 - output_4_accuracy_metric: 0.2313 - loss_1a: 209.8281 - loss_1b: 249.8689 - loss_1c: 0.0838 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -842.7944 - loss_2a_c: 313.1528 - val_loss: -139.3024 - val_output_1_loss: 3.2827 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 212.3675 - val_loss_1b: 249.7506 - val_loss_1c: 0.1491 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -847.7499 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 19/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 176.5498 - output_1_loss: 2.8780 - output_4_accuracy_metric: 0.2211 - loss_1a: 214.7830 - loss_1b: 249.8386 - loss_1c: 0.1285 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -852.6653 - loss_2a_c: 319.1750 - val_loss: -144.8423 - val_output_1_loss: 3.0686 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 217.3221 - val_loss_1b: 249.3020 - val_loss_1c: 0.0910 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -857.2009 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 20/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 170.6019 - output_1_loss: 2.8678 - output_4_accuracy_metric: 0.2359 - loss_1a: 219.7367 - loss_1b: 249.8564 - loss_1c: 0.1178 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -862.5920 - loss_2a_c: 318.3069 - val_loss: -150.3067 - val_output_1_loss: 2.9601 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 222.2749 - val_loss_1b: 249.6239 - val_loss_1c: 0.1284 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -867.4321 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 21/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 103.9226 - output_1_loss: 2.9346 - output_4_accuracy_metric: 0.1969 - loss_1a: 224.6885 - loss_1b: 249.8114 - loss_1c: 0.1302 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -872.4471 - loss_2a_c: 256.5118 - val_loss: -154.9483 - val_output_1_loss: 3.2092 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 227.2258 - val_loss_1b: 249.6360 - val_loss_1c: 0.1395 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -877.3469 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 22/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -25.3086 - output_1_loss: 3.1029 - output_4_accuracy_metric: 0.1258 - loss_1a: 229.6391 - loss_1b: 249.8187 - loss_1c: 0.1325 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -882.3386 - loss_2a_c: 131.9995 - val_loss: -159.3900 - val_output_1_loss: 2.8892 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 232.1754 - val_loss_1b: 251.0229 - val_loss_1c: 0.1292 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -888.6248 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 23/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 154.5476 - output_1_loss: 2.7813 - output_4_accuracy_metric: 0.2336 - loss_1a: 234.5875 - loss_1b: 249.8439 - loss_1c: 0.1128 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -892.2722 - loss_2a_c: 317.1675 - val_loss: -164.1870 - val_output_1_loss: 2.8970 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 237.1230 - val_loss_1b: 249.3630 - val_loss_1c: 0.0989 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -896.8715 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 24/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 146.7222 - output_1_loss: 2.7886 - output_4_accuracy_metric: 0.2375 - loss_1a: 239.5345 - loss_1b: 249.8744 - loss_1c: 0.0902 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -902.2075 - loss_2a_c: 314.3464 - val_loss: -170.2002 - val_output_1_loss: 3.0883 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 242.0695 - val_loss_1b: 250.9730 - val_loss_1c: 0.1021 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -908.3715 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 25/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 135.6509 - output_1_loss: 2.8099 - output_4_accuracy_metric: 0.2117 - loss_1a: 244.4805 - loss_1b: 249.8669 - loss_1c: 0.1171 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -912.0794 - loss_2a_c: 308.2158 - val_loss: -175.1591 - val_output_1_loss: 2.8982 - val_output_4_accuracy_metric: 0.1719 - val_loss_1a: 247.0146 - val_loss_1b: 249.3703 - val_loss_1c: 0.1309 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -916.6475 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 26/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 131.7337 - output_1_loss: 2.7898 - output_4_accuracy_metric: 0.2305 - loss_1a: 249.4246 - loss_1b: 249.8474 - loss_1c: 0.1095 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -921.9532 - loss_2a_c: 309.2464 - val_loss: -179.5096 - val_output_1_loss: 3.0908 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 251.9579 - val_loss_1b: 249.7107 - val_loss_1c: 0.1097 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -926.8889 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 89ms/step - loss: 134.6829 - output_1_loss: 2.8848 - output_4_accuracy_metric: 0.2305 - loss_1a: 254.3669 - loss_1b: 249.8584 - loss_1c: 0.1054 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -931.8528 - loss_2a_c: 317.0591 - val_loss: -184.3636 - val_output_1_loss: 2.9846 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 256.8994 - val_loss_1b: 250.3503 - val_loss_1c: 0.1001 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -937.4080 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 28/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 141.1428 - output_1_loss: 2.7976 - output_4_accuracy_metric: 0.2258 - loss_1a: 259.3078 - loss_1b: 249.8633 - loss_1c: 0.0998 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -941.7401 - loss_2a_c: 328.5066 - val_loss: -189.2027 - val_output_1_loss: 3.0693 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 261.8394 - val_loss_1b: 249.3906 - val_loss_1c: 0.1170 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -946.3251 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 29/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 124.8931 - output_1_loss: 2.7884 - output_4_accuracy_metric: 0.2211 - loss_1a: 264.2468 - loss_1b: 249.8663 - loss_1c: 0.0895 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -951.6211 - loss_2a_c: 317.3303 - val_loss: -194.7081 - val_output_1_loss: 3.1755 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 266.7776 - val_loss_1b: 249.7296 - val_loss_1c: 0.1138 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -956.5432 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 30/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 125.7755 - output_1_loss: 2.8336 - output_4_accuracy_metric: 0.2352 - loss_1a: 269.1845 - loss_1b: 249.8733 - loss_1c: 0.1169 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -961.4966 - loss_2a_c: 323.0813 - val_loss: -199.5983 - val_output_1_loss: 3.0967 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 271.7145 - val_loss_1b: 248.9251 - val_loss_1c: 0.1286 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -965.6021 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 31/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 99.0448 - output_1_loss: 2.9259 - output_4_accuracy_metric: 0.2250 - loss_1a: 274.1198 - loss_1b: 249.8062 - loss_1c: 0.1334 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -971.2939 - loss_2a_c: 301.1084 - val_loss: -204.0056 - val_output_1_loss: 3.0233 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 276.6483 - val_loss_1b: 249.0704 - val_loss_1c: 0.1329 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -975.6148 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 32/500\n",
      "40/40 [==============================] - 3s 87ms/step - loss: -104.6376 - output_1_loss: 3.0821 - output_4_accuracy_metric: 0.1148 - loss_1a: 279.0530 - loss_1b: 249.7967 - loss_1c: 0.1528 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -981.1436 - loss_2a_c: 102.1599 - val_loss: -208.6518 - val_output_1_loss: 3.0860 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 281.5806 - val_loss_1b: 249.5259 - val_loss_1c: 0.1602 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -985.9284 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 33/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 74.0922 - output_1_loss: 2.8165 - output_4_accuracy_metric: 0.2219 - loss_1a: 283.9848 - loss_1b: 249.8667 - loss_1c: 0.1357 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -991.0790 - loss_2a_c: 286.0801 - val_loss: -214.3497 - val_output_1_loss: 3.1357 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 286.5120 - val_loss_1b: 249.4226 - val_loss_1c: 0.0953 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -995.6932 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 34/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 94.4270 - output_1_loss: 2.8036 - output_4_accuracy_metric: 0.2359 - loss_1a: 288.9152 - loss_1b: 249.8548 - loss_1c: 0.0912 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1000.9359 - loss_2a_c: 311.5252 - val_loss: -219.4293 - val_output_1_loss: 2.9889 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 291.4411 - val_loss_1b: 249.5427 - val_loss_1c: 0.1026 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1005.6818 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 35/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 88.2155 - output_1_loss: 2.8224 - output_4_accuracy_metric: 0.2414 - loss_1a: 293.8433 - loss_1b: 249.8528 - loss_1c: 0.1034 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1010.7917 - loss_2a_c: 310.2231 - val_loss: -224.0812 - val_output_1_loss: 2.8922 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 296.3682 - val_loss_1b: 250.1914 - val_loss_1c: 0.1383 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1016.1746 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 36/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 82.3009 - output_1_loss: 2.7848 - output_4_accuracy_metric: 0.2320 - loss_1a: 298.7692 - loss_1b: 249.8633 - loss_1c: 0.0890 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1020.6505 - loss_2a_c: 309.2465 - val_loss: -228.8230 - val_output_1_loss: 3.0784 - val_output_4_accuracy_metric: 0.1719 - val_loss_1a: 301.2930 - val_loss_1b: 249.4835 - val_loss_1c: 0.0854 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1025.3202 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 37/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 77.6517 - output_1_loss: 2.8783 - output_4_accuracy_metric: 0.2250 - loss_1a: 303.6935 - loss_1b: 249.8636 - loss_1c: 0.1088 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1030.4968 - loss_2a_c: 309.3550 - val_loss: -233.7530 - val_output_1_loss: 3.0022 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 306.2166 - val_loss_1b: 248.3301 - val_loss_1c: 0.1083 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1033.9999 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 38/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 93.5714 - output_1_loss: 2.8206 - output_4_accuracy_metric: 0.2172 - loss_1a: 308.6153 - loss_1b: 249.7793 - loss_1c: 0.1273 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1040.2336 - loss_2a_c: 330.2427 - val_loss: -239.5008 - val_output_1_loss: 2.7915 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 311.1364 - val_loss_1b: 250.2987 - val_loss_1c: 0.1082 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1045.8143 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 39/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 79.2276 - output_1_loss: 2.7999 - output_4_accuracy_metric: 0.2445 - loss_1a: 313.5348 - loss_1b: 249.8509 - loss_1c: 0.1166 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1050.1663 - loss_2a_c: 320.9653 - val_loss: -243.9259 - val_output_1_loss: 3.1086 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 316.0563 - val_loss_1b: 249.2532 - val_loss_1c: 0.0930 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1054.6156 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 40/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 71.0752 - output_1_loss: 2.9312 - output_4_accuracy_metric: 0.2305 - loss_1a: 318.4540 - loss_1b: 249.8661 - loss_1c: 0.1243 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1059.9840 - loss_2a_c: 317.4931 - val_loss: -248.0319 - val_output_1_loss: 3.0462 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 320.9746 - val_loss_1b: 243.2849 - val_loss_1c: 0.1274 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1058.3593 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 90ms/step - loss: 58.5404 - output_1_loss: 2.8502 - output_4_accuracy_metric: 0.2250 - loss_1a: 323.3700 - loss_1b: 249.7694 - loss_1c: 0.1250 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1069.7258 - loss_2a_c: 309.8976 - val_loss: -253.1932 - val_output_1_loss: 2.9006 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 325.8888 - val_loss_1b: 250.3189 - val_loss_1c: 0.1301 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1075.3257 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 42/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -56.5260 - output_1_loss: 2.9658 - output_4_accuracy_metric: 0.1703 - loss_1a: 328.2842 - loss_1b: 249.7436 - loss_1c: 0.1587 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1079.5355 - loss_2a_c: 199.6539 - val_loss: -258.7449 - val_output_1_loss: 2.9685 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 330.8017 - val_loss_1b: 250.3024 - val_loss_1c: 0.1513 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1085.1173 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 43/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -80.6126 - output_1_loss: 3.0444 - output_4_accuracy_metric: 0.1695 - loss_1a: 333.1956 - loss_1b: 249.7587 - loss_1c: 0.1638 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1089.2769 - loss_2a_c: 180.2853 - val_loss: -263.3910 - val_output_1_loss: 3.1986 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 335.7117 - val_loss_1b: 248.7821 - val_loss_1c: 0.1075 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1093.3724 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 44/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 45.2073 - output_1_loss: 2.7234 - output_4_accuracy_metric: 0.2461 - loss_1a: 338.1049 - loss_1b: 249.8556 - loss_1c: 0.1023 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1099.2922 - loss_2a_c: 311.5252 - val_loss: -268.0525 - val_output_1_loss: 3.1355 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 340.6206 - val_loss_1b: 248.4731 - val_loss_1c: 0.1125 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1102.9501 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 45/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 50.1854 - output_1_loss: 2.8433 - output_4_accuracy_metric: 0.2328 - loss_1a: 343.0118 - loss_1b: 249.6959 - loss_1c: 0.1278 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1108.8390 - loss_2a_c: 321.1281 - val_loss: -272.8067 - val_output_1_loss: 3.1472 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 345.5252 - val_loss_1b: 248.7822 - val_loss_1c: 0.1704 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1113.0011 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 46/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 28.1775 - output_1_loss: 2.8354 - output_4_accuracy_metric: 0.2273 - loss_1a: 347.9154 - loss_1b: 249.7797 - loss_1c: 0.1178 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1118.8190 - loss_2a_c: 304.1467 - val_loss: -278.3376 - val_output_1_loss: 2.8857 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 350.4280 - val_loss_1b: 250.6656 - val_loss_1c: 0.1154 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1124.7491 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 47/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 23.0030 - output_1_loss: 2.8507 - output_4_accuracy_metric: 0.2297 - loss_1a: 352.8183 - loss_1b: 249.8061 - loss_1c: 0.0949 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1128.6799 - loss_2a_c: 303.9839 - val_loss: -283.4193 - val_output_1_loss: 3.2555 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 355.3305 - val_loss_1b: 249.4402 - val_loss_1c: 0.1523 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1133.3429 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 48/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 33.5182 - output_1_loss: 2.9065 - output_4_accuracy_metric: 0.2367 - loss_1a: 357.7187 - loss_1b: 249.7367 - loss_1c: 0.1263 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1138.3442 - loss_2a_c: 319.2835 - val_loss: -288.2869 - val_output_1_loss: 3.0697 - val_output_4_accuracy_metric: 0.1302 - val_loss_1a: 360.2293 - val_loss_1b: 248.2962 - val_loss_1c: 0.1438 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1141.9166 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 49/500\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 28.0245 - output_1_loss: 2.8849 - output_4_accuracy_metric: 0.2359 - loss_1a: 362.6147 - loss_1b: 249.5282 - loss_1c: 0.1545 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1147.7910 - loss_2a_c: 318.4697 - val_loss: -292.0843 - val_output_1_loss: 3.0445 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 365.1205 - val_loss_1b: 249.2570 - val_loss_1c: 0.1736 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1152.5906 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 50/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 23.7744 - output_1_loss: 2.9342 - output_4_accuracy_metric: 0.2328 - loss_1a: 367.5063 - loss_1b: 249.7940 - loss_1c: 0.1137 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1158.0062 - loss_2a_c: 319.2835 - val_loss: -297.1353 - val_output_1_loss: 3.0659 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 370.0148 - val_loss_1b: 250.0354 - val_loss_1c: 0.1127 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1163.2911 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 51/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 19.1926 - output_1_loss: 2.7814 - output_4_accuracy_metric: 0.2430 - loss_1a: 372.4013 - loss_1b: 249.7820 - loss_1c: 0.1216 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1167.8156 - loss_2a_c: 319.8260 - val_loss: -302.8162 - val_output_1_loss: 3.0269 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 374.9102 - val_loss_1b: 251.6818 - val_loss_1c: 0.1243 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1174.7322 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 52/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -28.6664 - output_1_loss: 2.9961 - output_4_accuracy_metric: 0.1961 - loss_1a: 377.2937 - loss_1b: 249.7487 - loss_1c: 0.1470 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1177.4891 - loss_2a_c: 276.5315 - val_loss: -308.2008 - val_output_1_loss: 2.7624 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 379.8006 - val_loss_1b: 249.1697 - val_loss_1c: 0.1846 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1181.9955 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 53/500\n",
      "40/40 [==============================] - 4s 92ms/step - loss: -215.7039 - output_1_loss: 3.0810 - output_4_accuracy_metric: 0.1086 - loss_1a: 382.1844 - loss_1b: 249.7382 - loss_1c: 0.1351 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1187.2064 - loss_2a_c: 94.1846 - val_loss: -312.0725 - val_output_1_loss: 3.2781 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 384.6899 - val_loss_1b: 248.0096 - val_loss_1c: 0.1510 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1190.5670 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 54/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 13.5776 - output_1_loss: 2.9230 - output_4_accuracy_metric: 0.2352 - loss_1a: 387.0727 - loss_1b: 249.7976 - loss_1c: 0.1234 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1197.1256 - loss_2a_c: 328.6151 - val_loss: -317.2076 - val_output_1_loss: 2.9728 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 389.5781 - val_loss_1b: 247.7828 - val_loss_1c: 0.1111 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1200.1415 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 91ms/step - loss: -0.0289 - output_1_loss: 2.8739 - output_4_accuracy_metric: 0.2273 - loss_1a: 391.9603 - loss_1b: 249.7669 - loss_1c: 0.1052 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1206.9055 - loss_2a_c: 320.0430 - val_loss: -322.1399 - val_output_1_loss: 2.9862 - val_output_4_accuracy_metric: 0.1302 - val_loss_1a: 394.4646 - val_loss_1b: 249.2350 - val_loss_1c: 0.0975 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1211.3857 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 56/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -21.7219 - output_1_loss: 2.7987 - output_4_accuracy_metric: 0.2133 - loss_1a: 396.8468 - loss_1b: 249.8624 - loss_1c: 0.0952 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1216.7902 - loss_2a_c: 303.4414 - val_loss: -327.6521 - val_output_1_loss: 2.8470 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 399.3511 - val_loss_1b: 250.0439 - val_loss_1c: 0.1085 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1221.9818 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 57/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -23.8057 - output_1_loss: 2.9666 - output_4_accuracy_metric: 0.2172 - loss_1a: 401.7313 - loss_1b: 249.7146 - loss_1c: 0.1103 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1226.3818 - loss_2a_c: 306.0456 - val_loss: -332.3598 - val_output_1_loss: 3.1550 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 404.2327 - val_loss_1b: 250.2168 - val_loss_1c: 0.1208 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1231.8845 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 58/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -22.6110 - output_1_loss: 2.9484 - output_4_accuracy_metric: 0.2445 - loss_1a: 406.6118 - loss_1b: 249.7625 - loss_1c: 0.1384 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1236.1403 - loss_2a_c: 312.0135 - val_loss: -336.5763 - val_output_1_loss: 2.8746 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 409.1123 - val_loss_1b: 247.9424 - val_loss_1c: 0.1043 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1239.3641 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 59/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -7.3361 - output_1_loss: 2.7530 - output_4_accuracy_metric: 0.2188 - loss_1a: 411.4902 - loss_1b: 249.7330 - loss_1c: 0.1096 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1245.9163 - loss_2a_c: 332.4129 - val_loss: -341.3457 - val_output_1_loss: 3.1604 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 413.9902 - val_loss_1b: 250.0959 - val_loss_1c: 0.1334 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1251.2904 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 60/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -36.0190 - output_1_loss: 2.9658 - output_4_accuracy_metric: 0.2445 - loss_1a: 416.3676 - loss_1b: 249.5770 - loss_1c: 0.1782 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1255.3015 - loss_2a_c: 308.1072 - val_loss: -346.3397 - val_output_1_loss: 3.1490 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 418.8635 - val_loss_1b: 250.0583 - val_loss_1c: 0.1510 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1260.7496 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 61/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -28.0858 - output_1_loss: 2.8540 - output_4_accuracy_metric: 0.2359 - loss_1a: 421.2372 - loss_1b: 249.7547 - loss_1c: 0.1136 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1265.3529 - loss_2a_c: 321.2366 - val_loss: -351.8566 - val_output_1_loss: 3.1281 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 423.7343 - val_loss_1b: 249.3856 - val_loss_1c: 0.0798 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1270.0457 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 62/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -35.1976 - output_1_loss: 2.9923 - output_4_accuracy_metric: 0.2383 - loss_1a: 426.1102 - loss_1b: 249.7867 - loss_1c: 0.1040 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1275.0555 - loss_2a_c: 318.7952 - val_loss: -356.1430 - val_output_1_loss: 3.1614 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 428.6071 - val_loss_1b: 249.1814 - val_loss_1c: 0.0790 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1279.5895 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 63/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -230.8451 - output_1_loss: 3.1724 - output_4_accuracy_metric: 0.1453 - loss_1a: 430.9811 - loss_1b: 249.7725 - loss_1c: 0.0914 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1284.8805 - loss_2a_c: 127.9304 - val_loss: -360.9779 - val_output_1_loss: 3.0170 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 433.4756 - val_loss_1b: 246.8489 - val_loss_1c: 0.0820 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1286.9669 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 64/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -113.6083 - output_1_loss: 2.9736 - output_4_accuracy_metric: 0.2086 - loss_1a: 435.8470 - loss_1b: 249.6179 - loss_1c: 0.1102 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1294.4146 - loss_2a_c: 250.1099 - val_loss: -366.0739 - val_output_1_loss: 3.0926 - val_output_4_accuracy_metric: 0.1927 - val_loss_1a: 438.3391 - val_loss_1b: 250.0114 - val_loss_1c: 0.0741 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1299.8561 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 65/500\n",
      "40/40 [==============================] - 4s 88ms/step - loss: -52.2002 - output_1_loss: 2.9934 - output_4_accuracy_metric: 0.2367 - loss_1a: 440.7104 - loss_1b: 249.6291 - loss_1c: 0.0768 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1304.1293 - loss_2a_c: 316.4623 - val_loss: -371.2634 - val_output_1_loss: 3.0472 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 443.2029 - val_loss_1b: 252.8609 - val_loss_1c: 0.0805 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1312.3530 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 66/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -64.4072 - output_1_loss: 2.9411 - output_4_accuracy_metric: 0.2211 - loss_1a: 445.5729 - loss_1b: 249.8096 - loss_1c: 0.0920 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1314.1267 - loss_2a_c: 309.2465 - val_loss: -376.2063 - val_output_1_loss: 3.0729 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 448.0647 - val_loss_1b: 251.1996 - val_loss_1c: 0.0829 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1320.5035 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 67/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -70.3580 - output_1_loss: 2.9335 - output_4_accuracy_metric: 0.2297 - loss_1a: 450.4358 - loss_1b: 249.8082 - loss_1c: 0.1001 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1323.8540 - loss_2a_c: 308.2157 - val_loss: -380.4749 - val_output_1_loss: 2.9198 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 452.9277 - val_loss_1b: 250.0183 - val_loss_1c: 0.0963 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1329.0471 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 68/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -60.6081 - output_1_loss: 2.9480 - output_4_accuracy_metric: 0.2391 - loss_1a: 455.2932 - loss_1b: 249.3561 - loss_1c: 0.2135 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1332.6617 - loss_2a_c: 322.1590 - val_loss: -384.7493 - val_output_1_loss: 3.1964 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 457.7769 - val_loss_1b: 250.9622 - val_loss_1c: 0.1238 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1339.4282 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 90ms/step - loss: -69.5907 - output_1_loss: 2.9655 - output_4_accuracy_metric: 0.2273 - loss_1a: 460.1435 - loss_1b: 249.7531 - loss_1c: 0.1049 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1343.1833 - loss_2a_c: 318.5781 - val_loss: -390.8751 - val_output_1_loss: 2.9325 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 462.6317 - val_loss_1b: 250.2298 - val_loss_1c: 0.0790 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1348.7050 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 70/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -83.0595 - output_1_loss: 2.8922 - output_4_accuracy_metric: 0.2492 - loss_1a: 464.9981 - loss_1b: 249.6264 - loss_1c: 0.0835 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1352.7483 - loss_2a_c: 310.1146 - val_loss: -395.5652 - val_output_1_loss: 3.0693 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 467.4844 - val_loss_1b: 252.0796 - val_loss_1c: 0.0733 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1360.1798 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 71/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -79.6497 - output_1_loss: 2.9824 - output_4_accuracy_metric: 0.2242 - loss_1a: 469.8500 - loss_1b: 249.7962 - loss_1c: 0.0756 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1362.6327 - loss_2a_c: 318.2526 - val_loss: -399.7953 - val_output_1_loss: 3.2695 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 472.3366 - val_loss_1b: 248.6058 - val_loss_1c: 0.0571 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1366.3539 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 72/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -79.2316 - output_1_loss: 3.0621 - output_4_accuracy_metric: 0.2414 - loss_1a: 474.6998 - loss_1b: 249.6933 - loss_1c: 0.0806 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1372.2274 - loss_2a_c: 323.4610 - val_loss: -404.2990 - val_output_1_loss: 3.3537 - val_output_4_accuracy_metric: 0.1250 - val_loss_1a: 477.1843 - val_loss_1b: 249.2904 - val_loss_1c: 0.0922 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1376.7363 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 73/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -174.8160 - output_1_loss: 2.9638 - output_4_accuracy_metric: 0.1734 - loss_1a: 479.5470 - loss_1b: 249.7266 - loss_1c: 0.0889 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1381.9666 - loss_2a_c: 232.8030 - val_loss: -409.7979 - val_output_1_loss: 3.1633 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 482.0315 - val_loss_1b: 248.4165 - val_loss_1c: 0.0810 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1385.6810 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 74/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -258.0992 - output_1_loss: 3.1803 - output_4_accuracy_metric: 0.1609 - loss_1a: 484.3953 - loss_1b: 249.7223 - loss_1c: 0.1093 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1391.6620 - loss_2a_c: 154.1892 - val_loss: -414.9514 - val_output_1_loss: 3.2141 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 486.8790 - val_loss_1b: 250.1458 - val_loss_1c: 0.0991 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1397.0624 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 75/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -109.6518 - output_1_loss: 2.9691 - output_4_accuracy_metric: 0.2234 - loss_1a: 489.2418 - loss_1b: 249.6876 - loss_1c: 0.1178 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1401.3230 - loss_2a_c: 307.7274 - val_loss: -419.8635 - val_output_1_loss: 3.0525 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 491.7239 - val_loss_1b: 249.0253 - val_loss_1c: 0.1232 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1405.5645 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 76/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -101.6947 - output_1_loss: 2.9341 - output_4_accuracy_metric: 0.2250 - loss_1a: 494.0822 - loss_1b: 249.5848 - loss_1c: 0.1141 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1410.7869 - loss_2a_c: 320.4228 - val_loss: -423.7107 - val_output_1_loss: 3.3632 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 496.5620 - val_loss_1b: 248.6989 - val_loss_1c: 0.0940 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1414.8788 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 77/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -97.6165 - output_1_loss: 3.1282 - output_4_accuracy_metric: 0.2313 - loss_1a: 498.9206 - loss_1b: 249.6043 - loss_1c: 0.1398 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1420.3500 - loss_2a_c: 328.9407 - val_loss: -428.7412 - val_output_1_loss: 3.0064 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 501.3985 - val_loss_1b: 246.5483 - val_loss_1c: 0.0760 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1422.4261 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 78/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -112.4100 - output_1_loss: 2.9740 - output_4_accuracy_metric: 0.2266 - loss_1a: 503.7542 - loss_1b: 249.4216 - loss_1c: 0.1574 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1429.5739 - loss_2a_c: 318.7952 - val_loss: -433.6703 - val_output_1_loss: 3.3384 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 506.2276 - val_loss_1b: 247.8690 - val_loss_1c: 0.0842 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1433.2323 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 79/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -114.1378 - output_1_loss: 2.9499 - output_4_accuracy_metric: 0.2250 - loss_1a: 508.5837 - loss_1b: 249.6937 - loss_1c: 0.0684 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1439.9379 - loss_2a_c: 322.5388 - val_loss: -439.0604 - val_output_1_loss: 3.2645 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 511.0610 - val_loss_1b: 249.3723 - val_loss_1c: 0.0536 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1444.6685 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 80/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -126.4462 - output_1_loss: 3.0122 - output_4_accuracy_metric: 0.2375 - loss_1a: 513.4158 - loss_1b: 249.6909 - loss_1c: 0.0826 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1449.6139 - loss_2a_c: 315.0517 - val_loss: -443.9521 - val_output_1_loss: 3.0244 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 515.8918 - val_loss_1b: 249.8510 - val_loss_1c: 0.0736 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1454.8359 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 81/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -140.9450 - output_1_loss: 2.9699 - output_4_accuracy_metric: 0.2203 - loss_1a: 518.2472 - loss_1b: 249.7271 - loss_1c: 0.0718 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1459.3850 - loss_2a_c: 305.5031 - val_loss: -448.2991 - val_output_1_loss: 3.3213 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 520.7228 - val_loss_1b: 248.9411 - val_loss_1c: 0.0597 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1463.5599 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 82/500\n",
      "40/40 [==============================] - 3s 86ms/step - loss: -128.3976 - output_1_loss: 2.9275 - output_4_accuracy_metric: 0.2336 - loss_1a: 523.0747 - loss_1b: 249.5071 - loss_1c: 0.1284 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1468.5071 - loss_2a_c: 322.4845 - val_loss: -453.1389 - val_output_1_loss: 3.1318 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 525.5456 - val_loss_1b: 246.9768 - val_loss_1c: 0.1189 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1471.0741 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 91ms/step - loss: -140.7460 - output_1_loss: 2.8997 - output_4_accuracy_metric: 0.2438 - loss_1a: 527.8964 - loss_1b: 249.5931 - loss_1c: 0.1087 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1478.4290 - loss_2a_c: 315.2687 - val_loss: -458.4566 - val_output_1_loss: 3.1158 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 530.3679 - val_loss_1b: 248.4839 - val_loss_1c: 0.0528 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1482.3369 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 84/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -393.6019 - output_1_loss: 3.3285 - output_4_accuracy_metric: 0.1102 - loss_1a: 532.7184 - loss_1b: 249.6175 - loss_1c: 0.0909 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1488.0251 - loss_2a_c: 66.7322 - val_loss: -463.2395 - val_output_1_loss: 3.0940 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 535.1904 - val_loss_1b: 250.3721 - val_loss_1c: 0.1064 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1493.9307 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 85/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -158.8506 - output_1_loss: 3.1362 - output_4_accuracy_metric: 0.2313 - loss_1a: 537.5413 - loss_1b: 249.7583 - loss_1c: 0.0883 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1497.8960 - loss_2a_c: 306.5881 - val_loss: -467.2622 - val_output_1_loss: 3.2811 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 540.0120 - val_loss_1b: 248.0864 - val_loss_1c: 0.0725 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1501.1245 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 86/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -147.6491 - output_1_loss: 3.0231 - output_4_accuracy_metric: 0.2367 - loss_1a: 542.3619 - loss_1b: 249.4817 - loss_1c: 0.0826 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1507.2466 - loss_2a_c: 322.7015 - val_loss: -471.2990 - val_output_1_loss: 3.3031 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 544.8301 - val_loss_1b: 253.6804 - val_loss_1c: 0.1599 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1515.7338 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 87/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -150.0018 - output_1_loss: 2.9843 - output_4_accuracy_metric: 0.2422 - loss_1a: 547.1781 - loss_1b: 249.8381 - loss_1c: 0.0737 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1517.2642 - loss_2a_c: 325.2514 - val_loss: -477.6611 - val_output_1_loss: 3.2847 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 549.6472 - val_loss_1b: 249.1793 - val_loss_1c: 0.0441 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1521.6298 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 88/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -178.5966 - output_1_loss: 3.0458 - output_4_accuracy_metric: 0.2227 - loss_1a: 551.9948 - loss_1b: 249.6685 - loss_1c: 0.0690 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1526.6820 - loss_2a_c: 301.4340 - val_loss: -482.7649 - val_output_1_loss: 3.0730 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 554.4623 - val_loss_1b: 249.7282 - val_loss_1c: 0.0319 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1531.8265 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 89/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -148.9173 - output_1_loss: 2.9878 - output_4_accuracy_metric: 0.2211 - loss_1a: 556.8101 - loss_1b: 249.7280 - loss_1c: 0.0708 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1536.4279 - loss_2a_c: 336.0479 - val_loss: -487.0066 - val_output_1_loss: 3.2795 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 559.2773 - val_loss_1b: 249.3477 - val_loss_1c: 0.0446 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1541.0341 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 90/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -172.6708 - output_1_loss: 2.9445 - output_4_accuracy_metric: 0.2352 - loss_1a: 561.6240 - loss_1b: 249.7649 - loss_1c: 0.0559 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1546.1006 - loss_2a_c: 317.1676 - val_loss: -491.7850 - val_output_1_loss: 3.2253 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 564.0904 - val_loss_1b: 248.6756 - val_loss_1c: 0.0777 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1550.0267 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 91/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -181.3045 - output_1_loss: 3.0797 - output_4_accuracy_metric: 0.2320 - loss_1a: 566.4355 - loss_1b: 249.6241 - loss_1c: 0.0717 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1555.5656 - loss_2a_c: 313.1528 - val_loss: -496.3427 - val_output_1_loss: 3.2578 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 568.9003 - val_loss_1b: 250.6318 - val_loss_1c: 0.0615 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1561.2740 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 92/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -199.6134 - output_1_loss: 3.0138 - output_4_accuracy_metric: 0.2164 - loss_1a: 571.2437 - loss_1b: 249.6312 - loss_1c: 0.0871 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1565.0948 - loss_2a_c: 299.6436 - val_loss: -501.9873 - val_output_1_loss: 2.9785 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 573.7061 - val_loss_1b: 250.3798 - val_loss_1c: 0.1406 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1570.8658 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 93/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -180.7526 - output_1_loss: 3.1125 - output_4_accuracy_metric: 0.2273 - loss_1a: 576.0467 - loss_1b: 249.5630 - loss_1c: 0.1253 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1574.4303 - loss_2a_c: 322.9727 - val_loss: -506.0765 - val_output_1_loss: 3.3200 - val_output_4_accuracy_metric: 0.1719 - val_loss_1a: 578.5069 - val_loss_1b: 248.0991 - val_loss_1c: 0.1746 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1578.0160 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 94/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -358.1815 - output_1_loss: 3.2117 - output_4_accuracy_metric: 0.1562 - loss_1a: 580.8492 - loss_1b: 249.7764 - loss_1c: 0.0699 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1584.4727 - loss_2a_c: 150.5000 - val_loss: -510.6856 - val_output_1_loss: 3.1881 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 583.3118 - val_loss_1b: 248.2266 - val_loss_1c: 0.0961 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1587.8556 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 95/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -302.3966 - output_1_loss: 3.1048 - output_4_accuracy_metric: 0.1852 - loss_1a: 585.6517 - loss_1b: 249.4967 - loss_1c: 0.0863 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1593.6611 - loss_2a_c: 211.0472 - val_loss: -514.0821 - val_output_1_loss: 3.3999 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 588.1096 - val_loss_1b: 252.5649 - val_loss_1c: 0.2723 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1600.8276 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 96/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -204.8456 - output_1_loss: 3.1173 - output_4_accuracy_metric: 0.2438 - loss_1a: 590.4465 - loss_1b: 249.7400 - loss_1c: 0.0869 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1603.4102 - loss_2a_c: 313.2614 - val_loss: -520.6872 - val_output_1_loss: 3.4544 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 592.9055 - val_loss_1b: 248.2011 - val_loss_1c: 0.0406 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1607.1410 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 90ms/step - loss: -208.8745 - output_1_loss: 3.0634 - output_4_accuracy_metric: 0.2320 - loss_1a: 595.2446 - loss_1b: 249.6608 - loss_1c: 0.0579 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1613.1724 - loss_2a_c: 314.4549 - val_loss: -525.1269 - val_output_1_loss: 3.3591 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 597.7021 - val_loss_1b: 247.4286 - val_loss_1c: 0.1545 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1615.5516 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 98/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -197.1949 - output_1_loss: 3.1018 - output_4_accuracy_metric: 0.2281 - loss_1a: 600.0385 - loss_1b: 249.6569 - loss_1c: 0.0824 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1622.7510 - loss_2a_c: 330.8395 - val_loss: -530.2018 - val_output_1_loss: 3.2155 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 602.4951 - val_loss_1b: 247.9175 - val_loss_1c: 0.0411 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1625.9020 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 99/500\n",
      "40/40 [==============================] - 4s 88ms/step - loss: -217.6691 - output_1_loss: 2.9721 - output_4_accuracy_metric: 0.2297 - loss_1a: 604.8297 - loss_1b: 249.5155 - loss_1c: 0.0920 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1631.9250 - loss_2a_c: 314.9974 - val_loss: -534.4748 - val_output_1_loss: 3.2681 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 607.2834 - val_loss_1b: 252.3237 - val_loss_1c: 0.0482 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1639.5201 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 100/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -204.7963 - output_1_loss: 3.0450 - output_4_accuracy_metric: 0.2461 - loss_1a: 609.6179 - loss_1b: 249.6483 - loss_1c: 0.0796 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1641.8391 - loss_2a_c: 332.7928 - val_loss: -539.7214 - val_output_1_loss: 3.1262 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 612.0712 - val_loss_1b: 249.1092 - val_loss_1c: 0.1114 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1646.2396 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 101/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -210.2811 - output_1_loss: 3.1213 - output_4_accuracy_metric: 0.2398 - loss_1a: 614.4042 - loss_1b: 249.6817 - loss_1c: 0.0715 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1651.5203 - loss_2a_c: 332.1416 - val_loss: -545.0063 - val_output_1_loss: 3.2475 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 616.8570 - val_loss_1b: 248.8479 - val_loss_1c: 0.0343 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1655.6364 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 102/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -212.1058 - output_1_loss: 3.0252 - output_4_accuracy_metric: 0.2406 - loss_1a: 619.1871 - loss_1b: 249.4607 - loss_1c: 0.1327 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1660.4744 - loss_2a_c: 334.7458 - val_loss: -549.6365 - val_output_1_loss: 3.3159 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 621.6368 - val_loss_1b: 249.5735 - val_loss_1c: 0.0269 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1665.9341 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 103/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -253.9317 - output_1_loss: 3.0937 - output_4_accuracy_metric: 0.2086 - loss_1a: 623.9670 - loss_1b: 249.5561 - loss_1c: 0.0819 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1670.2175 - loss_2a_c: 297.7448 - val_loss: -553.7961 - val_output_1_loss: 3.1610 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 626.4160 - val_loss_1b: 249.3881 - val_loss_1c: 0.0928 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1675.0635 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 104/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -302.6708 - output_1_loss: 3.2729 - output_4_accuracy_metric: 0.2016 - loss_1a: 628.7454 - loss_1b: 249.6620 - loss_1c: 0.0798 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1680.1113 - loss_2a_c: 253.8535 - val_loss: -558.7117 - val_output_1_loss: 3.1027 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 631.1941 - val_loss_1b: 250.8065 - val_loss_1c: 0.0750 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1686.1963 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 105/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -423.2240 - output_1_loss: 3.3092 - output_4_accuracy_metric: 0.1281 - loss_1a: 633.5231 - loss_1b: 249.6554 - loss_1c: 0.0609 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1689.7194 - loss_2a_c: 138.1301 - val_loss: -563.4438 - val_output_1_loss: 3.4522 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 635.9714 - val_loss_1b: 248.4795 - val_loss_1c: 0.0566 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1693.2719 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 106/500\n",
      "40/40 [==============================] - 4s 91ms/step - loss: -260.3114 - output_1_loss: 3.0120 - output_4_accuracy_metric: 0.2438 - loss_1a: 638.2994 - loss_1b: 249.7241 - loss_1c: 0.0594 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1699.3730 - loss_2a_c: 306.2083 - val_loss: -568.7659 - val_output_1_loss: 3.3858 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 640.7476 - val_loss_1b: 250.1845 - val_loss_1c: 0.0370 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1704.8629 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 107/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -252.1780 - output_1_loss: 3.0554 - output_4_accuracy_metric: 0.2180 - loss_1a: 643.0721 - loss_1b: 249.4339 - loss_1c: 0.1321 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1707.9154 - loss_2a_c: 318.2527 - val_loss: -572.8641 - val_output_1_loss: 3.2635 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 645.5154 - val_loss_1b: 247.0381 - val_loss_1c: 0.1057 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1710.8693 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 108/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -246.6679 - output_1_loss: 2.9687 - output_4_accuracy_metric: 0.2281 - loss_1a: 647.8400 - loss_1b: 249.5396 - loss_1c: 0.1211 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1717.9674 - loss_2a_c: 328.9949 - val_loss: -577.8685 - val_output_1_loss: 3.3865 - val_output_4_accuracy_metric: 0.1354 - val_loss_1a: 650.2828 - val_loss_1b: 249.5752 - val_loss_1c: 0.0564 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1723.1847 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 109/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -279.7899 - output_1_loss: 3.1276 - output_4_accuracy_metric: 0.2297 - loss_1a: 652.6036 - loss_1b: 249.3640 - loss_1c: 0.2021 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1726.9758 - loss_2a_c: 300.0234 - val_loss: -582.5960 - val_output_1_loss: 3.2348 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 655.0442 - val_loss_1b: 248.1014 - val_loss_1c: 0.0313 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1730.9950 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 110/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -280.6729 - output_1_loss: 3.0388 - output_4_accuracy_metric: 0.2320 - loss_1a: 657.3688 - loss_1b: 249.8149 - loss_1c: 0.0300 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1737.6354 - loss_2a_c: 304.9062 - val_loss: -588.1616 - val_output_1_loss: 3.1491 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 659.8126 - val_loss_1b: 250.4412 - val_loss_1c: 0.0336 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1743.2301 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 89ms/step - loss: -280.5519 - output_1_loss: 3.1332 - output_4_accuracy_metric: 0.2297 - loss_1a: 662.1346 - loss_1b: 249.5640 - loss_1c: 0.0972 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1746.7369 - loss_2a_c: 309.5179 - val_loss: -592.5900 - val_output_1_loss: 3.2325 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 664.5745 - val_loss_1b: 250.7826 - val_loss_1c: 0.0514 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1752.9325 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 112/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -289.5823 - output_1_loss: 3.0865 - output_4_accuracy_metric: 0.2453 - loss_1a: 666.8964 - loss_1b: 249.7704 - loss_1c: 0.0352 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1756.6283 - loss_2a_c: 305.5030 - val_loss: -597.1192 - val_output_1_loss: 3.1036 - val_output_4_accuracy_metric: 0.1562 - val_loss_1a: 669.3381 - val_loss_1b: 249.6011 - val_loss_1c: 0.0451 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1761.3431 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 113/500\n",
      "40/40 [==============================] - 4s 89ms/step - loss: -282.3943 - output_1_loss: 3.1534 - output_4_accuracy_metric: 0.2211 - loss_1a: 671.6599 - loss_1b: 249.7155 - loss_1c: 0.0462 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1766.0231 - loss_2a_c: 317.2761 - val_loss: -601.5122 - val_output_1_loss: 3.4064 - val_output_4_accuracy_metric: 0.1615 - val_loss_1a: 674.1000 - val_loss_1b: 248.7236 - val_loss_1c: 0.0650 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1769.9891 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 114/500\n",
      "40/40 [==============================] - 4s 88ms/step - loss: -271.2644 - output_1_loss: 3.0967 - output_4_accuracy_metric: 0.2555 - loss_1a: 676.4186 - loss_1b: 249.5924 - loss_1c: 0.1156 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1775.0244 - loss_2a_c: 332.7384 - val_loss: -606.9545 - val_output_1_loss: 3.1355 - val_output_4_accuracy_metric: 0.1458 - val_loss_1a: 678.8552 - val_loss_1b: 247.5261 - val_loss_1c: 0.0460 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1778.2944 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 115/500\n",
      "40/40 [==============================] - 3s 85ms/step - loss: -502.3831 - output_1_loss: 3.3542 - output_4_accuracy_metric: 0.1250 - loss_1a: 681.1737 - loss_1b: 249.6158 - loss_1c: 0.0628 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1784.9379 - loss_2a_c: 106.6087 - val_loss: -611.4195 - val_output_1_loss: 3.1788 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 683.6106 - val_loss_1b: 250.1551 - val_loss_1c: 0.0665 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1790.0956 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 116/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -335.7582 - output_1_loss: 3.1824 - output_4_accuracy_metric: 0.2305 - loss_1a: 685.9267 - loss_1b: 249.5838 - loss_1c: 0.0747 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1794.1224 - loss_2a_c: 277.8336 - val_loss: -615.9079 - val_output_1_loss: 3.2954 - val_output_4_accuracy_metric: 0.1667 - val_loss_1a: 688.3622 - val_loss_1b: 251.1527 - val_loss_1c: 0.0883 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1800.8500 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 117/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -287.4565 - output_1_loss: 3.0079 - output_4_accuracy_metric: 0.2555 - loss_1a: 690.6787 - loss_1b: 249.7387 - loss_1c: 0.0624 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1804.0951 - loss_2a_c: 331.3821 - val_loss: -620.4406 - val_output_1_loss: 3.5268 - val_output_4_accuracy_metric: 0.1406 - val_loss_1a: 693.1143 - val_loss_1b: 248.4357 - val_loss_1c: 0.0539 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1807.6019 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 118/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -315.8801 - output_1_loss: 3.0375 - output_4_accuracy_metric: 0.2352 - loss_1a: 695.4291 - loss_1b: 249.6333 - loss_1c: 0.0741 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1813.3281 - loss_2a_c: 307.5105 - val_loss: -625.3503 - val_output_1_loss: 3.5390 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 697.8630 - val_loss_1b: 250.0751 - val_loss_1c: 0.0573 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1818.8470 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 119/500\n",
      "40/40 [==============================] - 4s 90ms/step - loss: -319.1479 - output_1_loss: 3.0826 - output_4_accuracy_metric: 0.2195 - loss_1a: 700.1781 - loss_1b: 249.6486 - loss_1c: 0.0641 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1822.9226 - loss_2a_c: 309.0837 - val_loss: -630.5742 - val_output_1_loss: 3.2623 - val_output_4_accuracy_metric: 0.1510 - val_loss_1a: 702.6099 - val_loss_1b: 251.3176 - val_loss_1c: 0.1304 - val_loss_1d: 229.7353 - val_loss_2a: 2.1383 - val_loss_2b: -2.4849 - val_loss_3: -1829.5482 - val_loss_2a_c: 0.0000e+00\n",
      "Epoch 120/500\n",
      " 5/40 [==>...........................] - ETA: 2s - loss: -269.2925 - output_1_loss: 3.2510 - output_4_accuracy_metric: 0.2562 - loss_1a: 702.8470 - loss_1b: 249.3369 - loss_1c: 0.1474 - loss_1d: 229.7353 - loss_2a: 2.1383 - loss_2b: -2.4849 - loss_3: -1827.1348 - loss_2a_c: 360.6791"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "\n",
    "# data loaders\n",
    "Y = attack.getGroundTruth(true_mapping)\n",
    "gen = DataGenerator(X, Y, num_constrains=12000, alpha=10000, q=0, batch_size=batch_size, ml=0)\n",
    "train_gen = gen.gen()\n",
    "\n",
    "X_test = X[-200:]\n",
    "Y_test = Y[-200:]\n",
    "\n",
    "test_gen = DataGenerator(X_test, Y_test, batch_size=batch_size).gen()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=0.00001)\n",
    "dcgmm.compile(optimizer, loss={\"output_1\": loss_DCGMM_freemove}, metrics={\"output_4\": accuracy_metric})\n",
    "\n",
    "\n",
    "dcgmm.fit(train_gen, validation_data=test_gen, steps_per_epoch=int(len(Y)/batch_size), validation_steps=len(Y_test)//batch_size, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ea603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "masterthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
