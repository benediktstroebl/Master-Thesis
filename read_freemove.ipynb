{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import movingpandas as mpd\n",
    "from datetime import timedelta\n",
    "from pyproj import CRS\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import logging\n",
    "logging.basicConfig(filename='log_read_freemove.log', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading data...')\n",
    "raw_full_trip_gdf = gp.read_file(\"W:/Master-Thesis-Repository/data/freemove_dlr_data/raw_full_trip.geojson\")\n",
    "print('Data read.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_geojson(gdf, path):\n",
    "    assert isinstance(gdf, gp.GeoDataFrame)\n",
    "    gdf.to_file(path, driver='GeoJSON')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing points outside valid lon and lat range...\n",
      "points removed.\n"
     ]
    }
   ],
   "source": [
    "print('removing points outside valid lon and lat range...')\n",
    "# Remove points that fall outside the valid lon and lat range (-90 to 90 for latitude and -180 to 180 for longitude)\n",
    "raw_full_trip_gdf = raw_full_trip_gdf[(raw_full_trip_gdf.lat >= -90) & (raw_full_trip_gdf.lat <= 90) & (raw_full_trip_gdf.lon >= -180) & (raw_full_trip_gdf.lon <= 180)]\n",
    "print('points removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping NA values...\n",
      "NA values dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bened\\AppData\\Local\\Temp\\ipykernel_6076\\1393668278.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  geolife_raw_gdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print('Dropping NA values...')\n",
    "len_before = len(raw_full_trip_gdf)\n",
    "logging.info('Rows before dropping NA values: {}'.format(len(raw_full_trip_gdf)))\n",
    "raw_full_trip_gdf.dropna(inplace=True)\n",
    "logging.info('Rows after dropping NA values: {}'.format(len(raw_full_trip_gdf)))\n",
    "logging.info('Rows dropped: {}'.format(len_before - len(raw_full_trip_gdf)))\n",
    "print('NA values dropped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trajectory collection...\n",
      "trajectory collection created.\n"
     ]
    }
   ],
   "source": [
    "print('creating trajectory collection...')\n",
    "# Create trajectory collection\n",
    "raw_full_trip_collection = mpd.TrajectoryCollection(raw_full_trip_gdf, traj_id_col='traj_id', obj_id_col ='user', t='time', x='lon', y='lat')\n",
    "print('trajectory collection created.')\n",
    "\n",
    "logging.info(f'This is a test log of traj id: {raw_full_trip_collection.trajectories[0].id}')\n",
    "logging.info(f'Number of trajectories in data: {len(raw_full_trip_collection.trajectories)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting to EPSG:32650 for China (Beijing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1987s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-2)]: Done  47 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1292s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Done  67 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1960s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-2)]: Done 109 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-2)]: Done 189 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-2)]: Done 309 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-2)]: Done 429 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-2)]: Done 565 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.2052s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 701 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-2)]: Done 741 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1935s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1290s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Done 773 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-2)]: Done 841 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.7598s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 933 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1875s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done 1001 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1850s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (7.6026s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 1038 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1988s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done 1090 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1300s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Done 1137 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-2)]: Done 1243 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-2)]: Done 1351 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.0625s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 1467 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-2)]: Done 1529 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-2)]: Done 1563 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-2)]: Done 1597 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-2)]: Done 1630 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-2)]: Done 1663 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-2)]: Done 1698 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-2)]: Done 1733 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-2)]: Done 1770 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-2)]: Done 1807 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-2)]: Done 1846 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-2)]: Done 1885 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-2)]: Done 1926 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-2)]: Done 1967 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done 2010 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 2053 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 2098 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done 2143 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done 2190 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Done 2237 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1916s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done 2311 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.0349s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 2376 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done 2427 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-2)]: Done 2479 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 2532 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 2585 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 2640 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2695 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2752 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-2)]: Done 2809 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-2)]: Done 2868 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-2)]: Done 2927 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-2)]: Done 2988 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-2)]: Done 3049 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-2)]: Done 3112 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-2)]: Done 3175 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 3240 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-2)]: Done 3305 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-2)]: Done 3372 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-2)]: Done 3439 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-2)]: Done 3508 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-2)]: Done 3577 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-2)]: Done 3648 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-2)]: Done 3719 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 3792 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-2)]: Done 3865 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-2)]: Done 3940 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-2)]: Done 4015 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done 4092 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done 4169 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-2)]: Done 4248 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-2)]: Done 4327 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-2)]: Done 4408 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done 4489 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done 4572 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-2)]: Done 4655 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-2)]: Done 4740 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-2)]: Done 4825 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-2)]: Done 4912 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-2)]: Done 4999 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-2)]: Done 5088 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-2)]: Done 5177 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-2)]: Done 5268 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-2)]: Done 5359 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-2)]: Done 5452 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-2)]: Done 5545 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-2)]: Done 5640 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-2)]: Done 5735 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-2)]: Done 5832 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-2)]: Done 5929 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-2)]: Done 6028 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-2)]: Done 6127 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-2)]: Done 6228 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-2)]: Done 6329 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-2)]: Done 6432 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-2)]: Done 6535 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-2)]: Done 6640 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-2)]: Done 6745 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-2)]: Done 6852 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-2)]: Done 6959 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-2)]: Done 7068 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-2)]: Done 7177 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-2)]: Done 7288 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-2)]: Done 7399 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-2)]: Done 7512 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-2)]: Done 7625 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-2)]: Done 7740 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-2)]: Done 7855 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-2)]: Done 7972 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-2)]: Done 8089 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-2)]: Done 8208 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-2)]: Done 8327 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-2)]: Done 8448 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-2)]: Done 8569 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-2)]: Done 8692 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-2)]: Done 8815 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-2)]: Done 8940 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-2)]: Done 9065 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-2)]: Done 9192 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-2)]: Done 9319 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-2)]: Done 9448 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-2)]: Done 9577 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-2)]: Done 9708 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-2)]: Done 9839 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-2)]: Done 9972 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-2)]: Done 10105 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-2)]: Done 10240 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-2)]: Done 10375 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-2)]: Done 10512 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-2)]: Done 10649 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-2)]: Done 10788 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-2)]: Done 10927 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-2)]: Done 11068 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-2)]: Done 11209 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-2)]: Done 11352 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-2)]: Done 11495 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-2)]: Done 11640 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-2)]: Done 11785 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-2)]: Done 11932 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-2)]: Done 12079 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-2)]: Done 12228 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-2)]: Done 12377 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-2)]: Done 12528 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-2)]: Done 12679 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-2)]: Done 12832 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-2)]: Done 12985 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-2)]: Done 13140 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-2)]: Done 13295 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-2)]: Done 13452 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-2)]: Done 13609 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-2)]: Done 13768 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-2)]: Done 13927 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-2)]: Done 14088 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1987s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done 14337 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-2)]: Done 14663 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-2)]: Done 14989 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-2)]: Done 15319 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-2)]: Done 15649 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-2)]: Done 15983 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.0343s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 16247 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-2)]: Done 16416 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-2)]: Done 16585 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-2)]: Done 16756 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-2)]: Done 16927 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-2)]: Done 17100 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-2)]: Done 17273 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-2)]: Done 17448 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.1978s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Batch computation too slow (2.0003s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-2)]: Done 17706 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-2)]: Done 17784 out of 17784 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted to EPSG:32650 for China (Beijing).\n"
     ]
    }
   ],
   "source": [
    "# Convert to EPSG:32650 for China (Beijing)\n",
    "def convert_epsg(traj):\n",
    "    result = traj.to_crs(CRS(32650))\n",
    "    result.obj_id = traj.obj_id\n",
    "    return result\n",
    "print('converting to EPSG:32650 for China (Beijing)...')\n",
    "raw_full_trip_collection.trajectories = Parallel(n_jobs=-2, verbose=10)(delayed(convert_epsg)(traj) for traj in raw_full_trip_collection.trajectories)\n",
    "print('converted to EPSG:32650 for China (Beijing).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 16632/17784 [12:20:06<2:22:24,  7.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IllegalArgumentException: CGAlgorithmsDD::orientationIndex encountered NaN/Inf numbers Error at traj:  20110911000506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17784/17784 [13:06:40<00:00,  2.65s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories split.\n"
     ]
    }
   ],
   "source": [
    "# Split trajectories\n",
    "\n",
    "def split_traj(traj, MAX_DIAMETER=100, MIN_DURATION=timedelta(minutes=15), MIN_LENGTH=500):\n",
    "    try:\n",
    "        split = mpd.StopSplitter(traj).split(max_diameter=MAX_DIAMETER, min_duration=MIN_DURATION, min_length=MIN_LENGTH)\n",
    "        for i in range(len(split.trajectories)):\n",
    "            split.trajectories[i].obj_id = traj.obj_id\n",
    "        return split.trajectories\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        logging.warning(f'{e} Error at traj: {traj.id}')\n",
    "\n",
    "        return []\n",
    "\n",
    "print('splitting trajectories...')\n",
    "# split_trajs = Parallel(n_jobs=4, verbose=10)(delayed(split_traj)(traj) for traj in geolife_raw_collection.trajectories)\n",
    "split_trajs = []\n",
    "for traj in tqdm(raw_full_trip_collection.trajectories):\n",
    "    try:\n",
    "        split_trajs.append(split_traj(traj))\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        continue\n",
    "    \n",
    "split_trajs = [traj for sublist in split_trajs for traj in sublist]\n",
    "freemove_splitted_collection = mpd.TrajectoryCollection(split_trajs)\n",
    "print('trajectories split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothing trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26668/26668 [5:05:55<00:00,  1.45it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories smoothed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Smooth trajectories\n",
    "def smooth_traj(traj, PROCESS_NOISE_STD=0.1, MEASUREMENT_NOISE_STD=10):\n",
    "    try:\n",
    "        result = mpd.KalmanSmootherCV(traj).smooth(process_noise_std=PROCESS_NOISE_STD, measurement_noise_std=MEASUREMENT_NOISE_STD)\n",
    "        result.obj_id = traj.obj_id\n",
    "        return result\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        logging.warning(f'{e} Error at traj: {traj.id}')\n",
    "        return traj\n",
    "\n",
    "print('smoothing trajectories...')\n",
    "# geolife_splitted_smooth_collection = Parallel(n_jobs=4, verbose=10)(delayed(smooth_traj)(traj) for traj in geolife_splitted_collection.trajectories)\n",
    "freemove_splitted_smooth_collection = []\n",
    "for traj in tqdm(freemove_splitted_collection.trajectories):\n",
    "    try:\n",
    "        freemove_splitted_smooth_collection.append(smooth_traj(traj))\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        continue\n",
    "\n",
    "freemove_splitted_smooth_collection = mpd.TrajectoryCollection(freemove_splitted_smooth_collection)\n",
    "print('trajectories smoothed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalizing trajectories... (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26668/26668 [1:25:47<00:00,  5.18it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories generalized. (1)\n"
     ]
    }
   ],
   "source": [
    "# Generalize trajectories\n",
    "def generalize_traj(traj, TOLERANCE=1.0):\n",
    "    try:\n",
    "        result = mpd.DouglasPeuckerGeneralizer(traj).generalize(tolerance=TOLERANCE)\n",
    "        result.obj_id = traj.obj_id\n",
    "        return result\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        logging.warning(f'{e} Error at traj: {traj.id}')\n",
    "        return traj\n",
    "\n",
    "# Douglas-Peucker generalization for non-smoothed trajectories\n",
    "print('generalizing trajectories... (1)')\n",
    "logging.info('generalizing trajectories... (1)')\n",
    "# geolife_splitted_generalized_collection = Parallel(n_jobs=4, verbose=10)(delayed(generalize_traj)(traj) for traj in geolife_splitted_collection.trajectories)\n",
    "freemove_splitted_generalized_collection = []\n",
    "for traj in tqdm(freemove_splitted_collection.trajectories):\n",
    "    try:\n",
    "        freemove_splitted_generalized_collection.append(generalize_traj(traj))\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        continue\n",
    "freemove_splitted_generalized_collection = mpd.TrajectoryCollection(freemove_splitted_generalized_collection)\n",
    "print('trajectories generalized. (1)')\n",
    "logging.info('trajectories generalized. (1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalizing trajectories... (2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26668/26668 [1:07:59<00:00,  6.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories generalized. (2)\n"
     ]
    }
   ],
   "source": [
    "# Douglas-Peucker generalization for smoothed trajectories\n",
    "print('generalizing trajectories... (2)')\n",
    "logging.info('generalizing trajectories... (2)')\n",
    "# geolife_splitted_smooth_generalized_collection = Parallel(n_jobs=4, verbose=10)(delayed(generalize_traj)(traj) for traj in geolife_splitted_smooth_collection.trajectories)\n",
    "freemove_splitted_smooth_generalized_collection = []\n",
    "for traj in tqdm(freemove_splitted_smooth_collection.trajectories):\n",
    "    try:\n",
    "        freemove_splitted_smooth_generalized_collection.append(generalize_traj(traj))\n",
    "    except BaseException as e:\n",
    "        print(e, 'Error at traj: ', traj.id)\n",
    "        continue\n",
    "\n",
    "freemove_splitted_smooth_generalized_collection = mpd.TrajectoryCollection(freemove_splitted_smooth_generalized_collection)\n",
    "print('trajectories generalized. (2)')\n",
    "logging.info('trajectories generalized. (2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_trajcollection_to_gdf(trajcollection):\n",
    "    gdfs = []\n",
    "    for traj in tqdm(trajcollection.trajectories):\n",
    "        traj_gdf = traj.to_traj_gdf()\n",
    "        traj_gdf['user_id'] = traj.obj_id\n",
    "        gdfs.append(traj_gdf)\n",
    "\n",
    "    gdf = gp.GeoDataFrame(pd.concat(gdfs), crs='EPSG:32650')\n",
    "\n",
    "    return gp.GeoDataFrame(pd.concat(gdfs), crs='EPSG:32650')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26668/26668 [07:40<00:00, 57.94it/s] \n",
      "100%|██████████| 26668/26668 [07:16<00:00, 61.14it/s] \n",
      "100%|██████████| 26668/26668 [03:08<00:00, 141.45it/s]\n",
      "100%|██████████| 26668/26668 [01:48<00:00, 245.46it/s]\n"
     ]
    }
   ],
   "source": [
    "logging.info('converting to gdf...')\n",
    "freemove_splitted = convert_trajcollection_to_gdf(freemove_splitted_collection)\n",
    "freemove_splitted_smooth = convert_trajcollection_to_gdf(freemove_splitted_smooth_collection)\n",
    "freemove_splitted_generalized = convert_trajcollection_to_gdf(freemove_splitted_generalized_collection)\n",
    "freemove_splitted_smooth_generalized = convert_trajcollection_to_gdf(freemove_splitted_smooth_generalized_collection)\n",
    "logging.info('converted to gdf.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_timezone(gdf):\n",
    "    # Convert timezone to Asia/Shanghai\n",
    "    gdf = gdf.copy()\n",
    "    gdf['start_t'] = gdf['start_t'].dt.tz_localize('GMT').dt.tz_convert('Asia/Shanghai').dt.tz_localize(None)\n",
    "    gdf['end_t'] = gdf['end_t'].dt.tz_localize('GMT').dt.tz_convert('Asia/Shanghai').dt.tz_localize(None)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "logging.info('converting timezone...')\n",
    "freemove_splitted = convert_timezone(freemove_splitted)\n",
    "freemove_splitted_smooth = convert_timezone(freemove_splitted_smooth)\n",
    "freemove_splitted_generalized = convert_timezone(freemove_splitted_generalized)\n",
    "freemove_splitted_smooth_generalized = convert_timezone(freemove_splitted_smooth_generalized)\n",
    "logging.info('converted timezone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# Write gdf to pickle file to load fast for further processing\n",
    "logging.info('writing to pickle...')\n",
    "write_geojson(freemove_splitted, 'W:/Master-Thesis-Repository/data/freemove_dlr_data/freemove_splitted.geojson')\n",
    "write_geojson(freemove_splitted_smooth, 'W:/Master-Thesis-Repository/data/freemove_dlr_data/freemove_splitted_smooth.geojson')\n",
    "write_geojson(freemove_splitted_generalized, 'W:/Master-Thesis-Repository/data/freemove_dlr_data/freemove_splitted_generalized.geojson')\n",
    "write_geojson(freemove_splitted_smooth_generalized, 'W:/Master-Thesis-Repository/data/freemove_dlr_data/freemove_splitted_smooth_generalized.geojson')\n",
    "logging.info('written to pickle.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "543daf12f525df94f20bbdd448da69881f98a71c963c44c9c7818e0113666227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
