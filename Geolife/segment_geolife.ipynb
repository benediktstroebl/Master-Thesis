{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import movingpandas as mpd\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from shapely import LineString, Point\n",
    "import skmob\n",
    "from skmob.preprocessing import detection\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading geolife pickle file...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# read geolife pickle file\n",
    "print(\"Reading geolife pickle file...\")\n",
    "geolife_raw_gdf = gp.GeoDataFrame(pd.read_pickle('../data/geolife/geolife_raw.pkl')).to_crs(epsg=4326)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrajectories(geolife_raw_gdf, max_diameter=100, min_duration_minutes=15, min_length=200, to_csv=False):\n",
    "    \"\"\"This function splits the trajectories into smaller segments using the movingpandas library. The split is done based on the stop points.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        geolife_raw_gdf (_type_): Geolife raw data as geodataframe.\n",
    "        max_diameter (int, optional): See movingpandas documentation. Defaults to 100.\n",
    "        min_duration_minutes (int, optional): See movingpandas documentation. Defaults to 15.\n",
    "        min_length (int, optional): See movingpandas documentation. Defaults to 200.\n",
    "\n",
    "    Returns:\n",
    "        _type_: Geodataframe with split trajectories and user id. \n",
    "    \"\"\"\n",
    "    traj_collection = mpd.TrajectoryCollection(geolife_raw_gdf, traj_id_col='traj_id', obj_id_col='user', t=\"time\")\n",
    "    print(\"Trajectory collection created.\")\n",
    "    split_trajs = []\n",
    "    if to_csv:\n",
    "        \n",
    "        for traj in tqdm(traj_collection.trajectories):\n",
    "            # split trajectory\n",
    "            split = mpd.StopSplitter(traj).split(max_diameter=max_diameter, min_duration=timedelta(minutes=min_duration_minutes), min_length=min_length)\n",
    "\n",
    "            try:\n",
    "                split_traj = split.to_traj_gdf()\n",
    "            except ValueError:\n",
    "                split_traj = traj.to_traj_gdf()\n",
    "                continue\n",
    "\n",
    "            # add user id to each split trajectory\n",
    "            split_traj['user_id'] = traj.obj_id\n",
    "\n",
    "            path = \"../data/geolife/split_trajectories/\" + str(traj.id) + \".csv\"\n",
    "            # save to csv\n",
    "            split_traj.to_csv(path, index=False)\n",
    "        return print(\"All split trajectories are saved to csv in the data folder.\")\n",
    "    else:\n",
    "        for traj in tqdm(traj_collection.trajectories):\n",
    "            # split trajectory\n",
    "            split = mpd.StopSplitter(traj).split(max_diameter=max_diameter, min_duration=timedelta(minutes=min_duration_minutes), min_length=min_length)\n",
    "            try:\n",
    "                split_traj = split.to_traj_gdf()\n",
    "            except ValueError:\n",
    "                split_traj = traj.to_traj_gdf()\n",
    "                continue\n",
    "\n",
    "            # add user id to each split trajectory\n",
    "            split_traj['user_id'] = traj.obj_id\n",
    "            \n",
    "            # add split trajectories to list after converting to geodataframe\n",
    "            split_trajs.append(split_traj)\n",
    "\n",
    "            #print(f\"Next trajectory split and appended to list: {index}/{len(traj_collection.trajectories)}\")\n",
    "\n",
    "        # concat all split trajectories\n",
    "        split_trajs = pd.concat(split_trajs)\n",
    "\n",
    "        # add user id to each split trajectory\n",
    "        #split_trajs['user_id'] = split_trajs['traj_id'].str.split('_').str[0]\n",
    "        print(\"All split trajectories and concatenated.\")\n",
    "        print(\"Done.\")\n",
    "        return split_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting trajectories...\n",
      "Trajectory collection created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17784/17784 [16:45:29<00:00,  3.39s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All split trajectories are saved to csv in the data folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting trajectories...\")\n",
    "splitTrajectories(geolife_raw_gdf, to_csv=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "543daf12f525df94f20bbdd448da69881f98a71c963c44c9c7818e0113666227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
