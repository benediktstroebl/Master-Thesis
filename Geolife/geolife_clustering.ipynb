{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import attack\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cluster import KMeans\n",
    "import utils\n",
    "import tslearn\n",
    "import geopandas as gp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading splitted geolife geojson file...\n",
      "Done.\n",
      "Number of trajectories in loaded dataset: 26668\n",
      "Number of users in loaded dataset: 172\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data \n",
    "raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf, tesselation_gdf = dl.load_geolife()\n",
    "assert len(raw_full_trip_gdf) == len(raw_trip_sp_gdf) == len(raw_trip_ep_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching start and end points with tessellation...\n",
      "Done.\n",
      "\n",
      "Extracting trips that start and end within tessellation area...\n",
      "Number of trips that start and end wihin tessellation area: 23095\n",
      "Number of trips outside and therefore dropped: 3573\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMatching start and end points with tessellation...\")\n",
    "gdf_sp, gdf_ep = attack.match_boundary_points_with_tessellation(raw_trip_sp_gdf, raw_trip_ep_gdf, tesselation_gdf)\n",
    "print(\"Done.\")\n",
    "\n",
    "# Extract Full Trips that Start and End within Tessellation Area\n",
    "print(\"\\nExtracting trips that start and end within tessellation area...\")\n",
    "full_trip_gdf, trip_sp_gdf, trip_ep_gdf, gdf_sp, gdf_ep = attack.extract_trips_that_start_end_in_tessellation(raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf, gdf_sp, gdf_ep)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write separate geojson files for each user\n",
    "print(\"\\nWriting separate geojson files for each user...\")\n",
    "for user_id in tqdm(full_trip_gdf['PERSON_ID'].unique()):\n",
    "    utils.write_geojson(full_trip_gdf[full_trip_gdf['PERSON_ID'] == 134], 'geolife_data/user_' + str(user_id) + '.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [06:59<00:00,  1.45s/it]\n",
      "100%|██████████| 290/290 [00:00<00:00, 12657.90it/s]\n"
     ]
    }
   ],
   "source": [
    "A = attack.cdist(full_trip_gdf.geometry)\n",
    "Q = np.zeros(A.shape)\n",
    "\n",
    "for i in tqdm(range(len(A))):\n",
    "    for j in range(len(A)):\n",
    "        if A[i,j] > 0.5:\n",
    "            Q[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_trip_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m full_trip_gdf\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_trip_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "full_trip_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(A):    \n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    L = D - A\n",
    "    eigvals, eigvecs = np.linalg.eig(L)\n",
    "\n",
    "    n_dim = eigvecs.shape[0]\n",
    "    p = np.zeros(n_dim)\n",
    "    p[eigvecs[:,1] > 0] = 1.0\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trip_gdf = full_trip_gdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_trip_gdf.geometry.apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       LINESTRING (442818.279 4425260.053, 442808.220...\n",
       "1       LINESTRING (442586.020 4425413.497, 442576.267...\n",
       "2       LINESTRING (441711.057 4428615.035, 441726.734...\n",
       "3       LINESTRING (451459.757 4419372.843, 451459.662...\n",
       "4       LINESTRING (441421.774 4435745.239, 441437.450...\n",
       "                              ...                        \n",
       "1817    LINESTRING (442684.957 4425548.723, 442678.504...\n",
       "1818    LINESTRING (442917.943 4425549.563, 442947.311...\n",
       "1819    LINESTRING (443008.567 4425525.945, 443028.544...\n",
       "1820    LINESTRING (442890.929 4425572.150, 442890.752...\n",
       "1821    LINESTRING (442883.510 4425588.670, 442883.238...\n",
       "Name: geometry, Length: 1822, dtype: geometry"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack.LCSS(X[0], X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrained_spectral_clustering(A, Q):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    vol = np.sum(A)\n",
    "\n",
    "    D_norm = np.linalg.inv(np.sqrt(D))\n",
    "    L_norm = np.eye(*A.shape) - D_norm.dot(A.dot(D_norm))\n",
    "    Q_norm = D_norm.dot(Q.dot(D_norm))\n",
    "\n",
    "    # alpha < max eigenval of Q_norm\n",
    "    alpha = 0.6 * sp.linalg.svdvals(Q_norm)[0]\n",
    "    Q1 = Q_norm - alpha * np.eye(*Q_norm.shape)\n",
    "\n",
    "    val, vec = sp.linalg.eig(L_norm, Q1)\n",
    "\n",
    "    vec = vec[:,val >= 0]\n",
    "    vec_norm = (vec / np.linalg.norm(vec, axis=0)) * np.sqrt(vol)\n",
    "\n",
    "    costs = np.multiply(vec_norm.T.dot(L_norm), vec_norm.T).sum(axis=1)\n",
    "    ids = np.where(costs > 1e-10)[0]\n",
    "    min_idx = np.argmin(costs[ids])\n",
    "    min_v = vec_norm[:,ids[min_idx]]\n",
    "\n",
    "    u = D_norm.dot(min_v)\n",
    "\n",
    "    n_dim = u.shape[0]\n",
    "    p = np.zeros(n_dim)\n",
    "    p[u > 0] = 1.0\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrained_spectral_clustering_K(A, Q, K):\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    vol = np.sum(A)\n",
    "\n",
    "    D_norm = np.linalg.inv(np.sqrt(D))\n",
    "    L_norm = np.eye(*A.shape) - D_norm.dot(A.dot(D_norm))\n",
    "    Q_norm = D_norm.dot(Q.dot(D_norm))\n",
    "\n",
    "    # alpha < K-th eigenval of Q_norm\n",
    "    alpha = 0.6 * sp.linalg.svdvals(Q_norm)[K]\n",
    "    Q1 = Q_norm - alpha * np.eye(*Q_norm.shape)\n",
    "\n",
    "    val, vec = sp.linalg.eig(L_norm, Q1)\n",
    "\n",
    "    vec = vec[:,val >= 0]\n",
    "    vec_norm = (vec / np.linalg.norm(vec, axis=0)) * np.sqrt(vol)\n",
    "\n",
    "    costs = np.multiply(vec_norm.T.dot(L_norm), vec_norm.T).sum(axis=1)\n",
    "    ids = np.where(costs > 1e-10)[0]\n",
    "    min_idx = np.argsort(costs[ids])[0:K]\n",
    "    min_v = vec_norm[:,ids[min_idx]]\n",
    "\n",
    "    u = D_norm.dot(min_v)\n",
    "\n",
    "    model = KMeans(n_clusters=K).fit(u)\n",
    "    labels = model.labels_\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'LineString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m SpectralClustering, DBSCAN\n\u001b[0;32m      3\u001b[0m \u001b[39m# sklearn_spec = SpectralClustering(n_clusters=5, affinity='precomputed', n_init=100, n_jobs=-1).fit(A).labels_\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m sklearn_dbscan \u001b[39m=\u001b[39m DBSCAN(eps\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, min_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, metric\u001b[39m=\u001b[39;49mattack\u001b[39m.\u001b[39;49mLCSS)\u001b[39m.\u001b[39;49mfit(X)\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[1;32mc:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:368\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform DBSCAN clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[0;32m    344\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39m    Returns a fitted instance of self.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 368\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    370\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\pandas\\core\\series.py:893\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    847\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[39m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'LineString'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering, DBSCAN\n",
    "\n",
    "# sklearn_spec = SpectralClustering(n_clusters=5, affinity='precomputed', n_init=100, n_jobs=-1).fit(A).labels_\n",
    "\n",
    "sklearn_dbscan = DBSCAN(eps=0.1, min_samples=1, metric=attack.LCSS).fit(X).labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.416\n",
      "Completeness: 0.540\n",
      "V-measure: 0.470\n",
      "Rand index: 0.722\n",
      "ARI: 0.450\n",
      "MI: 0.400\n",
      "NMI: 0.470\n",
      "AMI: 0.457\n",
      "Cluster accuracy: 0.779\n",
      "Homogeneity: 0.979\n",
      "Completeness: 0.415\n",
      "V-measure: 0.583\n",
      "Rand index: 0.808\n",
      "ARI: 0.606\n",
      "MI: 0.942\n",
      "NMI: 0.583\n",
      "AMI: 0.507\n",
      "Cluster accuracy: 0.748\n",
      "Homogeneity: 0.022\n",
      "Completeness: 0.031\n",
      "V-measure: 0.026\n",
      "Rand index: 0.495\n",
      "ARI: -0.009\n",
      "MI: 0.021\n",
      "NMI: 0.026\n",
      "AMI: 0.016\n",
      "Cluster accuracy: 0.455\n",
      "Homogeneity: 0.137\n",
      "Completeness: 0.237\n",
      "V-measure: 0.173\n",
      "Rand index: 0.454\n",
      "ARI: -0.076\n",
      "MI: 0.132\n",
      "NMI: 0.173\n",
      "AMI: 0.165\n",
      "Cluster accuracy: 0.462\n",
      "Homogeneity: 0.598\n",
      "Completeness: 0.421\n",
      "V-measure: 0.494\n",
      "Rand index: 0.656\n",
      "ARI: 0.297\n",
      "MI: 0.575\n",
      "NMI: 0.494\n",
      "AMI: 0.482\n",
      "Cluster accuracy: 0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DELTA = 0.6\n",
    "\n",
    "attack.evaluate(sklearn_spec, full_trip_gdf)\n",
    "attack.evaluate(sklearn_dbscan, full_trip_gdf)\n",
    "\n",
    "attack.evaluate(spectral_clustering(np.exp(- (1-A) ** 2 / (2. * DELTA ** 2))), full_trip_gdf)\n",
    "attack.evaluate(constrained_spectral_clustering(np.exp(- (1-A) ** 2 / (2. * DELTA ** 2)), Q), full_trip_gdf)\n",
    "attack.evaluate(constrained_spectral_clustering_K(np.exp(- (1-A) ** 2 / (2. * DELTA ** 2)), Q, len(full_trip_gdf.PERSON_ID.unique())), full_trip_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
