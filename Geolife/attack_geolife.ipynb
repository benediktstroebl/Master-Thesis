{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import libpysal\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data frames (~ 40 secs)\n",
    "import load_geolife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data \n",
    "raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf, tesselation_gdf = load_geolife.geolife_raw_full_trip_gdf, load_geolife.geolife_raw_sp_gdf, load_geolife.geolife_raw_ep_gdf, load_geolife.geolife_tesselation_gdf\n",
    "assert len(raw_full_trip_gdf) == len(raw_trip_sp_gdf) == len(raw_trip_ep_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select n random person ids from the dataset\n",
    "n_users = 4\n",
    "raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf = attack.select_n_random_users_from_dataframes(n_users, raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Start Points (SP) and End Points (EP) with Tessellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sp, gdf_ep = attack.match_boundary_points_with_tessellation(raw_trip_sp_gdf, raw_trip_ep_gdf, tesselation_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Full Trips that Start and End within Tessellation Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips that start and end wihin tessellation area: 136\n",
      "Number of trips outside and therefore dropped: 16\n"
     ]
    }
   ],
   "source": [
    "full_trip_gdf, trip_sp_gdf, trip_ep_gdf, gdf_sp, gdf_ep = attack.extract_trips_that_start_end_in_tessellation(raw_full_trip_gdf, raw_trip_sp_gdf, raw_trip_ep_gdf, gdf_sp, gdf_ep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build mapping of trip chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:02<00:00, 62.86it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping_cont_trips = attack.build_trip_chain_mapping(gdf_sp, gdf_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges (matched) between trips: 8\n",
      "Number of wrong matches: 0\n"
     ]
    }
   ],
   "source": [
    "attack.evaluate_trip_chaining(mapping_cont_trips, full_trip_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge trips according to matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trip chains...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:00<00:00, 135750.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Merging trips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:01<00:00, 76.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Number of trips that were matched at least once: 136/136\n",
      "Concatenating MERGED and UNMERGED trips...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "full_trips_concat_gdf, trip_concat_dict = attack.merge_trips_from_matching(gdf_sp, mapping_cont_trips, full_trip_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sp_concat, trip_sp_gdf_concat, gdf_ep_concat, trip_ep_gdf_concat = attack.extract_concatenated_trips(full_trips_concat_gdf, gdf_sp, trip_sp_gdf, gdf_ep, trip_ep_gdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Clustering after Concatenation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clusters: 128\n"
     ]
    }
   ],
   "source": [
    "clustering_concat = attack.build_clustering_after_concatenation(full_trips_concat_gdf, trip_concat_dict, full_trip_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Home Locations (HL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Start Points (SPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SP-tessellation matching that still contains all SP (and potential HL), and not just the SP and EP of the concatenated trips. We do this, because we do not want loose potential HL contributed of substrip concatenated in a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\libpysal\\weights\\weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 11 disconnected components.\n",
      " There are 9 islands with ids: 0, 1, 2, 3, 4, 7, 16, 17, 20.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "gdf_hl_combined_sp = attack.build_hl_from_start_points(gdf_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From End Points (EPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\libpysal\\weights\\weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 5 disconnected components.\n",
      " There are 4 islands with ids: 0, 1, 2, 3.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "gdf_hl_combined_ep = attack.build_hl_from_end_points(gdf_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge (concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count unique PERSON_IDs per HL:  PERSON_ID\n",
      "1            12\n",
      "dtype: int64\n",
      "Number of users for which at least on Home Location has been identified:  3\n",
      "Number of unique HL tiles: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bened\\Documents\\Git\\Master-Thesis\\env\\lib\\site-packages\\libpysal\\weights\\weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 12 disconnected components.\n",
      " There are 9 islands with ids: 2, 3, 6, 7, 8, 9, 24, 25, 26.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "gp_combined, HL_table = attack.concatenate_hl(gdf_hl_combined_sp, gdf_hl_combined_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match trips with Home Location tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match concatenated trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched trajectories (concatenated) that do neither start nor end in a HL tile: 49/128\n",
      "Number of trajectories (concatenated) that start AND end in a HL tile: 20/128\n",
      "Number of trips that match different HL tiles with their SP and EP: 11\n"
     ]
    }
   ],
   "source": [
    "HL_table_se_concat, unmatched_trips, double_assigned_trips, nr_unmatched = attack.match_trips_to_HL(gp_combined, HL_table, trip_sp_gdf_concat, trip_ep_gdf_concat, full_trips_concat_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign double matched trips to one unique HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all double matched trips and compare them to all other trips that are uniquely assigned in their respective potential HLs that they have been matched with. Then take the HL with the single maximum lcss score between the trip under question and any trip of the assigned HL tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done  12 out of  22 | elapsed:    8.7s remaining:    7.2s\n",
      "[Parallel(n_jobs=-2)]: Done  15 out of  22 | elapsed:    8.8s remaining:    4.1s\n",
      "[Parallel(n_jobs=-2)]: Done  18 out of  22 | elapsed:    8.9s remaining:    1.9s\n",
      "[Parallel(n_jobs=-2)]: Done  22 out of  22 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "HL_table_trips_concat = attack.assign_double_matched_trips_to_unique_hl(HL_table_se_concat, full_trips_concat_gdf, unmatched_trips, double_assigned_trips, nr_unmatched)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trajectories that happened during the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.0890s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done  22 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-2)]: Done  40 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-2)]: Done  80 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done 102 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-2)]: Done 128 out of 128 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 128 out of 128 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "full_trips_concat_gdf_overlap_dict = attack.getTripOverlaps(full_trips_concat_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clustering after HL assignment step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 159.98it/s]\n"
     ]
    }
   ],
   "source": [
    "clustering_after_HL, HL_table_dict = attack.build_clustering_after_HL_assignment(HL_table_trips_concat, full_trip_gdf, trip_concat_dict, full_trips_concat_gdf_overlap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering results after concatenation step:\n",
      "Number of unique clusters: 128\n",
      "Homogeneity: 1.000\n",
      "Completeness: 0.150\n",
      "V-measure: 0.261\n",
      "Rand index: 0.484\n",
      "ARI: 0.002\n",
      "MI: 0.724\n",
      "NMI: 0.261\n",
      "AMI: 0.019\n",
      "\n",
      "Clustering results after HL matching step:\n",
      "Number of unique clusters: 55\n",
      "Homogeneity: 0.981\n",
      "Completeness: 0.244\n",
      "V-measure: 0.391\n",
      "Rand index: 0.611\n",
      "ARI: 0.241\n",
      "MI: 0.710\n",
      "NMI: 0.391\n",
      "AMI: 0.272\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering results after concatenation step:\")\n",
    "print(f\"Number of unique clusters: {len(set(clustering_concat))}\")\n",
    "attack.evaluate(clustering_concat, full_trip_gdf)\n",
    "\n",
    "clustering_HL = list(dict(sorted(clustering_after_HL.items())).values())\n",
    "print(\"\\nClustering results after HL matching step:\")\n",
    "print(f\"Number of unique clusters: {len(set(clustering_HL))}\")\n",
    "attack.evaluate(clustering_HL, full_trip_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Trips Without Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing trips that were not assigned to any HL_ID with trips that were assigned to a HL_ID...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/49 [00:09<01:32,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/49 [00:10<01:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/49 [00:11<01:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/49 [00:12<00:58,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 56 to trips 27840 27814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/49 [00:18<00:56,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 57 to trips 28137 27960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 14/49 [00:22<00:47,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 15/49 [00:24<00:53,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 57 to trip 27798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16/49 [00:26<00:51,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 58 to trips 27891 27966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 17/49 [00:28<00:54,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 59 to trips 27688 28228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 19/49 [00:30<00:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20/49 [00:31<00:38,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 23/49 [00:37<00:43,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 24/49 [00:38<00:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 27/49 [00:43<00:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 60 to trips 27874 27803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 28/49 [00:45<00:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing match and assign cluster id 2.0 to trip 27921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 29/49 [00:46<00:32,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match and assign new cluster id 61 to trips 27942 27950\n",
      "Done.\n",
      "Assigning clustering IDs to all trips that are part of a new cluster...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_after_double_assign_HL = attack.assign_trips_without_match(\n",
    "    clustering_after_HL, HL_table_dict, \n",
    "    full_trips_concat_gdf, \n",
    "    full_trips_concat_gdf_overlap_dict, \n",
    "    full_trip_gdf, \n",
    "    trip_concat_dict,\n",
    "    SIM_THRESH_FOR_NO_MATCH=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering results after concatenation step:\n",
      "Number of unique clusters: 128\n",
      "Homogeneity: 1.000\n",
      "Completeness: 0.150\n",
      "V-measure: 0.261\n",
      "Rand index: 0.484\n",
      "ARI: 0.002\n",
      "MI: 0.724\n",
      "NMI: 0.261\n",
      "AMI: 0.019\n",
      "\n",
      "Clustering results after HL matching step:\n",
      "Number of unique clusters: 55\n",
      "Homogeneity: 0.981\n",
      "Completeness: 0.244\n",
      "V-measure: 0.391\n",
      "Rand index: 0.611\n",
      "ARI: 0.241\n",
      "MI: 0.710\n",
      "NMI: 0.391\n",
      "AMI: 0.272\n",
      "\n",
      "Clustering results after double assign HL step:\n",
      "Number of unique clusters: 39\n",
      "Homogeneity: 0.981\n",
      "Completeness: 0.282\n",
      "V-measure: 0.438\n",
      "Rand index: 0.653\n",
      "ARI: 0.322\n",
      "MI: 0.710\n",
      "NMI: 0.438\n",
      "AMI: 0.353\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering results after concatenation step:\")\n",
    "print(f\"Number of unique clusters: {len(set(clustering_concat))}\")\n",
    "attack.evaluate(clustering_concat, full_trip_gdf)\n",
    "\n",
    "print(\"\\nClustering results after HL matching step:\")\n",
    "print(f\"Number of unique clusters: {len(set(list(dict(sorted(clustering_after_HL.items())).values())))}\")\n",
    "attack.evaluate(list(dict(sorted(clustering_after_HL.items())).values()), full_trip_gdf)\n",
    "\n",
    "print(\"\\nClustering results after double assign HL step:\")\n",
    "print(f\"Number of unique clusters: {len(set(list(dict(sorted(clustering_after_double_assign_HL.items())).values())))}\")\n",
    "attack.evaluate(list(dict(sorted(clustering_after_double_assign_HL.items())).values()), full_trip_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "543daf12f525df94f20bbdd448da69881f98a71c963c44c9c7818e0113666227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
