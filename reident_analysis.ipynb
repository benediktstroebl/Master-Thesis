{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e578aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import skmob\n",
    "from skmob.measures.individual import radius_of_gyration, number_of_locations\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from shapely import Point\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(10,5), 'figure.dpi':200})\n",
    "sns.set_palette(sns.color_palette(\"colorblind\"))\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8626c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "freemove = gp.read_file(\"data/freemove/freemove_clustering_tfidf.geojson\", geometry='geometry')\n",
    "freemove_private = gp.read_file(\"data/freemove/freemove_private_clustering_tfidf.geojson\", geometry='geometry')\n",
    "freemove_500tessellation = gp.read_file(\"data/freemove/freemove_500tessellation_clustering_tfidf.geojson\", geometry='geometry')\n",
    "freemove_private_500tessellation = gp.read_file(\"data/freemove/freemove_private_500tessellation_clustering_tfidf.geojson\", geometry='geometry')\n",
    "\n",
    "geolife = gp.read_file(\"data/geolife/geolife_clustering_tfidf.geojson\", geometry='geometry')\n",
    "geolife_private = gp.read_file(\"data/geolife/geolife_private_clustering_tfidf.geojson\", geometry='geometry')\n",
    "geolife_500tessellation = gp.read_file(\"data/geolife/geolife_500tessellation_clustering_tfidf.geojson\", geometry='geometry')\n",
    "geolife_private_500tessellation = gp.read_file(\"data/geolife/geolife_private_500tessellation_clustering_tfidf.geojson\", geometry='geometry')\n",
    "\n",
    "\n",
    "clustering_results = {\n",
    "    'freemove': freemove,\n",
    "    'freemove_private': freemove_private,\n",
    "    'freemove_500tessellation': freemove_500tessellation,\n",
    "    'freemove_private_500tessellation': freemove_private_500tessellation,\n",
    "    'geolife': geolife,\n",
    "    'geolife_private': geolife_private,\n",
    "    'geolife_500tessellation': geolife_500tessellation,\n",
    "    'geolife_private_500tessellation': geolife_private_500tessellation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b1eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.847\n",
      "Completeness: 0.511\n",
      "V-measure: 0.638\n",
      "Rand index: 0.968\n",
      "ARI: 0.266\n",
      "MI: 3.134\n",
      "NMI: 0.638\n",
      "AMI: 0.421\n",
      "Cluster accuracy: 0.317\n"
     ]
    }
   ],
   "source": [
    "attack.evaluate(geolife.clustering_HL.tolist(), geolife)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb45f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perf_scores(clustering_result_data, uid, n_points):\n",
    "    # get for random points from this user's trajectories\n",
    "    coords = [list(x.coords) for x in clustering_result_data.query('PERSON_ID == @uid').geometry.tolist()]\n",
    "    coords = [item for sublist in coords for item in sublist]\n",
    "    rand_points = random.choices(coords, k=n_points)\n",
    "\n",
    "    # find all trajectories where these points are part of and get unique cluster ids\n",
    "    clustering_result_data['contains_rand_points'] = clustering_result_data.geometry.apply(lambda x: 1 if len(set(x.coords).intersection(set(rand_points))) > 0 else 0)\n",
    "    cluster_ids = clustering_result_data.query('contains_rand_points == 1').clustering_HL.unique()\n",
    "\n",
    "    # get trips of cluster and the true nr of trips of this user\n",
    "    cluster_trips = clustering_result_data.query('clustering_HL in @cluster_ids')\n",
    "    n_cluster_trips = len(cluster_trips)\n",
    "    n_cluster_user_trips = len(cluster_trips.query('PERSON_ID == @uid'))\n",
    "    n_user_trips = len(clustering_result_data.query('PERSON_ID == @uid'))\n",
    "\n",
    "    # calculate precision, recall, mean\n",
    "    precision = n_cluster_user_trips/n_cluster_trips\n",
    "    recall = n_cluster_user_trips/n_user_trips\n",
    "    pr_mean = (precision + recall)/2\n",
    "    f_score = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    return precision, recall, pr_mean, f_score\n",
    "\n",
    "\n",
    "def evaluate_attack(clustering_result_data, n_draws_per_user, nr_points):\n",
    "    eval_scores = {'user_id': [], 'precision': [], 'recall': [], 'pr_mean': [], 'f_score': [], 'nr_points': []}\n",
    "    \n",
    "    # Find user ids that have at least N_POINTS + 1 trips\n",
    "    user_ids = clustering_result_data.groupby('PERSON_ID').TRIP_ID.nunique().reset_index().query('TRIP_ID > @nr_points').PERSON_ID.unique()\n",
    "    print('Nr of users to evaluate: ', user_ids.size)\n",
    "    \n",
    "    # only evaluate user that have at least N_POINTS/2 + 1 trips\n",
    "    for uid in tqdm(user_ids):\n",
    "    \n",
    "        precision_scores, recall_scores, pr_mean_scores, f_scores = [], [], [], []\n",
    "        for i in range(n_draws_per_user):\n",
    "            p, r, m, f = compute_perf_scores(clustering_result_data, uid, nr_points)\n",
    "            precision_scores.append(p)\n",
    "            recall_scores.append(r)\n",
    "            pr_mean_scores.append(m)\n",
    "            f_scores.append(f)\n",
    "\n",
    "        eval_scores['user_id'].extend([uid] * len(precision_scores))\n",
    "        eval_scores['precision'].extend(precision_scores)\n",
    "        eval_scores['recall'].extend(recall_scores)\n",
    "        eval_scores['pr_mean'].extend(pr_mean_scores)\n",
    "        eval_scores['f_score'].extend(f_scores)\n",
    "        eval_scores['nr_points'].extend([nr_points] * len(precision_scores))\n",
    "\n",
    "    return pd.DataFrame.from_dict(eval_scores)\n",
    "\n",
    "scores = []\n",
    "for name, data in clustering_results.items():\n",
    "    print(\"Next dataset: \", name)\n",
    "    scores_points = []\n",
    "    for nr_p in [1,4,10]:\n",
    "        scores_points.append(evaluate_attack(data, n_draws_per_user=100, nr_points=nr_p))\n",
    "    scores.append(pd.concat(scores_points))\n",
    "    \n",
    "scores = pd.concat(scores, keys=list(clustering_results.keys())).reset_index(0, names=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "92b64c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv('reident_scores.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd5dca",
   "metadata": {},
   "source": [
    "# Constructing Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "36bd8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('reident_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3767e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(gdf, tessellation):\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    gdf['START_POINT'] = gdf.geometry.apply(lambda x: Point(x.coords[0]))\n",
    "    gdf['END_POINT'] = gdf.geometry.apply(lambda x: Point(x.coords[-1]))\n",
    "    \n",
    "    sp = gdf[['PERSON_ID', 'TRIP_ID', 'TRIP_START', 'START_POINT', 'clustering_HL']].copy()\n",
    "    ep = gdf[['PERSON_ID', 'TRIP_ID', 'TRIP_END', 'END_POINT', 'clustering_HL']].copy()\n",
    "\n",
    "\n",
    "    sp['lat'] = sp.START_POINT.apply(lambda x: x.y)\n",
    "    sp['lng'] = sp.START_POINT.apply(lambda x: x.x)\n",
    "    ep['lat'] = ep.END_POINT.apply(lambda x: x.y)\n",
    "    ep['lng'] = ep.END_POINT.apply(lambda x: x.x)\n",
    "\n",
    "    sp = sp.rename(columns={'TRIP_START': 'datetime'})\n",
    "    ep = ep.rename(columns={'TRIP_END': 'datetime'})\n",
    "\n",
    "    sp.drop('START_POINT', axis=1, inplace=True)\n",
    "    ep.drop('END_POINT', axis=1, inplace=True)\n",
    "\n",
    "    points = pd.concat([sp, ep])\n",
    "    points = gp.GeoDataFrame(points, geometry=gp.points_from_xy(points.lng, points.lat, crs='epsg:4326'))\n",
    "    \n",
    "    points = gp.sjoin(points, tessellation, predicate='within', how='left').drop('index_right', axis=1)\n",
    "    \n",
    "    return points\n",
    "\n",
    "\n",
    "\n",
    "def get_location_entropy(tile_id, mapped_points_gdf):\n",
    "    assert isinstance(tile_id, str)\n",
    "    t_trips = mapped_points_gdf.query(\"tile_id == @tile_id\")\n",
    "    le = 0\n",
    "    c_l = len(t_trips)\n",
    "    for p in t_trips.clustering_HL:\n",
    "        c_l_u = len(t_trips.query('clustering_HL == @p'))\n",
    "        p_u_l =  c_l_u/ c_l\n",
    "        le += p_u_l * math.log(p_u_l)\n",
    "    return -le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation_freemove = gp.read_file(\"data/freemove/tessellation_freemove_500.geojson\", geometry='geometry').to_crs(4326)\n",
    "# Get random entropy\n",
    "re_freemove = get_points(clustering_results['freemove'], tessellation_freemove).groupby('PERSON_ID').apply(lambda g: math.log2(g.tile_id.nunique())).reset_index().rename(columns={0: 'rand_entropy', 'PERSON_ID': 'user_id'})\n",
    "re_freemove['data'] = 'freemove'\n",
    "\n",
    "# Get average location entropy\n",
    "mapped_points_freemove = get_points(clustering_results['freemove'], tessellation_freemove)\n",
    "mapped_points_freemove['ale'] = mapped_points_freemove.tile_id.progress_apply(lambda x: get_location_entropy(x, mapped_points_freemove))\n",
    "mapped_points_freemove = mapped_points_freemove[['PERSON_ID', 'ale']].groupby('PERSON_ID').mean().reset_index().rename(columns={'PERSON_ID': 'user_id'})\n",
    "mapped_points_freemove['data'] = 'freemove'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169aea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation_geolife = gp.read_file(\"data/geolife/tessellation_geolife_500.geojson\", geometry='geometry').to_crs(4326)\n",
    "# Get random entropy\n",
    "re_geolife = get_points(clustering_results['geolife'], tessellation_geolife).groupby('PERSON_ID').apply(lambda g: math.log2(g.tile_id.nunique())).reset_index().rename(columns={0: 'rand_entropy', 'PERSON_ID': 'user_id'})\n",
    "re_geolife['data'] = 'geolife'\n",
    "\n",
    "# Get average location entropy\n",
    "mapped_points_geolife = get_points(clustering_results['geolife'], tessellation_geolife)\n",
    "mapped_points_geolife['ale'] = mapped_points_geolife.tile_id.progress_apply(lambda x: get_location_entropy(x, mapped_points_geolife))\n",
    "mapped_points_geolife = mapped_points_geolife[['PERSON_ID', 'ale']].groupby('PERSON_ID').mean().reset_index().rename(columns={'PERSON_ID': 'user_id'})\n",
    "mapped_points_geolife['data'] = 'geolife'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f7154a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with scores\n",
    "scores =  pd.merge(scores, pd.concat([re_geolife, re_freemove]), how='left')\n",
    "scores = pd.merge(scores, pd.concat([mapped_points_geolife, mapped_points_freemove]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb6b3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_Trips\n",
    "n_trips_freemove = clustering_results['freemove'].groupby('PERSON_ID').TRIP_ID.nunique().reset_index().rename(columns={'TRIP_ID': 'n_trips', 'PERSON_ID': 'user_id'})\n",
    "n_trips_freemove['data'] = 'freemove'\n",
    "n_trips_geolife = clustering_results['geolife'].groupby('PERSON_ID').TRIP_ID.nunique().reset_index().rename(columns={'TRIP_ID': 'n_trips', 'PERSON_ID': 'user_id'})\n",
    "n_trips_geolife['data'] = 'geolife'\n",
    "\n",
    "scores = pd.merge(scores, pd.concat([n_trips_freemove, n_trips_geolife]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "22606cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Hour of Day of Travel of Users\n",
    "# freemove\n",
    "clustering_results['freemove']['hour_of_day'] = pd.to_datetime(clustering_results['freemove'].TRIP_START).dt.hour - 1\n",
    "hour_of_day_freemove = clustering_results['freemove'][['PERSON_ID', 'hour_of_day']].groupby('PERSON_ID').mean().reset_index().rename(columns={'PERSON_ID': 'user_id'})\n",
    "hour_of_day_freemove['data'] = 'freemove'\n",
    "\n",
    "# geolife\n",
    "clustering_results['geolife']['hour_of_day'] = pd.to_datetime(clustering_results['geolife'].TRIP_START).dt.hour - 1\n",
    "hour_of_day_geolife = clustering_results['geolife'][['PERSON_ID', 'hour_of_day']].groupby('PERSON_ID').mean().reset_index().rename(columns={'PERSON_ID': 'user_id'})\n",
    "hour_of_day_geolife['data'] = 'geolife'\n",
    "\n",
    "scores = pd.merge(scores, pd.concat([hour_of_day_freemove, hour_of_day_geolife]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius of gyration freemove\n",
    "freemove_raw_points = gp.read_file(\"data/freemove/freemove_raw_point.geojson\", geometry='geometry')\n",
    "freemove_raw_points = freemove_raw_points.to_crs(4326)\n",
    "freemove_raw_points['lon'] = freemove_raw_points.geometry.apply(lambda x: x.coords[0][0])\n",
    "freemove_raw_points['lat'] = freemove_raw_points.geometry.apply(lambda x: x.coords[0][1])\n",
    "tdf_freemove = skmob.TrajDataFrame(freemove_raw_points, latitude='lat', longitude='lon', datetime='time', user_id='user')\n",
    "rg_freemove = radius_of_gyration(tdf_freemove)\n",
    "rg_freemove['data'] = 'freemove'\n",
    "rg_freemove = rg_freemove.rename(columns={'uid': 'user_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius of gyration geolife\n",
    "geolife_raw_points = gp.read_file(\"data/geolife/geolife_raw_point.geojson\", geometry='geometry')\n",
    "geolife_raw_points = geolife_raw_points.to_crs(4326)\n",
    "geolife_raw_points = geolife_raw_points[geolife_raw_points['geometry'].notna()].copy() # there is one single point with NA values\n",
    "geolife_raw_points['lon'] = geolife_raw_points.geometry.apply(lambda x: x.coords[0][0])\n",
    "geolife_raw_points['lat'] = geolife_raw_points.geometry.apply(lambda x: x.coords[0][1])\n",
    "tdf_geolife = skmob.TrajDataFrame(geolife_raw_points, latitude='lat', longitude='lon', datetime='time', user_id='user')\n",
    "rg_geolife = radius_of_gyration(tdf_geolife)\n",
    "rg_geolife['data'] = 'geolife'\n",
    "rg_geolife = rg_geolife.rename(columns={'uid': 'user_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ec0ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with scores\n",
    "scores = pd.merge(scores, pd.concat([rg_freemove, rg_geolife]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea98e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean values per user and data\n",
    "scores['fscore_user_mean'] = scores.groupby(['data', 'nr_points', 'user_id']).f_score.transform('mean')\n",
    "scores['precision_user_mean'] = scores.groupby(['data', 'nr_points', 'user_id']).precision.transform('mean')\n",
    "scores['recall_user_mean'] = scores.groupby(['data', 'nr_points', 'user_id']).recall.transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b306055",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv('reident_scores.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
